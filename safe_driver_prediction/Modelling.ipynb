{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import data_vis\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                False\n",
       "ps_ind_01         False\n",
       "ps_ind_02_cat      True\n",
       "ps_ind_03         False\n",
       "ps_ind_04_cat      True\n",
       "ps_ind_05_cat      True\n",
       "ps_ind_06_bin     False\n",
       "ps_ind_07_bin     False\n",
       "ps_ind_08_bin     False\n",
       "ps_ind_09_bin     False\n",
       "ps_ind_10_bin     False\n",
       "ps_ind_11_bin     False\n",
       "ps_ind_12_bin     False\n",
       "ps_ind_13_bin     False\n",
       "ps_ind_14         False\n",
       "ps_ind_15         False\n",
       "ps_ind_16_bin     False\n",
       "ps_ind_17_bin     False\n",
       "ps_ind_18_bin     False\n",
       "ps_reg_01         False\n",
       "ps_reg_02         False\n",
       "ps_reg_03          True\n",
       "ps_car_01_cat      True\n",
       "ps_car_02_cat      True\n",
       "ps_car_03_cat      True\n",
       "ps_car_04_cat     False\n",
       "ps_car_05_cat      True\n",
       "ps_car_06_cat     False\n",
       "ps_car_07_cat      True\n",
       "ps_car_08_cat     False\n",
       "ps_car_09_cat      True\n",
       "ps_car_10_cat     False\n",
       "ps_car_11_cat     False\n",
       "ps_car_11          True\n",
       "ps_car_12         False\n",
       "ps_car_13         False\n",
       "ps_car_14          True\n",
       "ps_car_15         False\n",
       "ps_calc_01        False\n",
       "ps_calc_02        False\n",
       "ps_calc_03        False\n",
       "ps_calc_04        False\n",
       "ps_calc_05        False\n",
       "ps_calc_06        False\n",
       "ps_calc_07        False\n",
       "ps_calc_08        False\n",
       "ps_calc_09        False\n",
       "ps_calc_10        False\n",
       "ps_calc_11        False\n",
       "ps_calc_12        False\n",
       "ps_calc_13        False\n",
       "ps_calc_14        False\n",
       "ps_calc_15_bin    False\n",
       "ps_calc_16_bin    False\n",
       "ps_calc_17_bin    False\n",
       "ps_calc_18_bin    False\n",
       "ps_calc_19_bin    False\n",
       "ps_calc_20_bin    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any()\n",
    "test_data[test_data==-1] = None\n",
    "test_data.isnull().any()\n",
    "#train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Package for NN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#! sudo pip3 install scikit-neuralnetwork\n",
    "!sudo pip3 install scikit-neuralnetwork --upgrade\n",
    "!sudo pip3 install Theano --upgrade"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "#train_prop is specified\n",
    "X_train, X_val, y_train, y_val = data_util.split_train(train_data,prop=0.75)\n",
    "train_mean = X_train.mean()\n",
    "X_train.fillna(train_mean)\n",
    "X_val.fillna(train_mean)\n",
    "\n",
    "weight = np.zeros_like(y_train)\n",
    "weight[y_train==1]=100\n",
    "weight[y_train==0]=1\n",
    "\n",
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn= Classifier(\n",
    "    layers= [\n",
    "        Layer('Rectifier', units= 100),\n",
    "        Layer('Rectifier', units= 80),\n",
    "        Layer('Rectifier', units= 50),\n",
    "        Layer('Softmax')],\n",
    "    learning_rate=0.000000,\n",
    "    batch_size = 2000,\n",
    "    n_iter= 20,\n",
    "    regularize= 'L2'\n",
    ")\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(-1, 1.0))),\n",
    "        ('neural network', nn)])\n",
    "pipeline.fit(X_train, y_train,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: iteration 0, the loss is Variable containing:\n",
      " 0.7110\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 10, the loss is Variable containing:\n",
      " 0.1808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 20, the loss is Variable containing:\n",
      " 0.1641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 30, the loss is Variable containing:\n",
      " 0.1527\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 40, the loss is Variable containing:\n",
      " 0.1607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 50, the loss is Variable containing:\n",
      " 0.1577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 60, the loss is Variable containing:\n",
      " 0.1616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 70, the loss is Variable containing:\n",
      " 0.1566\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 80, the loss is Variable containing:\n",
      " 0.1624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 90, the loss is Variable containing:\n",
      " 0.1706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 100, the loss is Variable containing:\n",
      " 0.1526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 110, the loss is Variable containing:\n",
      " 0.1547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 0, the loss is Variable containing:\n",
      " 0.1544\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 10, the loss is Variable containing:\n",
      " 0.1592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 20, the loss is Variable containing:\n",
      " 0.1562\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 30, the loss is Variable containing:\n",
      " 0.1551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 40, the loss is Variable containing:\n",
      " 0.1581\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 50, the loss is Variable containing:\n",
      " 0.1578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 60, the loss is Variable containing:\n",
      " 0.1534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 70, the loss is Variable containing:\n",
      " 0.1326\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 80, the loss is Variable containing:\n",
      " 0.1657\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 90, the loss is Variable containing:\n",
      " 0.1502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 100, the loss is Variable containing:\n",
      " 0.1504\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 110, the loss is Variable containing:\n",
      " 0.1466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 0, the loss is Variable containing:\n",
      " 0.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 10, the loss is Variable containing:\n",
      " 0.1350\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 20, the loss is Variable containing:\n",
      " 0.1517\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 30, the loss is Variable containing:\n",
      " 0.1556\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 40, the loss is Variable containing:\n",
      " 0.1521\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 50, the loss is Variable containing:\n",
      " 0.1583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 60, the loss is Variable containing:\n",
      " 0.1444\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 70, the loss is Variable containing:\n",
      " 0.1473\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 80, the loss is Variable containing:\n",
      " 0.1472\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 90, the loss is Variable containing:\n",
      " 0.1435\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 100, the loss is Variable containing:\n",
      " 0.1655\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 110, the loss is Variable containing:\n",
      " 0.1572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 0, the loss is Variable containing:\n",
      " 0.1642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 10, the loss is Variable containing:\n",
      " 0.1584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 20, the loss is Variable containing:\n",
      " 0.1716\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 30, the loss is Variable containing:\n",
      " 0.1544\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 40, the loss is Variable containing:\n",
      " 0.1529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 50, the loss is Variable containing:\n",
      " 0.1534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 60, the loss is Variable containing:\n",
      " 0.1587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 70, the loss is Variable containing:\n",
      " 0.1458\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 80, the loss is Variable containing:\n",
      " 0.1458\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 90, the loss is Variable containing:\n",
      " 0.1574\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 100, the loss is Variable containing:\n",
      " 0.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 110, the loss is Variable containing:\n",
      " 0.1538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 0, the loss is Variable containing:\n",
      " 0.1407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 10, the loss is Variable containing:\n",
      " 0.1642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 20, the loss is Variable containing:\n",
      " 0.1550\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 30, the loss is Variable containing:\n",
      " 0.1563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 40, the loss is Variable containing:\n",
      " 0.1673\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 50, the loss is Variable containing:\n",
      " 0.1601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 60, the loss is Variable containing:\n",
      " 0.1530\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 70, the loss is Variable containing:\n",
      " 0.1541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 80, the loss is Variable containing:\n",
      " 0.1415\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 90, the loss is Variable containing:\n",
      " 0.1515\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 100, the loss is Variable containing:\n",
      " 0.1457\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 110, the loss is Variable containing:\n",
      " 0.1627\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 235\n",
    "hidden_size = [300,250,200]\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "batch_size = 5000\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# X_dev_tensor = torch.from_numpy(X_dev.values)\n",
    "# y_dev_tensor = torch.from_numpy(y_dev.values)\n",
    "\n",
    "# X_dev_tensor= X_dev_tensor.float()\n",
    "# y_dev_tensor =y_dev_tensor.type(torch.LongTensor)\n",
    "# #print(X_train_tensor)\n",
    "# X_dev_Variable = Variable(X_dev_tensor)\n",
    "# y_dev_Variable = Variable(y_dev_tensor)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.values)\n",
    "y_train_tensor = torch.from_numpy(y_train.values)\n",
    "\n",
    "X_train_tensor= X_train_tensor.float()\n",
    "y_train_tensor =y_train_tensor.type(torch.LongTensor)\n",
    "#print(X_train_tensor)\n",
    "X_train_Variable = Variable(X_train_tensor)\n",
    "y_train_Variable = Variable(y_train_tensor)\n",
    "\n",
    "\n",
    "train_set = Data.TensorDataset(data_tensor=X_train_tensor, target_tensor=y_train_tensor )\n",
    "\n",
    "\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_set,      \n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2)              # subprocesses for loading data\n",
    "\n",
    "\n",
    "# train_loader = Data.DataLoader(dataset=train_dataset, \n",
    "#                                            batch_size=batch_size, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = Data.DataLoader(dataset=test_dataset, \n",
    "#                                           batch_size=batch_size, \n",
    "#                                           shuffle=False)\n",
    "    \n",
    "class My_Net(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(My_Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0],hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1],hidden_size[2])\n",
    "        self.fc4 = nn.Linear(hidden_size[2], num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "        \n",
    "net = My_Net(input_size, hidden_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,  (batch_x, batch_y) in enumerate(train_loader):\n",
    "#         print(batch_x)\n",
    "        x,  y = Variable(batch_x), Variable(batch_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 ==0:\n",
    "            print('epoch {}: iteration {}, the loss is {}'.format(epoch,i ,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: iteration 0, the loss is Variable containing:\n",
      " 0.7395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 10, the loss is Variable containing:\n",
      " 0.2306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 20, the loss is Variable containing:\n",
      " 0.1929\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 30, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 40, the loss is Variable containing:\n",
      " 0.1502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 50, the loss is Variable containing:\n",
      " 0.1642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 60, the loss is Variable containing:\n",
      " 0.1539\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 70, the loss is Variable containing:\n",
      " 0.1650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 80, the loss is Variable containing:\n",
      " 0.1600\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 0, the loss is Variable containing:\n",
      " 0.1538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 10, the loss is Variable containing:\n",
      " 0.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 20, the loss is Variable containing:\n",
      " 0.1613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 30, the loss is Variable containing:\n",
      " 0.1547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 40, the loss is Variable containing:\n",
      " 0.1740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 50, the loss is Variable containing:\n",
      " 0.1568\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 60, the loss is Variable containing:\n",
      " 0.1484\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 70, the loss is Variable containing:\n",
      " 0.1547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 80, the loss is Variable containing:\n",
      " 0.1507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 0, the loss is Variable containing:\n",
      " 0.1461\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 10, the loss is Variable containing:\n",
      " 0.1452\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 20, the loss is Variable containing:\n",
      " 0.1532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 30, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 40, the loss is Variable containing:\n",
      " 0.1495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 50, the loss is Variable containing:\n",
      " 0.1527\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 60, the loss is Variable containing:\n",
      " 0.1593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 70, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 80, the loss is Variable containing:\n",
      " 0.1441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 0, the loss is Variable containing:\n",
      " 0.1665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 10, the loss is Variable containing:\n",
      " 0.1506\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 20, the loss is Variable containing:\n",
      " 0.1509\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 30, the loss is Variable containing:\n",
      " 0.1462\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 40, the loss is Variable containing:\n",
      " 0.1593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 50, the loss is Variable containing:\n",
      " 0.1637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 60, the loss is Variable containing:\n",
      " 0.1407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 70, the loss is Variable containing:\n",
      " 0.1329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 80, the loss is Variable containing:\n",
      " 0.1531\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 0, the loss is Variable containing:\n",
      " 0.1551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 10, the loss is Variable containing:\n",
      " 0.1419\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 20, the loss is Variable containing:\n",
      " 0.1571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 30, the loss is Variable containing:\n",
      " 0.1558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 40, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 50, the loss is Variable containing:\n",
      " 0.1630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 60, the loss is Variable containing:\n",
      " 0.1532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 70, the loss is Variable containing:\n",
      " 0.1442\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 80, the loss is Variable containing:\n",
      " 0.1502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 0, the loss is Variable containing:\n",
      " 0.1598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 10, the loss is Variable containing:\n",
      " 0.1626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 20, the loss is Variable containing:\n",
      " 0.1501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 30, the loss is Variable containing:\n",
      " 0.1433\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 40, the loss is Variable containing:\n",
      " 0.1560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 50, the loss is Variable containing:\n",
      " 0.1481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 60, the loss is Variable containing:\n",
      " 0.1598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 70, the loss is Variable containing:\n",
      " 0.1604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 80, the loss is Variable containing:\n",
      " 0.1606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 0, the loss is Variable containing:\n",
      " 0.1449\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 10, the loss is Variable containing:\n",
      " 0.1378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 20, the loss is Variable containing:\n",
      " 0.1494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 30, the loss is Variable containing:\n",
      " 0.1395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 40, the loss is Variable containing:\n",
      " 0.1677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 50, the loss is Variable containing:\n",
      " 0.1412\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 60, the loss is Variable containing:\n",
      " 0.1594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 70, the loss is Variable containing:\n",
      " 0.1583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 80, the loss is Variable containing:\n",
      " 0.1316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 0, the loss is Variable containing:\n",
      " 0.1387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 10, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 20, the loss is Variable containing:\n",
      " 0.1567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 30, the loss is Variable containing:\n",
      " 0.1621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 40, the loss is Variable containing:\n",
      " 0.1537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 50, the loss is Variable containing:\n",
      " 0.1644\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 60, the loss is Variable containing:\n",
      " 0.1528\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 70, the loss is Variable containing:\n",
      " 0.1734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 80, the loss is Variable containing:\n",
      " 0.1447\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 0, the loss is Variable containing:\n",
      " 0.1554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 10, the loss is Variable containing:\n",
      " 0.1403\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 20, the loss is Variable containing:\n",
      " 0.1585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 30, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 40, the loss is Variable containing:\n",
      " 0.1540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 50, the loss is Variable containing:\n",
      " 0.1367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 60, the loss is Variable containing:\n",
      " 0.1579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 70, the loss is Variable containing:\n",
      " 0.1542\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 80, the loss is Variable containing:\n",
      " 0.1441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 0, the loss is Variable containing:\n",
      " 0.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 10, the loss is Variable containing:\n",
      " 0.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 20, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 30, the loss is Variable containing:\n",
      " 0.1637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 40, the loss is Variable containing:\n",
      " 0.1591\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 50, the loss is Variable containing:\n",
      " 0.1611\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 60, the loss is Variable containing:\n",
      " 0.1703\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 70, the loss is Variable containing:\n",
      " 0.1652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 80, the loss is Variable containing:\n",
      " 0.1558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(446409,)\n",
      "(148803,)\n",
      "test set auc is 0.6344029175708916; Val set auc is 0.6293206671721198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score            \n",
    "#try to test it's accuracy\n",
    "out=  net(X_train_Variable)\n",
    "out = F.softmax(out)\n",
    "score_1 = roc_auc_score(y_train_Variable.data.numpy(), out.data.numpy()[:,1])\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val.values)\n",
    "y_val_tensor = torch.from_numpy(y_val.values)\n",
    "\n",
    "X_val_tensor= X_val_tensor.float()\n",
    "y_val_tensor =y_val_tensor.type(torch.LongTensor)\n",
    "#print(X_train_tensor)\n",
    "X_val_Variable = Variable(X_val_tensor)\n",
    "y_val_Variable = Variable(y_val_tensor)\n",
    "out2=  net(X_val_Variable)\n",
    "out2 = F.softmax(out2)\n",
    "score_2 = roc_auc_score(y_val_Variable.data.numpy(), out2.data.numpy()[:,1])\n",
    "\n",
    "print(out.data.numpy()[:,1].shape)\n",
    "print(out2.data.numpy()[:,1].shape)\n",
    "print('test set auc is {}; Val set auc is {}'.format(score_1, score_2))\n",
    "\n",
    "\n",
    "#So here I've tested that with Variable type, I can run this function\n",
    "# for t in range(100):\n",
    "#     out = net(X_train_tensor)                 # input x and predict based on x\n",
    "#     loss = criterion(out, y_train_tensor)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "#     optimizer.zero_grad()   # clear gradients for next train\n",
    "#     loss.backward()         # backpropagation, compute gradients\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446409,)\n",
      "(446409,)\n"
     ]
    }
   ],
   "source": [
    "print(out.data.numpy()[:,1].shape)\n",
    "print(out2.data.numpy()[:,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set auc is 0.6344029175708916; Val set auc is 0.6293206671721198\n"
     ]
    }
   ],
   "source": [
    "print('test set auc is {}; Val set auc is {}'.format(score_1, score_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_util\n",
    "import data_preprocess\n",
    "import datetime\n",
    "\n",
    "tic= datetime.datetime.now()\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "naive_pre = data_preprocess.naive_preprocess()\n",
    "y_test_index = test_data['id']\n",
    "test_data.drop(['id'], axis=1, inplace=True)\n",
    "train_data = naive_pre.dtype_change(train_data)\n",
    "test_data = naive_pre.dtype_change(test_data)\n",
    "#train_prop is specified\n",
    "#X_train, X_val, y_train, y_val = data_util.split_train(train_data,prop=0.75)\n",
    "y_train = train_data['target']\n",
    "train_data.drop(['target','id'], axis=1, inplace=True)\n",
    "X_train = train_data\n",
    "\n",
    "X_train = naive_pre.scale(X_train)\n",
    "X_test = naive_pre.scale(test_data,test=True)\n",
    "\n",
    "#result = y_test_index,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.values)\n",
    "\n",
    "X_test_tensor= X_test_tensor.float()\n",
    "\n",
    "#print(X_train_tensor)\n",
    "X_test_Variable = Variable(X_test_tensor)\n",
    "\n",
    "out=  net(X_test_Variable)\n",
    "out = F.softmax(out)\n",
    "#print(out)\n",
    "prob = out.data.numpy()[:,1]\n",
    "\n",
    "result = np.hstack((y_test_index, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"inter.csv\", result, delimiter=\",\",header= 'id, target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import data_util\n",
    "import data_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import numpy as np \n",
    "\n",
    "rso = np.random.RandomState(66)\n",
    "tic= datetime.datetime.now()\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "naive_pre = data_preprocess.naive_preprocess()\n",
    "train_data = naive_pre.dtype_change(train_data)\n",
    "\n",
    "X, y = data_util.abandon_col(train_data)\n",
    "\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X,y,test_size =0.1 ,random_state=rso)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size =0.2, random_state=rso)\n",
    "\n",
    "X_train = naive_pre.scale(X_train)\n",
    "X_val = naive_pre.scale(X_val,test=True)\n",
    "X_train_test = naive_pre.scale(X_train_test,test=True)\n",
    "X_dev, y_dev = X_train[:10000,:], y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={}\n",
    "#enter df here\n",
    "data['X_train'] = X_train\n",
    "data['X_val'] = X_val\n",
    "try:\n",
    "    data['y_train'] = y_train.values\n",
    "    data['y_val'] =y_val.values\n",
    "except:\n",
    "    data['y_train'] = y_train\n",
    "    data['y_val'] =y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 1.36523724]\n",
      "  acc for train: 0.042106908846534376, acc for val: 0.04148854748081913\n",
      "  auc for train: 0.5157980563450647, auc for val: 0.5220829989898828\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 1.35413134]\n",
      "  acc for train: 0.08038231066475013, acc for val: 0.07961694263473278\n",
      "  auc for train: 0.520182009165457, auc for val: 0.533105490876729\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 1.34124649]\n",
      "  acc for train: 0.08049431574231365, acc for val: 0.07987828781571431\n",
      "  auc for train: 0.5202673264810951, auc for val: 0.5331885254310119\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 1.32655239]\n",
      "  acc for train: 0.08387080214303048, acc for val: 0.08296776120517463\n",
      "  auc for train: 0.5198906392694171, auc for val: 0.5327399057848122\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 1.33419442]\n",
      "  acc for train: 0.0838031324086692, acc for val: 0.08279975358882936\n",
      "  auc for train: 0.5200184064286748, auc for val: 0.5329578141662669\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 1.30655932]\n",
      "  acc for train: 0.08678760103791372, acc for val: 0.08604790083817133\n",
      "  auc for train: 0.5192404256306938, auc for val: 0.5323326054459401\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 1.30297732]\n",
      "  acc for train: 0.08740129552539715, acc for val: 0.08668259627769792\n",
      "  auc for train: 0.519252432891609, auc for val: 0.5322018200713204\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 1.28488958]\n",
      "  acc for train: 0.09100412552035693, acc for val: 0.09011741865631243\n",
      "  auc for train: 0.5191697750874124, auc for val: 0.5322060914580045\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 1.28784466]\n",
      "  acc for train: 0.09187449831059008, acc for val: 0.0911347981108477\n",
      "  auc for train: 0.5190437216500183, auc for val: 0.5320748550129224\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 1.27280343]\n",
      "  acc for train: 0.09580400978177678, acc for val: 0.09480296440105285\n",
      "  auc for train: 0.5190528058213246, auc for val: 0.5321230719394038\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 4.051427101042863e-06. Weight decay is 2.080845035520147. dropout is 0.12910294315844584\n",
      " Val aus is 0.5321230719394038. Train auc is 0.5190528058213246\n",
      "This is round you consume 0:01:46.560969 time to run this model.\n",
      "You have finished 1!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.71718884]\n",
      "  acc for train: 0.6320096511041834, acc for val: 0.6315126285724952\n",
      "  auc for train: 0.49536250221924516, auc for val: 0.49547642984424917\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.32162407]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5319397280302609, auc for val: 0.5294437998480475\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.32945824]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5333330969889998, auc for val: 0.5307230720155844\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.29906163]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47814065937652794, auc for val: 0.4825957632114228\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.30308363]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5057881113243708, auc for val: 0.5103226209812077\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.29272121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.524111593805013, auc for val: 0.519681473535736\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.30011669]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5348433549809413, auc for val: 0.5311810137846732\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.3387714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5321119964596984, auc for val: 0.5276916429493818\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.34095648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5138884095635314, auc for val: 0.5086035989669244\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.37941104]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5442397793810851, auc for val: 0.5423198705740515\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.0013127261406181013. Weight decay is 1.5989822278254577. dropout is 0.5575533337122203\n",
      " Val aus is 0.5423198705740515. Train auc is 0.5442397793810851\n",
      "This is round you consume 0:01:47.980720 time to run this model.\n",
      "You have finished 2!!\n",
      "Epoch 0: iteration 0, the loss is [ 1.20639992]\n",
      "  acc for train: 0.0366256603632698, acc for val: 0.03611230375777035\n",
      "  auc for train: 0.5475034902058631, auc for val: 0.5472995932527236\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.20859155]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.512588110210386, auc for val: 0.5185347396527542\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.20392744]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5091704232810065, auc for val: 0.5136741221296732\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.1805473]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46668409920621856, auc for val: 0.4731810292914733\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.18108818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4684232535804723, auc for val: 0.47783713773177955\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.17911497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5168716100673686, auc for val: 0.5077663445281805\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.17724846]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5090153195874577, auc for val: 0.49965412794026276\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.1560242]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46196290971464793, auc for val: 0.46924920469260833\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.15306407]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.489037078452161, auc for val: 0.4855271749204342\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.16999544]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5353599499477891, auc for val: 0.5358795967738799\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.007879870282127468. Weight decay is 0.0028137803098194584. dropout is 0.9809761910397172\n",
      " Val aus is 0.5358795967738799. Train auc is 0.5353599499477891\n",
      "This is round you consume 0:01:42.851602 time to run this model.\n",
      "You have finished 3!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 0.98713529]\n",
      "  acc for train: 0.19252506113610485, acc for val: 0.19202337172618492\n",
      "  auc for train: 0.4835921905016788, auc for val: 0.4820480584203207\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.73045838]\n",
      "  acc for train: 0.7231001138718288, acc for val: 0.7260449140361029\n",
      "  auc for train: 0.48875336353085275, auc for val: 0.4920095849666595\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.72516286]\n",
      "  acc for train: 0.7337149284100879, acc for val: 0.736834736508055\n",
      "  auc for train: 0.48872415474131925, auc for val: 0.4921091136641833\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.58176845]\n",
      "  acc for train: 0.884641770426926, acc for val: 0.8874255632922026\n",
      "  auc for train: 0.4874093336997529, auc for val: 0.4930200742694533\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.58887798]\n",
      "  acc for train: 0.8885596147025332, acc for val: 0.8908043831320354\n",
      "  auc for train: 0.4876382561306993, auc for val: 0.49329767932065666\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.50478536]\n",
      "  acc for train: 0.9378091806828576, acc for val: 0.9397412682708283\n",
      "  auc for train: 0.4872088922424964, auc for val: 0.49508464883522985\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.49715981]\n",
      "  acc for train: 0.9385278799305569, acc for val: 0.9404413000056002\n",
      "  auc for train: 0.48725290198963545, auc for val: 0.4952999184544794\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.45240304]\n",
      "  acc for train: 0.9541549216897832, acc for val: 0.9552166364875208\n",
      "  auc for train: 0.4873820464027911, auc for val: 0.4973167998367004\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.4484666]\n",
      "  acc for train: 0.9547476152252236, acc for val: 0.9557299930930202\n",
      "  auc for train: 0.4874770363415216, auc for val: 0.49739620076781416\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.41498247]\n",
      "  acc for train: 0.9604645410591947, acc for val: 0.9611902406242416\n",
      "  auc for train: 0.4879085338988566, auc for val: 0.4990736090259961\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 8.903006523444832e-05. Weight decay is 1.1966463072220914. dropout is 0.3989469315014088\n",
      " Val aus is 0.4990736090259961. Train auc is 0.4879085338988566\n",
      "This is round you consume 0:01:47.696715 time to run this model.\n",
      "You have finished 4!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.89015132]\n",
      "  acc for train: 0.9568010416472214, acc for val: 0.956560697418283\n",
      "  auc for train: 0.46605446638465076, auc for val: 0.46396159760497224\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.7442798]\n",
      "  acc for train: 0.9427630719259273, acc for val: 0.9427654053650432\n",
      "  auc for train: 0.4968097801017667, auc for val: 0.4898534719154108\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.71627229]\n",
      "  acc for train: 0.9409919916369542, acc for val: 0.9410479941757359\n",
      "  auc for train: 0.49755382980975227, auc for val: 0.4906144140027347\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.68813062]\n",
      "  acc for train: 0.9235495342455524, acc for val: 0.9244432414269447\n",
      "  auc for train: 0.5029561426976613, auc for val: 0.497508627574615\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.69311833]\n",
      "  acc for train: 0.9252926132651347, acc for val: 0.9262166551550337\n",
      "  auc for train: 0.502637383551697, auc for val: 0.4972563288293246\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.70312393]\n",
      "  acc for train: 0.9158071832589744, acc for val: 0.9168548974220164\n",
      "  auc for train: 0.49907291241420626, auc for val: 0.4946655655335015\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.67743182]\n",
      "  acc for train: 0.9200400418152289, acc for val: 0.9207750751367395\n",
      "  auc for train: 0.4990601458781176, auc for val: 0.49470693621274264\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.6866588]\n",
      "  acc for train: 0.9458058765330695, acc for val: 0.9465735780022028\n",
      "  auc for train: 0.49684112773924083, auc for val: 0.4935699692582449\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.69016004]\n",
      "  acc for train: 0.9464079038249734, acc for val: 0.9467602531314753\n",
      "  auc for train: 0.49752597593567355, auc for val: 0.49421958464950677\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.68344384]\n",
      "  acc for train: 0.9595428326084116, acc for val: 0.9600795236050701\n",
      "  auc for train: 0.49643043453808233, auc for val: 0.49688463799751015\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.0004461874190716296. Weight decay is 70.56862850945058. dropout is 0.8865398044741222\n",
      " Val aus is 0.49688463799751015. Train auc is 0.49643043453808233\n",
      "This is round you consume 0:01:46.676924 time to run this model.\n",
      "You have finished 5!!\n",
      "Epoch 0: iteration 0, the loss is [ 1.34820974]\n",
      "  acc for train: 0.33871502174765256, acc for val: 0.3407661147305345\n",
      "  auc for train: 0.4878292241557543, auc for val: 0.4885778095645462\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 1.20456481]\n",
      "  acc for train: 0.05898934085011854, acc for val: 0.05799062890851052\n",
      "  auc for train: 0.48440479619541293, auc for val: 0.4770887040789721\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 1.33817887]\n",
      "  acc for train: 0.08152802927066027, acc for val: 0.08140902387574904\n",
      "  auc for train: 0.4877459460539636, auc for val: 0.4811356142944189\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 1.3771354]\n",
      "  acc for train: 0.11241109596968396, acc for val: 0.11288245067109709\n",
      "  auc for train: 0.4869559210477462, auc for val: 0.48171199087827266\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 1.25453389]\n",
      "  acc for train: 0.05480781795441393, acc for val: 0.05375310347402416\n",
      "  auc for train: 0.4870473987494209, auc for val: 0.4821061425131665\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 1.17493939]\n",
      "  acc for train: 0.06775373816946369, acc for val: 0.06710970897347346\n",
      "  auc for train: 0.48450535126637667, auc for val: 0.4788298974594549\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 1.51960814]\n",
      "  acc for train: 0.04982825888106927, acc for val: 0.049179562806847245\n",
      "  auc for train: 0.48766955414436597, auc for val: 0.481127652900758\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 1.58076537]\n",
      "  acc for train: 0.05220136646194627, acc for val: 0.05155967070507196\n",
      "  auc for train: 0.4861604786212834, auc for val: 0.4803948839227301\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 1.32328749]\n",
      "  acc for train: 0.05340775448486998, acc for val: 0.05265172021131625\n",
      "  auc for train: 0.4884362822415703, auc for val: 0.48186102957093657\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 1.11455679]\n",
      "  acc for train: 0.05221303365752581, acc for val: 0.05148500065336295\n",
      "  auc for train: 0.48437300271662753, auc for val: 0.4772871425051074\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 6.354276310216332e-06. Weight decay is 262.6684327051769. dropout is 0.9914665992393943\n",
      " Val aus is 0.4772871425051074. Train auc is 0.48437300271662753\n",
      "This is round you consume 0:01:48.046244 time to run this model.\n",
      "You have finished 6!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 0.83644313]\n",
      "  acc for train: 0.48297989508857736, acc for val: 0.4859246952528515\n",
      "  auc for train: 0.5070903719773481, auc for val: 0.5055538075739823\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.81273586]\n",
      "  acc for train: 0.8883332711082902, acc for val: 0.8900950176407997\n",
      "  auc for train: 0.5077105051634889, auc for val: 0.5043055064055815\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.80850959]\n",
      "  acc for train: 0.8876309059344024, acc for val: 0.8893483171237097\n",
      "  auc for train: 0.5068455308163965, auc for val: 0.5035065027420473\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.79204297]\n",
      "  acc for train: 0.890662043345965, acc for val: 0.8922417816274337\n",
      "  auc for train: 0.5073687851899994, auc for val: 0.5038893851332228\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.80437011]\n",
      "  acc for train: 0.8882422669827699, acc for val: 0.8897590024081091\n",
      "  auc for train: 0.5071878877060447, auc for val: 0.5036989970618673\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.77964222]\n",
      "  acc for train: 0.8974196830256305, acc for val: 0.8987007411002632\n",
      "  auc for train: 0.5073465125256492, auc for val: 0.5036572529965213\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.79930866]\n",
      "  acc for train: 0.8990764247979242, acc for val: 0.900306147212007\n",
      "  auc for train: 0.506665978895123, auc for val: 0.503105523654516\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.78291625]\n",
      "  acc for train: 0.9018765517370121, acc for val: 0.9031249416640221\n",
      "  auc for train: 0.5065188803256018, auc for val: 0.5029835141063366\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.77624297]\n",
      "  acc for train: 0.9049216897832701, acc for val: 0.9056170546398103\n",
      "  auc for train: 0.5065743114326268, auc for val: 0.5030216170306725\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.79011351]\n",
      "  acc for train: 0.9083075099404506, acc for val: 0.9093318897123336\n",
      "  auc for train: 0.5073190942125602, auc for val: 0.5036813727365234\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 5.675065563963184e-06. Weight decay is 5.260775415682158. dropout is 0.7723558241169411\n",
      " Val aus is 0.5036813727365234. Train auc is 0.5073190942125602\n",
      "This is round you consume 0:01:49.215586 time to run this model.\n",
      "You have finished 7!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.87244952]\n",
      "  acc for train: 0.5617054639810338, acc for val: 0.5623681606899513\n",
      "  auc for train: 0.5021808821655026, auc for val: 0.49537341913335053\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.85002184]\n",
      "  acc for train: 0.9411553323750677, acc for val: 0.9412440030614722\n",
      "  auc for train: 0.5177412107910209, auc for val: 0.5191813378838124\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.81357473]\n",
      "  acc for train: 0.9410339935410406, acc for val: 0.9409453228546361\n",
      "  auc for train: 0.5176890407874839, auc for val: 0.5191438940235409\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.84408468]\n",
      "  acc for train: 0.9461955608654259, acc for val: 0.946265564038903\n",
      "  auc for train: 0.5173161222798297, auc for val: 0.5189119072317662\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.82858229]\n",
      "  acc for train: 0.9467649200097071, acc for val: 0.9469655957736751\n",
      "  auc for train: 0.5174370133726244, auc for val: 0.5192838975242486\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.81842154]\n",
      "  acc for train: 0.9491706957382068, acc for val: 0.9492710336201908\n",
      "  auc for train: 0.5173636890182064, auc for val: 0.5189160996811193\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.82557791]\n",
      "  acc for train: 0.9491333607123523, acc for val: 0.9493830386977543\n",
      "  auc for train: 0.5170727515140345, auc for val: 0.5185977967974478\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.80412191]\n",
      "  acc for train: 0.9520734939983946, acc for val: 0.9522205006626967\n",
      "  auc for train: 0.5165880551480566, auc for val: 0.5180609653104361\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.81437898]\n",
      "  acc for train: 0.9522251675409286, acc for val: 0.9523045044708693\n",
      "  auc for train: 0.5166856150125696, auc for val: 0.5181599527234051\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.81933939]\n",
      "  acc for train: 0.9540172487819448, acc for val: 0.954012581903713\n",
      "  auc for train: 0.5164913483183406, auc for val: 0.5181411280494418\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 4.694108791524344e-06. Weight decay is 1.7237375606873107. dropout is 0.8546539158580123\n",
      " Val aus is 0.5181411280494418. Train auc is 0.5164913483183406\n",
      "This is round you consume 0:01:47.036630 time to run this model.\n",
      "You have finished 8!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.80019969]\n",
      "  acc for train: 0.47765265358696263, acc for val: 0.47799100225876906\n",
      "  auc for train: 0.4736804073240229, auc for val: 0.4698906619733687\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.69732028]\n",
      "  acc for train: 0.5134359424293902, acc for val: 0.5155127032425469\n",
      "  auc for train: 0.47564858074878597, auc for val: 0.48429096619934564\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.69822687]\n",
      "  acc for train: 0.514686665795516, acc for val: 0.5166700890440367\n",
      "  auc for train: 0.47563473045038396, auc for val: 0.484276248772537\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.67854226]\n",
      "  acc for train: 0.6804938490544905, acc for val: 0.6830816330340309\n",
      "  auc for train: 0.4868810196301742, auc for val: 0.4973743576806735\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.67850912]\n",
      "  acc for train: 0.6936031100076537, acc for val: 0.6964382385334802\n",
      "  auc for train: 0.48665003464209405, auc for val: 0.4972150847004076\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.66934454]\n",
      "  acc for train: 0.9449145027907931, acc for val: 0.9453041871231496\n",
      "  auc for train: 0.5149390608165261, auc for val: 0.5219758672491209\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.66969478]\n",
      "  acc for train: 0.9472106068808452, acc for val: 0.9474136160839292\n",
      "  auc for train: 0.5198333335882801, auc for val: 0.5285480127519424\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.66838169]\n",
      "  acc for train: 0.9608518919524351, acc for val: 0.9611249043289962\n",
      "  auc for train: 0.5753621178898125, auc for val: 0.5705672323330836\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.66860604]\n",
      "  acc for train: 0.9610992364987213, acc for val: 0.9614702533181504\n",
      "  auc for train: 0.5737485024731042, auc for val: 0.5693169239011252\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.6691218]\n",
      "  acc for train: 0.9624176295992085, acc for val: 0.9628143142489126\n",
      "  auc for train: 0.5577496474875827, auc for val: 0.5530775352335148\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.0009560008926958795. Weight decay is 77.6854555033499. dropout is 0.3261348398645527\n",
      " Val aus is 0.5530775352335148. Train auc is 0.5577496474875827\n",
      "This is round you consume 0:01:45.638367 time to run this model.\n",
      "You have finished 9!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 0.88383162]\n",
      "  acc for train: 0.8801989023502399, acc for val: 0.882693348765144\n",
      "  auc for train: 0.5045674019883559, auc for val: 0.5056901837163883\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.81579244]\n",
      "  acc for train: 0.1161095969683959, acc for val: 0.11458119434747709\n",
      "  auc for train: 0.4917932093017904, auc for val: 0.488929861289618\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.8174814]\n",
      "  acc for train: 0.12382161324646718, acc for val: 0.12234687972521421\n",
      "  auc for train: 0.49142103947980537, auc for val: 0.4884512391928028\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.77820855]\n",
      "  acc for train: 0.15764481323153318, acc for val: 0.1552857062853516\n",
      "  auc for train: 0.4927367761656457, auc for val: 0.4890144808553868\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.77224016]\n",
      "  acc for train: 0.1597845769008195, acc for val: 0.1573391327073494\n",
      "  auc for train: 0.49254650279660034, auc for val: 0.4888150588450487\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.73789227]\n",
      "  acc for train: 0.2125669697026265, acc for val: 0.21027086561257444\n",
      "  auc for train: 0.4934995231503793, auc for val: 0.4893655164189449\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.72509956]\n",
      "  acc for train: 0.21633314043569976, acc for val: 0.21417237581437026\n",
      "  auc for train: 0.49331683812721483, auc for val: 0.48887247385004196\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.71145785]\n",
      "  acc for train: 0.29121320166514214, acc for val: 0.2880583919804364\n",
      "  auc for train: 0.49504897622069577, auc for val: 0.49038255752020465\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.70892274]\n",
      "  acc for train: 0.30694524818458435, acc for val: 0.30403778304616474\n",
      "  auc for train: 0.4950831815556588, auc for val: 0.49049822827541406\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.68030953]\n",
      "  acc for train: 0.3971700050402285, acc for val: 0.3963486344714294\n",
      "  auc for train: 0.4970660095400657, auc for val: 0.4935527358606351\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 9.721037716294921e-05. Weight decay is 23.228723711213792. dropout is 0.8711181021149221\n",
      " Val aus is 0.4935527358606351. Train auc is 0.4970660095400657\n",
      "This is round you consume 0:01:44.488041 time to run this model.\n",
      "You have finished 10!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.86337918]\n",
      "  acc for train: 0.9372468218559241, acc for val: 0.9375291679889488\n",
      "  auc for train: 0.46489711783913357, auc for val: 0.4511192932619976\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.82211828]\n",
      "  acc for train: 0.3941668688980567, acc for val: 0.3943698781011406\n",
      "  auc for train: 0.45964536080059415, auc for val: 0.45765028735594165\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.81626534]\n",
      "  acc for train: 0.4012861916406877, acc for val: 0.4015195355522784\n",
      "  auc for train: 0.45957801000862564, auc for val: 0.457515608992637\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.75835013]\n",
      "  acc for train: 0.5321337900651496, acc for val: 0.533648192051373\n",
      "  auc for train: 0.4598892371572382, auc for val: 0.45784647669463263\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.76508415]\n",
      "  acc for train: 0.5490162220687338, acc for val: 0.5512516567417723\n",
      "  auc for train: 0.45983588986365087, auc for val: 0.4578023795450411\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.71156365]\n",
      "  acc for train: 0.6858980940469301, acc for val: 0.6874124960331535\n",
      "  auc for train: 0.4603537331552517, auc for val: 0.45860407459566743\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.73453969]\n",
      "  acc for train: 0.6850697231607833, acc for val: 0.6867778005936269\n",
      "  auc for train: 0.46040018026613305, auc for val: 0.4587006638173447\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.69025815]\n",
      "  acc for train: 0.8149349437174486, acc for val: 0.8161623326924153\n",
      "  auc for train: 0.4608711816206705, auc for val: 0.45900692813156474\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.68889129]\n",
      "  acc for train: 0.8189087905318374, acc for val: 0.8202038492411656\n",
      "  auc for train: 0.4612501584841029, auc for val: 0.4594644301069526\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.65261751]\n",
      "  acc for train: 0.8892503126808415, acc for val: 0.8890123018910191\n",
      "  auc for train: 0.46172427052479265, auc for val: 0.45995041342311926\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 1.0693635900636876e-05. Weight decay is 0.07218981973285646. dropout is 0.7898811709436281\n",
      " Val aus is 0.45995041342311926. Train auc is 0.46172427052479265\n",
      "This is round you consume 0:01:44.453405 time to run this model.\n",
      "You have finished 11!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.91866952]\n",
      "  acc for train: 0.8837713976366929, acc for val: 0.8849334503164143\n",
      "  auc for train: 0.5255269471153263, auc for val: 0.5228546715423174\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.68149912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5, auc for val: 0.5\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.68196046]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5, auc for val: 0.5\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-123:\n",
      "Process Process-124:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-648351dddc7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                              weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mdescribe\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}'\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competition_husky/safe_driver_prediction/MY_NN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competition_husky/safe_driver_prediction/MY_NN.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, X_tensor)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mX_Variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competition_husky/safe_driver_prediction/MY_NN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# return out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m         return F.batch_norm(\n\u001b[1;32m     36\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             self.training, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m    637\u001b[0m                training=False, momentum=0.1, eps=1e-5):\n\u001b[1;32m    638\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from MY_NN import NeuralNetwork\n",
    "\n",
    "# #only use step decay for now\n",
    "# #coarse search\n",
    "# train_hist={}\n",
    "# for i in range(100):\n",
    "#     #learnning_rate 5e-4 too large\n",
    "#     weight_decay = 10** (np.random.uniform(-5,3))#L2 \n",
    "#     learning_rate = 10** (np.random.uniform(-6,-2))\n",
    "    \n",
    "#     nn_model = NeuralNetwork(data,learning_rate = learning_rate,num_epochs=5,verbose=None,\n",
    "#                              weight_decay=weight_decay,batchnorm=True)\n",
    "#     print('Learning rate is {}. Weight decay is {}'.format(learning_rate, weight_decay))\n",
    "#     describe= 'Learning rate is {}. Weight decay is {}'.format(learning_rate, weight_decay)\n",
    "#     nn_model.train()\n",
    "#     train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "#     if i+1 %10 ==0:\n",
    "#         print('You have finished {}!!'.format(i+1))\n",
    "\n",
    "        \n",
    "# filename= 'coarse_search_lr_wd.pkl'\n",
    "# with open(filename, 'wb') as f:\n",
    "#     pickle.dump(train_hist, f)\n",
    "    \n",
    "    \n",
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "#only use step decay for now\n",
    "#coarse search\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "input_size = 235\n",
    "hidden_size= [230,220,210]\n",
    "lr_decay = {'step_size': 25, 'gamma':0.1}\n",
    "\n",
    "train_hist={}\n",
    "for i in range(20):\n",
    "    #learnning_rate 5e-4 too large\n",
    "    tic = datetime.now()\n",
    "    dropout = np.random.uniform(0,1)\n",
    "    weight_decay = 10** (np.random.uniform(-3,3))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-6,-2))\n",
    "    \n",
    "    nn_model = NeuralNetwork(input_size = input_size, hidden_size=hidden_size,\n",
    "                             learning_rate = learning_rate,num_epochs=5, batch_size=4096,\n",
    "                             verbose=True,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n",
    "    nn_model.train(data)\n",
    "    describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "    train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "    print(describe)\n",
    "    toc = datetime.now()\n",
    "    print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "    print('You have finished {}!!'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose the best and plot it to see how it's going.\n",
    "\n",
    "lr =0.0021465415548623146\n",
    "wd = 0.0804501958708467\n",
    "nn_model = NeuralNetwork(data,learning_rate = lr,num_epochs=8,verbose=True,\n",
    "                             weight_decay=wd,batchnorm=True)\n",
    "nn_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is 0.0009560008926958795. Weight decay is 77.6854555033499. dropout is 0.3261348398645527\n",
      " Val aus is 0.5530775352335148. Train auc is 0.5577496474875827\n",
      "Learning rate is 0.0013127261406181013. Weight decay is 1.5989822278254577. dropout is 0.5575533337122203\n",
      " Val aus is 0.5423198705740515. Train auc is 0.5442397793810851\n",
      "Learning rate is 0.007879870282127468. Weight decay is 0.0028137803098194584. dropout is 0.9809761910397172\n",
      " Val aus is 0.5358795967738799. Train auc is 0.5353599499477891\n",
      "Learning rate is 4.051427101042863e-06. Weight decay is 2.080845035520147. dropout is 0.12910294315844584\n",
      " Val aus is 0.5321230719394038. Train auc is 0.5190528058213246\n",
      "Learning rate is 4.694108791524344e-06. Weight decay is 1.7237375606873107. dropout is 0.8546539158580123\n",
      " Val aus is 0.5181411280494418. Train auc is 0.5164913483183406\n",
      "Learning rate is 5.675065563963184e-06. Weight decay is 5.260775415682158. dropout is 0.7723558241169411\n",
      " Val aus is 0.5036813727365234. Train auc is 0.5073190942125602\n",
      "Learning rate is 8.903006523444832e-05. Weight decay is 1.1966463072220914. dropout is 0.3989469315014088\n",
      " Val aus is 0.4990736090259961. Train auc is 0.4879085338988566\n",
      "Learning rate is 0.0004461874190716296. Weight decay is 70.56862850945058. dropout is 0.8865398044741222\n",
      " Val aus is 0.49688463799751015. Train auc is 0.49643043453808233\n",
      "Learning rate is 9.721037716294921e-05. Weight decay is 23.228723711213792. dropout is 0.8711181021149221\n",
      " Val aus is 0.4935527358606351. Train auc is 0.4970660095400657\n",
      "Learning rate is 6.354276310216332e-06. Weight decay is 262.6684327051769. dropout is 0.9914665992393943\n",
      " Val aus is 0.4772871425051074. Train auc is 0.48437300271662753\n",
      "Learning rate is 1.0693635900636876e-05. Weight decay is 0.07218981973285646. dropout is 0.7898811709436281\n",
      " Val aus is 0.45995041342311926. Train auc is 0.46172427052479265\n"
     ]
    }
   ],
   "source": [
    "a =sorted(train_hist, key=lambda x:x[0],reverse=True)\n",
    "for i in a:\n",
    "    print(train_hist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAALJCAYAAADielEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc83ee3f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_vis(nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finer search here but should cost considerable time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is 0.00020406927268633738. Weight decay is 0.0008021124318505044\n",
      "Val aus is 0.6317421740076681. Train auc is 0.6791059413712075\n",
      "Learning rate is 0.00015493820527177172. Weight decay is 0.0008104257925743996\n",
      "Val aus is 0.6330116090802047. Train auc is 0.6654130268843802\n",
      "Learning rate is 0.00011280697210265712. Weight decay is 0.00022878098723526239\n",
      "Val aus is 0.6150286814657072. Train auc is 0.6313906017203497\n",
      "Learning rate is 7.651260359148915e-06. Weight decay is 2.6327288973450546e-05\n",
      "Val aus is 0.5515363038949513. Train auc is 0.5470427497716127\n",
      "Learning rate is 5.55017362248129e-05. Weight decay is 0.0006954451651473917\n",
      "Val aus is 0.6209540032022394. Train auc is 0.6257346869824794\n",
      "Learning rate is 3.513556802668994e-06. Weight decay is 0.00010345946256136488\n",
      "Val aus is 0.530607868619493. Train auc is 0.5191439264170947\n",
      "Learning rate is 0.00041679711472788464. Weight decay is 0.00017450057767011\n",
      "Val aus is 0.6299209582212122. Train auc is 0.7003492741546931\n",
      "Learning rate is 0.00046931647302294216. Weight decay is 0.0005242045085095721\n",
      "Val aus is 0.6284672207696417. Train auc is 0.7037803306035294\n",
      "Learning rate is 0.0007480411204707365. Weight decay is 0.00013297987797352255\n",
      "Val aus is 0.6254457315422669. Train auc is 0.7189093244563526\n",
      "Learning rate is 0.0005948852474826226. Weight decay is 0.0005612195248733336\n"
     ]
    }
   ],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "train_hist={}\n",
    "best_net = None\n",
    "best_auc =0\n",
    "for i in range(10):\n",
    "    #learnning_rate 5e-4 too large\n",
    "    weight_decay = 10** (np.random.uniform(-5,-3))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-5.5,-3))\n",
    "    dropout = np.random.uniform(0,1)\n",
    "    nn_model = NeuralNetwork(data,learning_rate = learning_rate,num_epochs=80,verbose=None,dropout=dropout,\n",
    "                             weight_decay=weight_decay,batchnorm=True)\n",
    "    print('Learning rate is {}. Weight decay is {}'.format(learning_rate, weight_decay))\n",
    "    describe= 'Learning rate is {}. Weight decay is {}'.format(learning_rate, weight_decay)\n",
    "    nn_model.train()\n",
    "    print('Val aus is {}. Train auc is {}'.format(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1]))\n",
    "    if nn_model.auc_history['val'][-1]> best_auc:\n",
    "        best_auc =nn_model.auc_history['val'][-1]\n",
    "        best_net = nn_model\n",
    "    train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "    if (i+1) %10 ==0:\n",
    "        print('You have finished {}!!'.format(i+1))\n",
    "\n",
    "train_hist['best_net'] = best_net\n",
    "filename= 'search_lr_wd.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 0.96388286]\n",
      "  acc for train: 0.43534506897646025, acc for val: 0.4365957923425862\n",
      "  auc for train: 0.46641468653097995, auc for val: 0.4694342688795342\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.63663191]\n",
      "  acc for train: 0.8803925777968601, acc for val: 0.8812652840262092\n",
      "  auc for train: 0.5210164423005953, auc for val: 0.5161746400086831\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.45769787]\n",
      "  acc for train: 0.9634326756146279, acc for val: 0.9639250312680842\n",
      "  auc for train: 0.5328574174698167, auc for val: 0.5266127325223127\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.35054463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5385647540666245, auc for val: 0.5334625369541983\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.28321517]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5381127645821319, auc for val: 0.5351305491640541\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.26585665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5383247945897658, auc for val: 0.5361717450885745\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.23649496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5388659136886669, auc for val: 0.5375353924920464\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.19210169]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.539700480622576, auc for val: 0.5395077106185315\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.19306733]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5402410461300294, auc for val: 0.5403708201655841\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.18179266]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5437046176125472, auc for val: 0.5442375452729399\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.16861475]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5439648702121508, auc for val: 0.5441813230987249\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.16604416]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5482940262136249, auc for val: 0.5471999781000279\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.17256184]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5488250069831402, auc for val: 0.5482692118127055\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.1600001]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5511139970094885, auc for val: 0.5496321675748018\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.1667404]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5543011332750472, auc for val: 0.5533454247281478\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.18265635]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5546307761896491, auc for val: 0.553618740851038\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.17564861]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.555781672944528, auc for val: 0.5548447290672331\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.17820887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5595637759373198, auc for val: 0.5577635621752117\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.17906691]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5637497971675178, auc for val: 0.5617780053411554\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.19748439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5646040256414129, auc for val: 0.5633606148768011\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.17283474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5653359095551043, auc for val: 0.5642541716800643\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.15941714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5691205612946704, auc for val: 0.5673109534121997\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.17626843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5719771810501869, auc for val: 0.5700469939742199\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.15491308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.574190160852859, auc for val: 0.5718262125946811\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.17707901]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.576863273700561, auc for val: 0.5750557981679804\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.22013016]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5776004878450043, auc for val: 0.5758284630754321\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.1902959]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5808161684666863, auc for val: 0.5787942651482793\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.19321831]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5823809930910991, auc for val: 0.5805494128947052\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 300, the loss is [ 0.15423577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5843784169677513, auc for val: 0.5816539917370307\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.18230116]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5851784401663402, auc for val: 0.5815656295393976\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.16687998]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5846053165715284, auc for val: 0.58183695969928\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.18872426]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.588103699309612, auc for val: 0.5849085879144951\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.15764053]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5903533753768748, auc for val: 0.5876596077747868\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.15410705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.592665444570389, auc for val: 0.5895194176511931\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.16872516]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.595482227616337, auc for val: 0.592469813161803\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.1569102]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5965923349154612, auc for val: 0.5935479417334041\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.17336418]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5975215492137784, auc for val: 0.5946412701266137\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.1538175]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6006628838644317, auc for val: 0.5979568460186977\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 300, the loss is [ 0.15632018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6035827566603094, auc for val: 0.6008125593333073\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.18321206]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6090953660354035, auc for val: 0.6070414101428947\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.13602434]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6090755448798993, auc for val: 0.6073512892856812\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.15391308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6078402098928137, auc for val: 0.606563073724039\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.17425214]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6101721415177092, auc for val: 0.6081981252128301\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.14944799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6107643576019294, auc for val: 0.608497840234531\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 400, the loss is [ 0.14402528]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6115619674757233, auc for val: 0.610986558862029\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 0, the loss is [ 0.16321748]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6139510098421255, auc for val: 0.6136712889059801\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.15570393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6163597710245906, auc for val: 0.6150441506766198\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.20813507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6151537722102703, auc for val: 0.6139607972054961\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.1457784]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6137912970862425, auc for val: 0.6114843915486475\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.15647461]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6127867461185462, auc for val: 0.6106959792701647\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.15343946]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6145621168286978, auc for val: 0.6124608638737106\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.13971567]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6146298963023429, auc for val: 0.6124346215965881\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.17039542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.618049938507484, auc for val: 0.615628291937294\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.15597004]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6162608552397792, auc for val: 0.6151096786850683\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.1421611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6180260086243905, auc for val: 0.6156939865912188\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 0, the loss is [ 0.14657588]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187103267272531, auc for val: 0.6163218791807967\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.18852615]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6141472287152995, auc for val: 0.6136550115271557\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.15463713]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6194132362118228, auc for val: 0.6183813102903286\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.1724001]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6135108477515698, auc for val: 0.6124847417898259\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.14499983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187197654537075, auc for val: 0.616490257519535\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.18036851]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6184496207886603, auc for val: 0.615580993440393\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 100, the loss is [ 0.16675496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6193558009831758, auc for val: 0.6166276222580379\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.14156191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6146306293742908, auc for val: 0.6126242278124755\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.13646029]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6157533541834899, auc for val: 0.6142570728149215\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.15638264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6239308109505078, auc for val: 0.620265897717828\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.15997514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6264678603422097, auc for val: 0.6221465219901261\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.13045749]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621698326286133, auc for val: 0.6181389538898131\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 200, the loss is [ 0.13245548]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.623359232109268, auc for val: 0.6200201833483149\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.16689554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.624943279234373, auc for val: 0.6221362275597957\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.16730256]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6242355075442143, auc for val: 0.6207378527426146\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.14993529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621256273775857, auc for val: 0.617978391599809\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.1801305]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6232797344604397, auc for val: 0.6206051791369206\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.11670103]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6226702846153152, auc for val: 0.6196630357799916\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.12997773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6228369716804327, auc for val: 0.618685859283818\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.1768474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6253411834064088, auc for val: 0.619595415305787\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.14106265]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.62602371080094, auc for val: 0.6207027832671382\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.16962788]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268588709789654, auc for val: 0.6215036927033759\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 200, the loss is [ 0.14117277]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.623461078790549, auc for val: 0.6192977576665841\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.13755955]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6270790505761974, auc for val: 0.6236725008821936\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.14386225]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276589311248751, auc for val: 0.6225686249580054\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.16202977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274329221988771, auc for val: 0.6214527593303324\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.12860292]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.627400343860058, auc for val: 0.6216069402262674\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.16169819]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6294742946045133, auc for val: 0.6241616241499677\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 300, the loss is [ 0.12861703]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273431859682046, auc for val: 0.6216547749958291\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.15848528]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271481009449256, auc for val: 0.6194590930412418\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.14947848]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274787405869386, auc for val: 0.619954508741966\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.15718378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291224149680387, auc for val: 0.6216572759309482\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.14947823]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312681325595576, auc for val: 0.6229153540516211\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.11146899]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.632860778207398, auc for val: 0.6246263495176212\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.16322629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343023374485246, auc for val: 0.6252818889676224\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.1542685]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343954898377596, auc for val: 0.6247513423957198\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.16573492]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341772819752722, auc for val: 0.6231563083747826\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.15205076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6317388334659022, auc for val: 0.6215273563610217\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 300, the loss is [ 0.15458079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.632997211291198, auc for val: 0.6234646463601561\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.14919011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353497780720911, auc for val: 0.6265941419038004\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.14959593]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331379653564435, auc for val: 0.6245522223519968\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.15470241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335742295046481, auc for val: 0.6243659327569815\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.1737093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319417384128306, auc for val: 0.623095882474453\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.14675422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358510746838234, auc for val: 0.6257713405144553\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 400, the loss is [ 0.13503832]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6351128585558647, auc for val: 0.6240452479706741\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 0, the loss is [ 0.15876572]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633104301091033, auc for val: 0.6227842241092871\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.1643507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371876772531776, auc for val: 0.6270384701157399\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.15111077]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6360860591034435, auc for val: 0.6263453351956729\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.15367527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6369566688445154, auc for val: 0.6269504349441922\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.15759331]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6377156019845656, auc for val: 0.627889995922724\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.16278806]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6375084844246933, auc for val: 0.6268414989215808\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.18399349]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6372680721499151, auc for val: 0.627235913680911\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.14086421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6366488145689013, auc for val: 0.6265896800651434\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.15637629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637025623366637, auc for val: 0.6268888638260774\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.18616274]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368207869559979, auc for val: 0.6257319520393017\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 0, the loss is [ 0.15989184]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394228307044718, auc for val: 0.627724633491216\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.16831556]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397839539731796, auc for val: 0.6285584397468696\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.16448854]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412085717082558, auc for val: 0.630125823148463\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.17586648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399002884873867, auc for val: 0.6278415509550646\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.13990514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380008744132282, auc for val: 0.6270388673083415\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.18364224]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6392836453544499, auc for val: 0.6272383657500634\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 100, the loss is [ 0.15869644]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6424636580528732, auc for val: 0.6311090151704418\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.17769535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6417339873455379, auc for val: 0.6288461963894236\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.17808154]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639516548975163, auc for val: 0.6277352424178964\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.18508072]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409010409149383, auc for val: 0.6293027486108934\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.14584696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433862936410942, auc for val: 0.6308587988671195\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.12991081]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643813771901907, auc for val: 0.629644985794488\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 200, the loss is [ 0.16287664]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429920629448409, auc for val: 0.6296061486276772\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.17248602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422047663204895, auc for val: 0.6301863542985671\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.12774318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429416878236005, auc for val: 0.631165084481889\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.12718853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427159989788904, auc for val: 0.630062492855545\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.12756006]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64076629279902, auc for val: 0.6265728701725787\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.17339201]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6439818049161841, auc for val: 0.630164611449307\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.13919944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.646838637002852, auc for val: 0.6338327515326272\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.13727504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6462169611501217, auc for val: 0.6325895411955837\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.14273988]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6443071803379307, auc for val: 0.6315044849334648\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.14557837]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.646651088769255, auc for val: 0.6327054775811766\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 200, the loss is [ 0.14873542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407942844912433, auc for val: 0.6261733733527057\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.17443523]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6439902445190622, auc for val: 0.6288730300700409\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.14894634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436499141667744, auc for val: 0.6297408081963793\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.16958211]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6448029220204555, auc for val: 0.6307656114685126\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.17017768]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6445717411651973, auc for val: 0.6295598086555089\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.14546952]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6465422493050791, auc for val: 0.6312338927749779\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 300, the loss is [ 0.12959281]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6463968019252405, auc for val: 0.6310005740723656\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.17139147]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6494408787827821, auc for val: 0.6335584305249846\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.16347478]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6493730731059115, auc for val: 0.6322269720108973\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.16536799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6486261436711768, auc for val: 0.6330553679269495\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.18812957]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6469505739356243, auc for val: 0.6312581478361188\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.11982883]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6499312812682597, auc for val: 0.6342039161155688\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.16739157]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64880020095385, auc for val: 0.6321403739999617\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.12575097]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6491918665166512, auc for val: 0.6320603390642536\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.15028465]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.649829712619433, auc for val: 0.6328063081181736\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 200, the loss is [ 0.15579619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6498620669554572, auc for val: 0.6324648765965438\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 300, the loss is [ 0.1464572]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6508310603780836, auc for val: 0.6339826034050968\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 400, the loss is [ 0.16893944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6478166087790395, auc for val: 0.6280932432611778\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 0, the loss is [ 0.13606025]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517124762829603, auc for val: 0.632821247321293\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 100, the loss is [ 0.13336651]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519049797088136, auc for val: 0.6329728871869567\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 200, the loss is [ 0.16220525]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514194861927936, auc for val: 0.632688685230241\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 300, the loss is [ 0.16195978]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521427486269415, auc for val: 0.633321242640184\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 400, the loss is [ 0.18410546]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6524861269013136, auc for val: 0.6336320377066038\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 0, the loss is [ 0.13743696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6525489933088316, auc for val: 0.6337507206101232\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 100, the loss is [ 0.14711069]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6522512573430298, auc for val: 0.6334370098743534\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 200, the loss is [ 0.15588121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6528217345666609, auc for val: 0.6338692857341328\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 300, the loss is [ 0.1214186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6529018967261953, auc for val: 0.6338709484299762\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 400, the loss is [ 0.13872708]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6533324853639778, auc for val: 0.6342006157833524\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 0, the loss is [ 0.15164171]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6530366465426178, auc for val: 0.6339932862572142\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 100, the loss is [ 0.12067741]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6529345163408914, auc for val: 0.6337989575841805\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 200, the loss is [ 0.18278855]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6537747687563614, auc for val: 0.6347810194240564\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 300, the loss is [ 0.17340234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6537523958395527, auc for val: 0.6344441950860104\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 400, the loss is [ 0.14560066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6533190628970005, auc for val: 0.6339284461312207\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 0, the loss is [ 0.15282324]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6534647231490599, auc for val: 0.6340081941359959\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 100, the loss is [ 0.167539]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6535152847074092, auc for val: 0.6339616950361922\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 200, the loss is [ 0.16867645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6537423897630247, auc for val: 0.6339806349837179\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 300, the loss is [ 0.15445772]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6540171584084669, auc for val: 0.6343357640117221\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 400, the loss is [ 0.12816384]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6540217381757494, auc for val: 0.6342652466627702\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 0, the loss is [ 0.17336862]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6543961752337503, auc for val: 0.6345241084832882\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 100, the loss is [ 0.15659039]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6546479471864854, auc for val: 0.6346378947663437\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 200, the loss is [ 0.17279351]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6548561675234009, auc for val: 0.6348250714666017\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 300, the loss is [ 0.14513145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6543158815170192, auc for val: 0.6344273313155848\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 400, the loss is [ 0.139401]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6543073163860048, auc for val: 0.6342226618522011\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 0, the loss is [ 0.11815596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.654561375207851, auc for val: 0.6344673262299159\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 100, the loss is [ 0.1500929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6547134086408726, auc for val: 0.6345461169629317\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 200, the loss is [ 0.13842703]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6549207068406795, auc for val: 0.6346894596380346\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 300, the loss is [ 0.15832052]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6550046823811234, auc for val: 0.6346050255123448\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 400, the loss is [ 0.12525477]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6551223722745592, auc for val: 0.6346431071361311\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 0, the loss is [ 0.13735898]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.655465006037227, auc for val: 0.6349116657186168\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 100, the loss is [ 0.15141906]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6552380411186255, auc for val: 0.6346902439994497\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 200, the loss is [ 0.16827235]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6557432691417253, auc for val: 0.6349888175622862\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 300, the loss is [ 0.17265323]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6561149298172615, auc for val: 0.6355444273632413\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 400, the loss is [ 0.12214474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6559203399499186, auc for val: 0.6352090514625689\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 0, the loss is [ 0.14459829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.655833054841614, auc for val: 0.6349652127943951\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 100, the loss is [ 0.14725827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6552657185267344, auc for val: 0.6344434646024559\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 200, the loss is [ 0.12199733]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6558527761311378, auc for val: 0.6345964564265332\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 300, the loss is [ 0.11667851]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6556974802033066, auc for val: 0.6343961648525815\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 400, the loss is [ 0.14200793]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6562363229453052, auc for val: 0.6349183691268772\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 0, the loss is [ 0.15161608]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6564593418436613, auc for val: 0.6350328746167254\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 100, the loss is [ 0.14840356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6563331723082003, auc for val: 0.6348717898367691\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 200, the loss is [ 0.15138702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6565676640453453, auc for val: 0.6350254858319571\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 300, the loss is [ 0.13404694]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6565521458614001, auc for val: 0.6347057796179582\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 400, the loss is [ 0.14480501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6567096521356485, auc for val: 0.6347952995631112\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 0, the loss is [ 0.15640117]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6566616053139875, auc for val: 0.6347086602040498\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 100, the loss is [ 0.12120549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6561760670437861, auc for val: 0.6340087792746234\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 200, the loss is [ 0.18062577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6563932462557587, auc for val: 0.6340938035508347\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 300, the loss is [ 0.13715008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6571757528686586, auc for val: 0.6347488405584597\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 400, the loss is [ 0.13674502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6574096781832777, auc for val: 0.6350412707921932\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 0, the loss is [ 0.12805067]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6574919885435263, auc for val: 0.6351573349810837\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 100, the loss is [ 0.12733939]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.657733355264995, auc for val: 0.6350889802644044\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 200, the loss is [ 0.16350387]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6577144367680957, auc for val: 0.6351034145192004\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 300, the loss is [ 0.16156903]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6576422041374431, auc for val: 0.6348682188622752\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 400, the loss is [ 0.14749761]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6570085282122928, auc for val: 0.6344295340430095\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 0, the loss is [ 0.13185717]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6573572280603038, auc for val: 0.6344786092563428\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 100, the loss is [ 0.131928]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6573560591181837, auc for val: 0.6347587741324201\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 200, the loss is [ 0.12908915]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6576425701323474, auc for val: 0.6347571841090403\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 300, the loss is [ 0.12025452]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6573863998252208, auc for val: 0.6343463478789324\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 400, the loss is [ 0.1657837]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6580137750727292, auc for val: 0.6348740075998758\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 0, the loss is [ 0.14923674]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6578327106301699, auc for val: 0.6347509129766397\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 100, the loss is [ 0.15432025]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6578559365044802, auc for val: 0.6345090740541824\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 200, the loss is [ 0.13459463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6580781512961855, auc for val: 0.6346445355259287\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 300, the loss is [ 0.14135003]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6582543279482956, auc for val: 0.6348955399495867\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 400, the loss is [ 0.17272034]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6586824720338404, auc for val: 0.6351312869148549\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 0, the loss is [ 0.15808085]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6586359187187355, auc for val: 0.6350889451811461\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 100, the loss is [ 0.14713787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6585067242179985, auc for val: 0.6348279771121634\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 200, the loss is [ 0.15926798]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6586722624378651, auc for val: 0.6351579978040687\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 300, the loss is [ 0.19064288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6592201717277618, auc for val: 0.6356018022730824\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 400, the loss is [ 0.1388202]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6589269553932267, auc for val: 0.6351234019525778\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 0, the loss is [ 0.13468476]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6588216802633748, auc for val: 0.6351959190472461\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 100, the loss is [ 0.18273884]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.659009489292496, auc for val: 0.6353409331890069\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 200, the loss is [ 0.13728036]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6590817397011483, auc for val: 0.6351292771453503\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 300, the loss is [ 0.17283112]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6591748454038104, auc for val: 0.6350476145970572\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 400, the loss is [ 0.15686035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6593621666200822, auc for val: 0.6351694412111046\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 0, the loss is [ 0.14657667]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6595294033345694, auc for val: 0.6352476217460229\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 100, the loss is [ 0.14400983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6596326601976953, auc for val: 0.6354074209751615\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 200, the loss is [ 0.17292447]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.659794277441107, auc for val: 0.6353911761736483\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 300, the loss is [ 0.15273194]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6597591083066798, auc for val: 0.6355157681002248\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 400, the loss is [ 0.13064499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6599860099974395, auc for val: 0.6354784307427013\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 0, the loss is [ 0.17426381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6598295108855151, auc for val: 0.6352357786404383\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 100, the loss is [ 0.15886514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6602541761257251, auc for val: 0.6355639862796796\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 200, the loss is [ 0.1394805]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6598959094723671, auc for val: 0.6353343939202758\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 300, the loss is [ 0.17220391]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.660264012229118, auc for val: 0.6354899418103065\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 400, the loss is [ 0.14530903]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6600710339760846, auc for val: 0.6352393583857467\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 0, the loss is [ 0.14796503]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6598088167529362, auc for val: 0.6350132016796981\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 100, the loss is [ 0.17519449]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.659978916266425, auc for val: 0.6352151158543409\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 200, the loss is [ 0.16136977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.659986501752367, auc for val: 0.634915878215546\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 300, the loss is [ 0.15900448]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6601546651644061, auc for val: 0.6349024613752373\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 400, the loss is [ 0.15860574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6602771919877534, auc for val: 0.6349451288820577\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 0, the loss is [ 0.15197082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6605128240676277, auc for val: 0.6351669427819324\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 100, the loss is [ 0.16275121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6604949972171982, auc for val: 0.6352302655570092\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 200, the loss is [ 0.14570932]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.660920669619732, auc for val: 0.6354678919825373\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 300, the loss is [ 0.16602191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6606323953371929, auc for val: 0.6352796226893815\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 400, the loss is [ 0.15267968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6603046339533115, auc for val: 0.6347969284286697\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 0, the loss is [ 0.16676706]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6605872385998982, auc for val: 0.6349573328440121\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 100, the loss is [ 0.15726909]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6607035174612369, auc for val: 0.6348913951132269\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 200, the loss is [ 0.1851248]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6608510705291821, auc for val: 0.6349362265052934\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 300, the loss is [ 0.15030107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6606384407845973, auc for val: 0.6349018436592986\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 400, the loss is [ 0.17383251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6610488664655101, auc for val: 0.6352439292330988\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 0, the loss is [ 0.18290454]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6611060232752245, auc for val: 0.6350636313573921\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 100, the loss is [ 0.14288951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6611598770872086, auc for val: 0.63506834003183\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 200, the loss is [ 0.11855413]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6616644867451057, auc for val: 0.635108562987339\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 300, the loss is [ 0.18191589]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6614140909641293, auc for val: 0.6351114849215564\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 400, the loss is [ 0.13867436]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6610998587152228, auc for val: 0.6348434212636059\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 0, the loss is [ 0.15093258]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.661309444402506, auc for val: 0.6350084754636314\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 100, the loss is [ 0.14946704]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6613844298404499, auc for val: 0.6349100243233232\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 200, the loss is [ 0.13721251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6613333265168877, auc for val: 0.6347715544621875\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 300, the loss is [ 0.17163725]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6618190743355972, auc for val: 0.6352485552112852\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 400, the loss is [ 0.14007276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6617773380854215, auc for val: 0.6349852478407658\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 0, the loss is [ 0.15163447]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6617663168851176, auc for val: 0.6349464520220807\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 100, the loss is [ 0.16360675]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.661408423260568, auc for val: 0.6345932688619323\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 200, the loss is [ 0.1230457]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6618600098801309, auc for val: 0.6350987459399148\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 300, the loss is [ 0.13937868]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6619861682850182, auc for val: 0.6352243101739323\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 400, the loss is [ 0.15979338]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6618619979242577, auc for val: 0.6348625178328201\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 0, the loss is [ 0.13169563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6621814985673959, auc for val: 0.634832900045071\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 100, the loss is [ 0.15829748]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6619521115122952, auc for val: 0.634564672247591\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 200, the loss is [ 0.16846205]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6623528885317671, auc for val: 0.6349588126057234\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 300, the loss is [ 0.13931811]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6625844636721376, auc for val: 0.6347409155010304\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 400, the loss is [ 0.17851749]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6622850764393575, auc for val: 0.6343926352262135\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 0, the loss is [ 0.15530837]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.662143192543591, auc for val: 0.6343461812334561\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 100, the loss is [ 0.1504434]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6627223342231472, auc for val: 0.6350117306888015\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 200, the loss is [ 0.17408456]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6628045456449632, auc for val: 0.6347332873983222\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 300, the loss is [ 0.11592411]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6623206476657576, auc for val: 0.6344085730492175\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 400, the loss is [ 0.12637722]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6623887122057612, auc for val: 0.6342284343011461\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 0, the loss is [ 0.17753069]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6623386359868008, auc for val: 0.6340696863167795\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 100, the loss is [ 0.14746629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6625638022356188, auc for val: 0.6343022093812152\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 200, the loss is [ 0.14771758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6627831369913926, auc for val: 0.6344981706787279\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 300, the loss is [ 0.14464614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6631033168314102, auc for val: 0.6344880742182116\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 400, the loss is [ 0.17558801]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6630028109977757, auc for val: 0.6341906358493723\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 0, the loss is [ 0.15343197]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.663233924605818, auc for val: 0.6346861079339045\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 100, the loss is [ 0.16128986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6633058897935205, auc for val: 0.6345179977314964\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 200, the loss is [ 0.1497016]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6631789992442332, auc for val: 0.6341087615485566\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 300, the loss is [ 0.16717288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6633893026989255, auc for val: 0.6343205692020073\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 400, the loss is [ 0.14175165]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6637467766853894, auc for val: 0.6347261379314935\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 0, the loss is [ 0.18589948]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6638868456019902, auc for val: 0.6348811119596581\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 100, the loss is [ 0.16384074]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6639123244126209, auc for val: 0.6347959648920433\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 200, the loss is [ 0.15932071]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6635257953776721, auc for val: 0.6340455452762277\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 300, the loss is [ 0.16196261]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.663946112814846, auc for val: 0.6343207045231462\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 400, the loss is [ 0.14321655]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6643384794491956, auc for val: 0.6350403598804539\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 0, the loss is [ 0.1587327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6641962110848643, auc for val: 0.6348843709437488\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 100, the loss is [ 0.14931785]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6644394295009326, auc for val: 0.6348776036338397\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 200, the loss is [ 0.12924281]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6642741938162415, auc for val: 0.6348829124825872\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 300, the loss is [ 0.15369336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6639143498678426, auc for val: 0.634473153809695\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 400, the loss is [ 0.13707678]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6643585716805454, auc for val: 0.6346810797512223\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 0, the loss is [ 0.14036013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6644657724769342, auc for val: 0.6348291173180545\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 100, the loss is [ 0.14638147]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651331328416596, auc for val: 0.6351532415166377\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 200, the loss is [ 0.14300735]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.664912616699166, auc for val: 0.6348700156262836\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 300, the loss is [ 0.18748599]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6640851142785156, auc for val: 0.6344827002148419\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 400, the loss is [ 0.14957976]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6647919835419566, auc for val: 0.6348800318964956\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 0, the loss is [ 0.11319157]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6646764243804182, auc for val: 0.6348418851180868\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 100, the loss is [ 0.15139657]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6647050250850706, auc for val: 0.6349055098597788\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 200, the loss is [ 0.14325242]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6647564756206942, auc for val: 0.634805399782548\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 300, the loss is [ 0.1438643]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.664726535691604, auc for val: 0.6347173520812652\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 400, the loss is [ 0.11620539]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648635637200248, auc for val: 0.6348957015831691\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 0, the loss is [ 0.14825115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6645930784130463, auc for val: 0.6347674171436687\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 100, the loss is [ 0.16153833]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6647925554524735, auc for val: 0.6348014453981612\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 200, the loss is [ 0.11324553]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648380638849771, auc for val: 0.6348587275879626\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 300, the loss is [ 0.11744325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648868315658731, auc for val: 0.6349057115885134\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 400, the loss is [ 0.14235155]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6649862735021763, auc for val: 0.6349820815767147\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 0, the loss is [ 0.16556248]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648559718185438, auc for val: 0.6347760551430233\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 100, the loss is [ 0.13003139]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648200372252914, auc for val: 0.6348242006500147\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 200, the loss is [ 0.11932897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.664906976358265, auc for val: 0.6348722997969862\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 300, the loss is [ 0.14890839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6648638672600437, auc for val: 0.6347849750614167\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 400, the loss is [ 0.12815721]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650850387923564, auc for val: 0.6349962126119221\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 0, the loss is [ 0.13658714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665073115319926, auc for val: 0.6348855637745272\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 100, the loss is [ 0.167189]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6649905958749434, auc for val: 0.6349867739624968\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 200, the loss is [ 0.15503065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650540363572568, auc for val: 0.6349074143795089\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 300, the loss is [ 0.17574918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6647558734875778, auc for val: 0.6346700473194968\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 400, the loss is [ 0.16191101]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6649578477948763, auc for val: 0.6349318185444971\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 0, the loss is [ 0.16561857]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6649489935781298, auc for val: 0.6349059083053539\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 100, the loss is [ 0.14629951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665092210514682, auc for val: 0.6349670571713968\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 200, the loss is [ 0.16787753]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650720137023175, auc for val: 0.6349197248442113\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 300, the loss is [ 0.17268896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650657931802648, auc for val: 0.6348555412763354\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 400, the loss is [ 0.1449488]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652005647940609, auc for val: 0.6350203361108447\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 0, the loss is [ 0.13254686]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650293560106939, auc for val: 0.6349046979329466\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 100, the loss is [ 0.1226358]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651884483916873, auc for val: 0.6349921454599197\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 200, the loss is [ 0.15822001]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651260871112442, auc for val: 0.6349624537467337\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 300, the loss is [ 0.16167544]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651401264748069, auc for val: 0.634988721083326\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 400, the loss is [ 0.1403264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650657240779535, auc for val: 0.6348644223525501\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 0, the loss is [ 0.16077609]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651612694632274, auc for val: 0.6348451616438067\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 100, the loss is [ 0.14042361]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651862704321476, auc for val: 0.6349584442315125\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 200, the loss is [ 0.14873977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651047307868287, auc for val: 0.6348975459601709\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 300, the loss is [ 0.14453503]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6650873251976934, auc for val: 0.6348814878517102\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 400, the loss is [ 0.12113326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651727698965634, auc for val: 0.6348908613465131\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 0, the loss is [ 0.15729558]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652424780512759, auc for val: 0.6349371787651583\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 100, the loss is [ 0.19274545]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652014535394486, auc for val: 0.6348511257976981\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 200, the loss is [ 0.15643083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651551042848605, auc for val: 0.6348596259699668\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 300, the loss is [ 0.15099595]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6651118599965467, auc for val: 0.6347617562093658\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 400, the loss is [ 0.17724574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652693171880569, auc for val: 0.6349855347716987\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 0, the loss is [ 0.15273753]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6653361376545684, auc for val: 0.6349078491613156\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 100, the loss is [ 0.14030449]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6654183549508539, auc for val: 0.63497958941241\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 200, the loss is [ 0.14902261]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652494426212585, auc for val: 0.6349388677734452\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 300, the loss is [ 0.16701064]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652923781134493, auc for val: 0.6348812999056841\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 400, the loss is [ 0.17315805]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652808579697225, auc for val: 0.6348399592978072\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 0, the loss is [ 0.16832104]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665436859220363, auc for val: 0.6349681434994271\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 100, the loss is [ 0.14585838]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6652745974858187, auc for val: 0.6347947758201854\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 200, the loss is [ 0.15451501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665416918256601, auc for val: 0.6349176687146869\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 300, the loss is [ 0.16481081]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.66523148869678, auc for val: 0.634932745744892\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 400, the loss is [ 0.17883734]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6654113169500034, auc for val: 0.6349493012838348\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 0, the loss is [ 0.17301202]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6653616902825452, auc for val: 0.6348273706729863\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 100, the loss is [ 0.13609441]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6653949230836356, auc for val: 0.6349891320586363\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 200, the loss is [ 0.15097551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6654368420607286, auc for val: 0.635003226757612\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 300, the loss is [ 0.13358028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6654548149999373, auc for val: 0.6349339085043061\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 400, the loss is [ 0.14231737]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655145189332176, auc for val: 0.6349153745201963\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 0, the loss is [ 0.11813228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6653676550332908, auc for val: 0.6349055236424874\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 100, the loss is [ 0.18390839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655600182448345, auc for val: 0.6349361701214855\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 200, the loss is [ 0.13800529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655741767982901, auc for val: 0.6351366521474101\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 300, the loss is [ 0.17814086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655748272411877, auc for val: 0.6349495656612445\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 400, the loss is [ 0.1413094]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656484464012161, auc for val: 0.6349782963437511\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 0, the loss is [ 0.1659932]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656199644999784, auc for val: 0.6349806030679768\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 100, the loss is [ 0.1684428]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656351648442093, auc for val: 0.6350517017966357\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 200, the loss is [ 0.13797933]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656302718749515, auc for val: 0.635008247422453\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 300, the loss is [ 0.13277356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656274122450714, auc for val: 0.6349295970224698\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 400, the loss is [ 0.16537061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656624876971701, auc for val: 0.6350160471825317\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 0, the loss is [ 0.15646537]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657088306135149, auc for val: 0.635008521823651\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 100, the loss is [ 0.19060238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655743388099732, auc for val: 0.6348522847981917\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 200, the loss is [ 0.16306312]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6655801423219921, auc for val: 0.6348705080448718\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 300, the loss is [ 0.15904258]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657031291317544, auc for val: 0.6350230563163276\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 400, the loss is [ 0.18205537]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657656708975411, auc for val: 0.6348608401012947\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 0, the loss is [ 0.1536527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656607236558382, auc for val: 0.6348604541854547\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 100, the loss is [ 0.13777389]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665841138505752, auc for val: 0.6350036176853462\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 200, the loss is [ 0.15707913]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656331255530663, auc for val: 0.6348820955438608\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 300, the loss is [ 0.15348805]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658601772746833, auc for val: 0.6349990405731265\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 400, the loss is [ 0.16732743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665869846032993, auc for val: 0.6349650160775546\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 0, the loss is [ 0.14748378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665722838981522, auc for val: 0.6349879191802819\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 100, the loss is [ 0.16767153]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658388071143464, auc for val: 0.6349075271471245\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 200, the loss is [ 0.17082788]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658589786510334, auc for val: 0.6349089054179817\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 300, the loss is [ 0.13648954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657660300131327, auc for val: 0.634929345174795\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 400, the loss is [ 0.13671337]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6659785817664063, auc for val: 0.6350485154850084\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 0, the loss is [ 0.15425931]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658826725505064, auc for val: 0.6349890781807755\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 100, the loss is [ 0.14666693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658713165054452, auc for val: 0.6349396771943305\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 200, the loss is [ 0.13050027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6656819966555425, auc for val: 0.6348504729985012\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 300, the loss is [ 0.15261956]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657900768445452, auc for val: 0.6349159822123471\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 400, the loss is [ 0.16681609]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658023756646536, auc for val: 0.6348039400684128\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 0, the loss is [ 0.15316153]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658898067844417, auc for val: 0.6350020439506219\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 100, the loss is [ 0.11443379]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6657366246607602, auc for val: 0.6348193867258023\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 200, the loss is [ 0.14515038]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658239211315254, auc for val: 0.6348446892727946\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 300, the loss is [ 0.20660317]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658542948438053, auc for val: 0.6349153043536799\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 400, the loss is [ 0.18324302]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658758168127994, auc for val: 0.634863929933962\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 0, the loss is [ 0.14407592]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6658430258336463, auc for val: 0.6349169307132916\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 100, the loss is [ 0.17466654]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665982048321733, auc for val: 0.634901834888484\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 200, the loss is [ 0.15614462]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6659099174121561, auc for val: 0.6348531919510104\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 300, the loss is [ 0.1427035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6660327371087225, auc for val: 0.6350086508799222\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 400, the loss is [ 0.13873269]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6659455827073626, auc for val: 0.6348690646193923\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 0, the loss is [ 0.15731195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6660185111534597, auc for val: 0.6349631591708178\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 100, the loss is [ 0.17357309]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.665963514834468, auc for val: 0.6348629087605542\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 200, the loss is [ 0.13935228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.666127789811521, auc for val: 0.6349534523850622\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 300, the loss is [ 0.14641897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6659603260797088, auc for val: 0.6348726781949852\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 400, the loss is [ 0.16289262]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6660520331948737, auc for val: 0.6349203287774414\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "#choose the best among finer search\n",
    "lr =0.00015493820527177172\n",
    "wd = 0.0008104257925743996\n",
    "nn_model = NeuralNetwork(data,learning_rate = lr,num_epochs=80,verbose=True,\n",
    "                             weight_decay=wd,batchnorm=True)\n",
    "nn_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most expensive search final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = [230,220,210,200]\n",
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "train_hist={}\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "\n",
    "for i in range(5):\n",
    "    #learnning_rate 5e-4 too large\n",
    "    tic = datetime.now()\n",
    "    weight_decay = 10** (np.random.uniform(-3,-1))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-4,np.log10(5e-4)))\n",
    "    dropout = np.random.uniform(0,1)\n",
    "    nn_model = NeuralNetwork(data,hidden_size=hidden_size,learning_rate = learning_rate,num_epochs=55,verbose=None,dropout=dropout,\n",
    "                             weight_decay=weight_decay,batchnorm=True)\n",
    "    print('Learning rate is {}. Weight decay is {}. dropout is {}'.format(learning_rate, weight_decay,dropout))\n",
    "    describe= 'Learning rate is {}. Weight decay is {}. dropout is {}'.format(learning_rate, weight_decay, dropout)\n",
    "    nn_model.train()\n",
    "    print('Val aus is {}. Train auc is {}'.format(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1]))\n",
    "    if nn_model.auc_history['val'][-1]> best_auc:\n",
    "        best_auc =nn_model.auc_history['val'][-1]\n",
    "        best_net = nn_model\n",
    "    train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "    toc = datetime.now()\n",
    "    print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "    print('You have finished {}!!'.format(i+1))\n",
    "\n",
    "train_hist['best_net'] = best_net\n",
    "filename= 'search_lr_wd2.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAALJCAYAAADielEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc83e40f278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model= best_net\n",
    "\n",
    "data_vis.nnplot(nn_model, loss=False, acc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New processing: preprocess cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_util\n",
    "import data_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "\n",
    "rso = np.random.RandomState(66)\n",
    "\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "lv1_pre = data_preprocess.preprocess_cell()\n",
    "\n",
    "X_train = train_data.drop(['id','target'],axis=1)\n",
    "y_train = train_data['target']\n",
    "y_train\n",
    "\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_train,y_train,test_size =0.1 ,random_state=rso)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size =0.2, random_state=rso)\n",
    "\n",
    "X_train, y_train, col = lv1_pre.process(X_train, y=y_train, rso =rso, oversample= None)\n",
    "X_val = lv1_pre.process(X_val,test=True,rso =rso)\n",
    "X_train_test = lv1_pre.process(X_train_test,test=True,rso =rso)\n",
    "#X_dev, y_dev = X_train[:10000,:], y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_16_bin_0</th>\n",
       "      <th>ps_calc_16_bin_1</th>\n",
       "      <th>ps_calc_17_bin_0</th>\n",
       "      <th>ps_calc_17_bin_1</th>\n",
       "      <th>ps_calc_18_bin_0</th>\n",
       "      <th>ps_calc_18_bin_1</th>\n",
       "      <th>ps_calc_19_bin_0</th>\n",
       "      <th>ps_calc_19_bin_1</th>\n",
       "      <th>ps_calc_20_bin_0</th>\n",
       "      <th>ps_calc_20_bin_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>1.071380e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "      <td>107138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.940422e-17</td>\n",
       "      <td>4.166575e-17</td>\n",
       "      <td>-7.295236e-18</td>\n",
       "      <td>2.676025e-17</td>\n",
       "      <td>9.390959e-17</td>\n",
       "      <td>-2.294683e-16</td>\n",
       "      <td>-7.296563e-16</td>\n",
       "      <td>-1.314883e-16</td>\n",
       "      <td>-1.353366e-15</td>\n",
       "      <td>-4.194761e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372809</td>\n",
       "      <td>0.627191</td>\n",
       "      <td>0.445808</td>\n",
       "      <td>0.554192</td>\n",
       "      <td>0.713622</td>\n",
       "      <td>0.286378</td>\n",
       "      <td>0.650255</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>0.846908</td>\n",
       "      <td>0.153092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483554</td>\n",
       "      <td>0.483554</td>\n",
       "      <td>0.497057</td>\n",
       "      <td>0.497057</td>\n",
       "      <td>0.452070</td>\n",
       "      <td>0.452070</td>\n",
       "      <td>0.476892</td>\n",
       "      <td>0.476892</td>\n",
       "      <td>0.360078</td>\n",
       "      <td>0.360078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.594890e-01</td>\n",
       "      <td>-1.638316e+00</td>\n",
       "      <td>-9.787887e-02</td>\n",
       "      <td>-2.056526e+00</td>\n",
       "      <td>-2.122196e+00</td>\n",
       "      <td>-1.086670e+00</td>\n",
       "      <td>-2.621268e+00</td>\n",
       "      <td>-2.828311e+00</td>\n",
       "      <td>-4.102093e+00</td>\n",
       "      <td>-2.237630e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.594890e-01</td>\n",
       "      <td>-8.979692e-01</td>\n",
       "      <td>-9.787887e-02</td>\n",
       "      <td>-6.475388e-01</td>\n",
       "      <td>-7.316796e-01</td>\n",
       "      <td>-5.931496e-01</td>\n",
       "      <td>-7.247620e-01</td>\n",
       "      <td>-4.174239e-01</td>\n",
       "      <td>-1.096969e+00</td>\n",
       "      <td>-6.345823e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.575813e-01</td>\n",
       "      <td>-1.576221e-01</td>\n",
       "      <td>-9.787887e-02</td>\n",
       "      <td>-8.394377e-02</td>\n",
       "      <td>3.112074e-01</td>\n",
       "      <td>-3.463895e-01</td>\n",
       "      <td>-5.239479e-03</td>\n",
       "      <td>7.880198e-01</td>\n",
       "      <td>-1.009484e-01</td>\n",
       "      <td>-2.125311e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.462342e-01</td>\n",
       "      <td>5.827250e-01</td>\n",
       "      <td>-9.787887e-02</td>\n",
       "      <td>7.614488e-01</td>\n",
       "      <td>1.006465e+00</td>\n",
       "      <td>3.938907e-01</td>\n",
       "      <td>3.355959e-01</td>\n",
       "      <td>7.880198e-01</td>\n",
       "      <td>3.431724e-01</td>\n",
       "      <td>4.114085e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.553865e+00</td>\n",
       "      <td>2.433593e+00</td>\n",
       "      <td>3.132249e+01</td>\n",
       "      <td>1.606841e+00</td>\n",
       "      <td>1.006465e+00</td>\n",
       "      <td>3.355012e+00</td>\n",
       "      <td>1.004244e+01</td>\n",
       "      <td>7.880198e-01</td>\n",
       "      <td>1.521199e+01</td>\n",
       "      <td>1.286470e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ps_ind_01     ps_ind_03     ps_ind_14     ps_ind_15     ps_reg_01  \\\n",
       "count  1.071380e+05  1.071380e+05  1.071380e+05  1.071380e+05  1.071380e+05   \n",
       "mean   6.940422e-17  4.166575e-17 -7.295236e-18  2.676025e-17  9.390959e-17   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -9.594890e-01 -1.638316e+00 -9.787887e-02 -2.056526e+00 -2.122196e+00   \n",
       "25%   -9.594890e-01 -8.979692e-01 -9.787887e-02 -6.475388e-01 -7.316796e-01   \n",
       "50%   -4.575813e-01 -1.576221e-01 -9.787887e-02 -8.394377e-02  3.112074e-01   \n",
       "75%    5.462342e-01  5.827250e-01 -9.787887e-02  7.614488e-01  1.006465e+00   \n",
       "max    2.553865e+00  2.433593e+00  3.132249e+01  1.606841e+00  1.006465e+00   \n",
       "\n",
       "          ps_reg_02     ps_reg_03     ps_car_11     ps_car_12     ps_car_13  \\\n",
       "count  1.071380e+05  1.071380e+05  1.071380e+05  1.071380e+05  1.071380e+05   \n",
       "mean  -2.294683e-16 -7.296563e-16 -1.314883e-16 -1.353366e-15 -4.194761e-16   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -1.086670e+00 -2.621268e+00 -2.828311e+00 -4.102093e+00 -2.237630e+00   \n",
       "25%   -5.931496e-01 -7.247620e-01 -4.174239e-01 -1.096969e+00 -6.345823e-01   \n",
       "50%   -3.463895e-01 -5.239479e-03  7.880198e-01 -1.009484e-01 -2.125311e-01   \n",
       "75%    3.938907e-01  3.355959e-01  7.880198e-01  3.431724e-01  4.114085e-01   \n",
       "max    3.355012e+00  1.004244e+01  7.880198e-01  1.521199e+01  1.286470e+01   \n",
       "\n",
       "             ...         ps_calc_16_bin_0  ps_calc_16_bin_1  ps_calc_17_bin_0  \\\n",
       "count        ...            107138.000000     107138.000000     107138.000000   \n",
       "mean         ...                 0.372809          0.627191          0.445808   \n",
       "std          ...                 0.483554          0.483554          0.497057   \n",
       "min          ...                 0.000000          0.000000          0.000000   \n",
       "25%          ...                 0.000000          0.000000          0.000000   \n",
       "50%          ...                 0.000000          1.000000          0.000000   \n",
       "75%          ...                 1.000000          1.000000          1.000000   \n",
       "max          ...                 1.000000          1.000000          1.000000   \n",
       "\n",
       "       ps_calc_17_bin_1  ps_calc_18_bin_0  ps_calc_18_bin_1  ps_calc_19_bin_0  \\\n",
       "count     107138.000000     107138.000000     107138.000000     107138.000000   \n",
       "mean           0.554192          0.713622          0.286378          0.650255   \n",
       "std            0.497057          0.452070          0.452070          0.476892   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            1.000000          1.000000          0.000000          1.000000   \n",
       "75%            1.000000          1.000000          1.000000          1.000000   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       ps_calc_19_bin_1  ps_calc_20_bin_0  ps_calc_20_bin_1  \n",
       "count     107138.000000     107138.000000     107138.000000  \n",
       "mean           0.349745          0.846908          0.153092  \n",
       "std            0.476892          0.360078          0.360078  \n",
       "min            0.000000          0.000000          0.000000  \n",
       "25%            0.000000          1.000000          0.000000  \n",
       "50%            0.000000          1.000000          0.000000  \n",
       "75%            1.000000          1.000000          0.000000  \n",
       "max            1.000000          1.000000          1.000000  \n",
       "\n",
       "[8 rows x 238 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ={}\n",
    "#enter df here\n",
    "data['X_train'] = X_train.values\n",
    "data['X_val'] = X_val.values\n",
    "data['y_train'] = y_train.values\n",
    "data['y_val'] =y_val.values\n",
    "#X_train = None\n",
    "#X_val = None\n",
    "print(type(X_train), type(X_val),type(y_train), type(y_val))\n",
    "X_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "#only use step decay for now\n",
    "#coarse search\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "input_size = 237\n",
    "hidden_size= [230,220,210]\n",
    "lr_decay = {'step_size': 25, 'gamma':0.1}\n",
    "\n",
    "train_hist={}\n",
    "for i in range(100):\n",
    "    #learnning_rate 5e-4 too large\n",
    "    tic = datetime.now()\n",
    "    dropout = np.random.uniform(0,1)\n",
    "    weight_decay = 10** (np.random.uniform(-3,3))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-6,-2))\n",
    "    \n",
    "    nn_model = NeuralNetwork(data,input_size = input_size, hidden_size=hidden_size,\n",
    "                             learning_rate = learning_rate,num_epochs=5,batch_size =512, \n",
    "                             verbose=None,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n",
    "    nn_model.train()\n",
    "    describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "    train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "    print(describe)\n",
    "    toc = datetime.now()\n",
    "    print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "    print('You have finished {}!!'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is 0.0001697748323692106. Weight decay is 0.01611014195754915. dropout is 0.8633795643083599\n",
      " Val aus is 0.6003277112111378. Train auc is 0.6346519767601385\n",
      "Learning rate is 0.00011292573215690098. Weight decay is 0.0025168409474830154. dropout is 0.7474963413998843\n",
      " Val aus is 0.5997970907137983. Train auc is 0.633021357700171\n",
      "Learning rate is 0.0004576885112175419. Weight decay is 0.7826435311885301. dropout is 0.6981187592989551\n",
      " Val aus is 0.5951053802842754. Train auc is 0.6484250603014419\n",
      "Learning rate is 0.0035761607375581514. Weight decay is 0.00729795832118471. dropout is 0.8336651558501216\n",
      " Val aus is 0.5949200266604695. Train auc is 0.6517912182364991\n",
      "Learning rate is 6.0618015129868076e-05. Weight decay is 0.00496681831649462. dropout is 0.5197983413792601\n",
      " Val aus is 0.593480985335158. Train auc is 0.657112285152382\n",
      "Learning rate is 2.520241184671594e-05. Weight decay is 0.008209244622133769. dropout is 0.39878113804746995\n",
      " Val aus is 0.5896564177744055. Train auc is 0.6488002163005206\n",
      "Learning rate is 0.0003364093995809248. Weight decay is 40.38236910619775. dropout is 0.6260098224546417\n",
      " Val aus is 0.5890169752750437. Train auc is 0.6344304459205093\n",
      "Learning rate is 0.00015379848171195436. Weight decay is 15.147496390606072. dropout is 0.6937951813450229\n",
      " Val aus is 0.5889955694756569. Train auc is 0.6605906989586742\n",
      "Learning rate is 0.00035241178980443123. Weight decay is 48.06564546712159. dropout is 0.08535113360113433\n",
      " Val aus is 0.586640694731108. Train auc is 0.64094130348404\n",
      "Learning rate is 7.722564749536545e-05. Weight decay is 0.00275276739393203. dropout is 0.8542123583365075\n",
      " Val aus is 0.583571184041119. Train auc is 0.5570400951185741\n",
      "Learning rate is 3.1368595238183194e-05. Weight decay is 0.003912627924794611. dropout is 0.4207448172906385\n",
      " Val aus is 0.5835634519416097. Train auc is 0.6510281360933134\n",
      "Learning rate is 5.018100322682305e-05. Weight decay is 0.025056925665561048. dropout is 0.23123493479657753\n",
      " Val aus is 0.5834165007028079. Train auc is 0.7817011446319728\n",
      "Learning rate is 0.003771630228931296. Weight decay is 0.04266050550835299. dropout is 0.7488935611820214\n",
      " Val aus is 0.5823809732304315. Train auc is 0.6247156694421353\n",
      "Learning rate is 0.0031052414349108793. Weight decay is 0.010860049501368147. dropout is 0.6680190203441491\n",
      " Val aus is 0.5820469593119607. Train auc is 0.7563138393925822\n",
      "Learning rate is 0.0004510417532794107. Weight decay is 2.403802912643618. dropout is 0.21029939040229606\n",
      " Val aus is 0.5818580434844756. Train auc is 0.6821845542620208\n",
      "Learning rate is 0.0017781294971446228. Weight decay is 0.006916546689426339. dropout is 0.7247146158702842\n",
      " Val aus is 0.5816502115159612. Train auc is 0.8445689332178898\n",
      "Learning rate is 3.1254982574072496e-05. Weight decay is 0.015781545267140793. dropout is 0.32576011853108977\n",
      " Val aus is 0.5811370173741517. Train auc is 0.6603426075210468\n",
      "Learning rate is 0.007901117497878645. Weight decay is 0.0051825762071712874. dropout is 0.8387346508697067\n",
      " Val aus is 0.5800359969765849. Train auc is 0.6274128972267646\n",
      "Learning rate is 0.00018762062985101246. Weight decay is 52.9263831683967. dropout is 0.49545084875952916\n",
      " Val aus is 0.577188283897815. Train auc is 0.687257267489177\n",
      "Learning rate is 1.755351409528121e-05. Weight decay is 0.02325101164006467. dropout is 0.1896390014783761\n",
      " Val aus is 0.5770486136880599. Train auc is 0.6624212884678343\n",
      "Learning rate is 3.626401736980522e-05. Weight decay is 0.1637147012998134. dropout is 0.14752682467927547\n",
      " Val aus is 0.5769620382306475. Train auc is 0.6667046529898075\n",
      "Learning rate is 0.0024109731209465504. Weight decay is 0.0063640841849510865. dropout is 0.245604749550976\n",
      " Val aus is 0.5762202490963455. Train auc is 0.9393720760032822\n",
      "Learning rate is 0.00014018087473032192. Weight decay is 14.6918419459913. dropout is 0.5003159200678932\n",
      " Val aus is 0.5757088241531272. Train auc is 0.6422380842886335\n",
      "Learning rate is 0.00011471675580587781. Weight decay is 4.587713042352929. dropout is 0.5849028328049316\n",
      " Val aus is 0.5719758489557077. Train auc is 0.6111850846564661\n",
      "Learning rate is 0.0022554809362409756. Weight decay is 0.04356481033818433. dropout is 0.3340528920959568\n",
      " Val aus is 0.5712700740389062. Train auc is 0.8319610180890069\n",
      "Learning rate is 3.335870719713195e-05. Weight decay is 0.01587646065075224. dropout is 0.8099788988197253\n",
      " Val aus is 0.5699475655145766. Train auc is 0.5468426709180226\n",
      "Learning rate is 0.002640403321308396. Weight decay is 0.0012651477012070903. dropout is 0.6581287746898374\n",
      " Val aus is 0.5682888403443517. Train auc is 0.9261186453441255\n",
      "Learning rate is 0.0007943630083064011. Weight decay is 0.33291362749871434. dropout is 0.09702959304623904\n",
      " Val aus is 0.5664802921200476. Train auc is 0.8338499615650166\n",
      "Learning rate is 9.500653825094759e-05. Weight decay is 0.027304774063278078. dropout is 0.40460175213793337\n",
      " Val aus is 0.562718097580454. Train auc is 0.9111976494945541\n",
      "Learning rate is 1.1521254754982775e-05. Weight decay is 0.05917321633171188. dropout is 0.11764138557249781\n",
      " Val aus is 0.5620613815883302. Train auc is 0.6049268652614097\n",
      "Learning rate is 0.0007901117645121056. Weight decay is 0.6222540364493497. dropout is 0.11792882402766114\n",
      " Val aus is 0.5608915654274096. Train auc is 0.7249714904445085\n",
      "Learning rate is 0.00046508036211673475. Weight decay is 1.041346742955071. dropout is 0.22814998819016674\n",
      " Val aus is 0.5605394736071856. Train auc is 0.7469529481740194\n",
      "Learning rate is 0.00017749913020671736. Weight decay is 6.768472084172184. dropout is 0.2879182058272358\n",
      " Val aus is 0.560059356712977. Train auc is 0.7403106334091154\n",
      "Learning rate is 0.0013017991503556205. Weight decay is 0.022202257863861714. dropout is 0.14153258013013204\n",
      " Val aus is 0.5547908086053498. Train auc is 0.9395704652086299\n",
      "Learning rate is 7.018288227782286e-05. Weight decay is 0.25194005625624305. dropout is 0.07379514287915756\n",
      " Val aus is 0.5539171239619014. Train auc is 0.8967470169412963\n",
      "Learning rate is 2.4896649339302976e-05. Weight decay is 0.16109732359234818. dropout is 0.44216334256440226\n",
      " Val aus is 0.5538093644814126. Train auc is 0.5908349343205337\n",
      "Learning rate is 3.0384377520841735e-05. Weight decay is 0.13953059385994274. dropout is 0.8427163563596116\n",
      " Val aus is 0.5528732967930172. Train auc is 0.5463319299244515\n",
      "Learning rate is 0.0001087160828936583. Weight decay is 0.12490998006041626. dropout is 0.10900698885737004\n",
      " Val aus is 0.5526972402326304. Train auc is 0.950426356771988\n",
      "Learning rate is 7.16680617528309e-05. Weight decay is 1.5491820848850462. dropout is 0.2388698390232401\n",
      " Val aus is 0.5520245889234496. Train auc is 0.6170653573926642\n",
      "Learning rate is 0.0005248998615901393. Weight decay is 0.008297491466537639. dropout is 0.40495918079861837\n",
      " Val aus is 0.5502700776875651. Train auc is 0.9642572552478692\n",
      "Learning rate is 0.00015878158909487215. Weight decay is 0.055189645529418276. dropout is 0.169195675032499\n",
      " Val aus is 0.5496702203801975. Train auc is 0.956207451617736\n",
      "Learning rate is 0.00016336042051423588. Weight decay is 444.0930476340161. dropout is 0.3105727888888956\n",
      " Val aus is 0.5469457748350075. Train auc is 0.5563126216264027\n",
      "Learning rate is 2.8135290665976623e-05. Weight decay is 0.14123945365551777. dropout is 0.6130413383059504\n",
      " Val aus is 0.5413981444204128. Train auc is 0.549275396670923\n",
      "Learning rate is 0.0003733689352171557. Weight decay is 0.002160412061341069. dropout is 0.01542396692177761\n",
      " Val aus is 0.5405147028722683. Train auc is 0.9903297165555587\n",
      "Learning rate is 0.001900877725788026. Weight decay is 0.05682903368288279. dropout is 0.0540283828721182\n",
      " Val aus is 0.5331663590767064. Train auc is 0.8979339425923258\n",
      "Learning rate is 7.014159805540533e-06. Weight decay is 0.04854854165407018. dropout is 0.44588400993212196\n",
      " Val aus is 0.5319980727964375. Train auc is 0.5560735046851301\n",
      "Learning rate is 4.544261337296862e-06. Weight decay is 3.04554289802152. dropout is 0.28676332243586367\n",
      " Val aus is 0.5306594723333626. Train auc is 0.5035423506002611\n",
      "Learning rate is 0.0018309948209134302. Weight decay is 0.22325126914162188. dropout is 0.01598267485227023\n",
      " Val aus is 0.5301217800535519. Train auc is 0.787134869345429\n",
      "Learning rate is 3.65330913995289e-06. Weight decay is 0.0166582418441922. dropout is 0.5490905784937966\n",
      " Val aus is 0.5282901733578058. Train auc is 0.5451618333594357\n",
      "Learning rate is 1.5106280337897548e-06. Weight decay is 0.01602868285913926. dropout is 0.2546604338370424\n",
      " Val aus is 0.5276546877487778. Train auc is 0.539891212850796\n",
      "Learning rate is 2.798165257167215e-05. Weight decay is 0.5347286550336511. dropout is 0.3859584612079314\n",
      " Val aus is 0.5261230278748315. Train auc is 0.5338411199217475\n",
      "Learning rate is 2.4022993161278127e-05. Weight decay is 203.06247599965764. dropout is 0.20115112323477857\n",
      " Val aus is 0.5216965957431539. Train auc is 0.49244751970626816\n",
      "Learning rate is 6.044237095310103e-06. Weight decay is 25.2892790591031. dropout is 0.15761964670455642\n",
      " Val aus is 0.5214751038574703. Train auc is 0.5139788994030765\n",
      "Learning rate is 8.732661453272546e-06. Weight decay is 0.015198859565749082. dropout is 0.8536759460780138\n",
      " Val aus is 0.521325690525728. Train auc is 0.5183502301835817\n",
      "Learning rate is 2.043766696705395e-06. Weight decay is 1.6438473825682478. dropout is 0.9284744125949635\n",
      " Val aus is 0.5212392140532226. Train auc is 0.5029285795545582\n",
      "Learning rate is 4.121859976227454e-06. Weight decay is 0.1958491861038254. dropout is 0.7497143006110264\n",
      " Val aus is 0.5202000817760677. Train auc is 0.5151449329150424\n",
      "Learning rate is 6.299197878264026e-06. Weight decay is 24.172350337060692. dropout is 0.23686893766922534\n",
      " Val aus is 0.5189686644256684. Train auc is 0.4905454603639363\n",
      "Learning rate is 6.212576200350693e-05. Weight decay is 20.875928080276577. dropout is 0.9245401165054907\n",
      " Val aus is 0.5174701569777334. Train auc is 0.5128413649428024\n",
      "Learning rate is 6.856621071873929e-05. Weight decay is 15.096960719837686. dropout is 0.3603361315125574\n",
      " Val aus is 0.5172058133981239. Train auc is 0.5038131995110013\n",
      "Learning rate is 5.294511142818919e-06. Weight decay is 1.8941669377270256. dropout is 0.07899763240582547\n",
      " Val aus is 0.5154703887076655. Train auc is 0.49826430997578164\n",
      "Learning rate is 1.3390520497004374e-06. Weight decay is 2.733899158364737. dropout is 0.637037249453082\n",
      " Val aus is 0.5147574279878036. Train auc is 0.49172721733012287\n",
      "Learning rate is 4.541926054519885e-06. Weight decay is 0.03127751958168317. dropout is 0.8173055503052234\n",
      " Val aus is 0.5144247134028591. Train auc is 0.5227305276557334\n",
      "Learning rate is 3.3390745616531355e-06. Weight decay is 0.07799188675171832. dropout is 0.1746285872273856\n",
      " Val aus is 0.509920713440308. Train auc is 0.5301563954422241\n",
      "Learning rate is 9.705969793522295e-06. Weight decay is 26.373580230052266. dropout is 0.8196955372711414\n",
      " Val aus is 0.5085140439385132. Train auc is 0.47579080255498546\n",
      "Learning rate is 6.559577726619036e-06. Weight decay is 11.171410805830547. dropout is 0.7420606591588331\n",
      " Val aus is 0.5066191420331073. Train auc is 0.4961477655476386\n",
      "Learning rate is 1.2275309042370284e-06. Weight decay is 193.45436495936227. dropout is 0.6757156916505088\n",
      " Val aus is 0.5022106324344682. Train auc is 0.4962166898170241\n",
      "Learning rate is 2.937557799885094e-06. Weight decay is 0.24181778398425083. dropout is 0.9636947065131417\n",
      " Val aus is 0.5002828048912558. Train auc is 0.4957897909081861\n",
      "Learning rate is 0.0025742386200934726. Weight decay is 6.850320002649148. dropout is 0.09285809463682404\n",
      " Val aus is 0.5. Train auc is 0.5\n",
      "Learning rate is 5.374937508142974e-05. Weight decay is 53.0419985498642. dropout is 0.9164272379772147\n",
      " Val aus is 0.4994024769822753. Train auc is 0.5054342373282134\n",
      "Learning rate is 3.926423053962582e-06. Weight decay is 0.019412373661134172. dropout is 0.9811476064514884\n",
      " Val aus is 0.4991486496093068. Train auc is 0.5082592856164465\n",
      "Learning rate is 6.37160131502232e-05. Weight decay is 360.76606047119895. dropout is 0.3903792173073096\n",
      " Val aus is 0.4949480383867779. Train auc is 0.4968479410332753\n",
      "Learning rate is 1.7097005461568339e-06. Weight decay is 0.07750058446041747. dropout is 0.4931605065748573\n",
      " Val aus is 0.4940655090033464. Train auc is 0.48830189993892537\n",
      "Learning rate is 2.5443112222643715e-06. Weight decay is 8.403351014022038. dropout is 0.16322023375693728\n",
      " Val aus is 0.49390026059242753. Train auc is 0.517043961558091\n",
      "Learning rate is 2.8336485720738767e-05. Weight decay is 0.34487278294430734. dropout is 0.8908734697052788\n",
      " Val aus is 0.4873858232903998. Train auc is 0.49584853025926473\n",
      "Learning rate is 2.1466692927276458e-05. Weight decay is 246.3961144953998. dropout is 0.8352870764977088\n",
      " Val aus is 0.48559494449848606. Train auc is 0.5063186515319011\n",
      "Learning rate is 4.430318063980075e-06. Weight decay is 2.420414080517866. dropout is 0.7924023737369421\n",
      " Val aus is 0.4821049947894345. Train auc is 0.5073759201590522\n",
      "Learning rate is 2.477641684294093e-05. Weight decay is 62.04750075993437. dropout is 0.2312545509514622\n",
      " Val aus is 0.4776928503146527. Train auc is 0.49501063557714364\n",
      "Learning rate is 3.3931720907214596e-06. Weight decay is 12.366419363285551. dropout is 0.9180339580723893\n",
      " Val aus is 0.47547018181668005. Train auc is 0.5155908656416941\n",
      "Learning rate is 6.268459976871477e-06. Weight decay is 2.5558205581597826. dropout is 0.8368644355131424\n",
      " Val aus is 0.47341383552792143. Train auc is 0.49654387343975354\n",
      "Learning rate is 1.6242320804503657e-06. Weight decay is 3.049371487672463. dropout is 0.49690927080781366\n",
      " Val aus is 0.47258493090462567. Train auc is 0.49904922564485915\n",
      "Learning rate is 3.579963047217718e-05. Weight decay is 17.736147240888567. dropout is 0.8677209711669119\n",
      " Val aus is 0.4709738487990159. Train auc is 0.49795454302418984\n",
      "Learning rate is 9.108388560257222e-06. Weight decay is 0.45670916648916166. dropout is 0.6806163586323362\n",
      " Val aus is 0.463705433436414. Train auc is 0.48596411075872875\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(train_hist, key =lambda x:x[0], reverse=True):\n",
    "    print(train_hist[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finer Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 1.22688496]\n",
      "  acc for train: 0.5463561014766003, acc for val: 0.5452780526050515\n",
      "  auc for train: 0.4855649203504382, auc for val: 0.48279902558555865\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.27840167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4946628301856943, auc for val: 0.494118915746092\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.24782151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5159274484134839, auc for val: 0.5223581356832782\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.21881074]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48722805483905945, auc for val: 0.4974772067579898\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.23243892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48467809977909837, auc for val: 0.4967870551678421\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 500, the loss is [ 0.17353983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4574031695803364, auc for val: 0.4619211377673038\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.15162422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4789626551777525, auc for val: 0.4838959675543613\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.1785073]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5114127654596695, auc for val: 0.5117288594601164\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.18134567]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5779949221380006, auc for val: 0.574353296017978\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.16962853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5848021569790267, auc for val: 0.5828545934570084\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.15697828]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5615415604578375, auc for val: 0.5633915432748381\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.18930826]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5687526894973227, auc for val: 0.5714322388820252\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.17063527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5913993286002419, auc for val: 0.5937191279857708\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.16642641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5889719366152881, auc for val: 0.584941261704627\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.21858482]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.591021194104807, auc for val: 0.5883219972309486\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 600, the loss is [ 0.19494024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5951368274423434, auc for val: 0.5914914663883744\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.16544415]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6012656746892794, auc for val: 0.5994063784911802\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.17436321]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.598962350725645, auc for val: 0.5981748383493772\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.15487495]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6040177633628742, auc for val: 0.6011937276567259\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.13529579]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6054669463512897, auc for val: 0.6014739000506442\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.18062919]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6070162389558362, auc for val: 0.6057821692628078\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.19779971]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6056761481883732, auc for val: 0.6012706163759588\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.12454559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6077113473768953, auc for val: 0.6044718459058298\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.15912238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6074388351460778, auc for val: 0.6033203294229734\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.13404366]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6128975898589356, auc for val: 0.61000874084342\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.16898748]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6179727172155581, auc for val: 0.6152824599727089\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.19509785]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.615237612715213, auc for val: 0.6131607585858456\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.19405292]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6147036244492384, auc for val: 0.6123842620854106\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.16743821]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.615935536321153, auc for val: 0.6162770903898296\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.15491195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6164188892887282, auc for val: 0.6147847049704476\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.13855033]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6176395411167792, auc for val: 0.6192436906068004\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.16606398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6163620364828064, auc for val: 0.615716125380107\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 500, the loss is [ 0.16521385]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6159787021543819, auc for val: 0.6157147220497796\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: iteration 600, the loss is [ 0.1581282]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6139256177572145, auc for val: 0.6110786110666389\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.14576435]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.613849725409405, auc for val: 0.6115788005964234\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.2118741]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.615094080489703, auc for val: 0.6142185050374146\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.19112757]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6182839726543787, auc for val: 0.6150361366580714\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.18772741]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6116478733977386, auc for val: 0.6100658701704537\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.15921818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6151182458153475, auc for val: 0.6127501967569357\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.1697672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6155110510252171, auc for val: 0.6128862308375744\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.20788504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6130028846991782, auc for val: 0.6139242780396726\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.17365786]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6120153618086609, auc for val: 0.6108634968161041\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.17125152]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.614811801953465, auc for val: 0.614001155482144\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 700, the loss is [ 0.15908827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6154321023300975, auc for val: 0.6126543918966736\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 800, the loss is [ 0.18466672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6107859977559729, auc for val: 0.6131428936895884\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.18024904]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.613274076024627, auc for val: 0.6140524246520873\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.23852512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6146572424212946, auc for val: 0.6136911898841855\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.18074043]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6206071951464633, auc for val: 0.6190685449581528\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 300, the loss is [ 0.174602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6146824980020872, auc for val: 0.6157128162770761\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.14919351]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207476458262812, auc for val: 0.6209030297340437\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 500, the loss is [ 0.17453082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207881894818679, auc for val: 0.6170889984275082\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 600, the loss is [ 0.18443796]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6199016151744701, auc for val: 0.6180167989967069\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 700, the loss is [ 0.16909546]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.616974296024821, auc for val: 0.6153651286587278\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 800, the loss is [ 0.15838967]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6157617129351176, auc for val: 0.617279558156234\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.15723024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6138738825417107, auc for val: 0.6161063815203689\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.16046621]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6170486893007876, auc for val: 0.6160450196488299\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.14823857]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6186367403405805, auc for val: 0.6175283723822026\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.17861862]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6143545008664723, auc for val: 0.61294322860239\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.15322685]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.61643525927074, auc for val: 0.6155777958520041\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 500, the loss is [ 0.15287215]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6157658747648191, auc for val: 0.6140572135168296\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 600, the loss is [ 0.16587564]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6196628445820092, auc for val: 0.6191102013153535\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 700, the loss is [ 0.13771701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.617738957777405, auc for val: 0.6141749078242522\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 800, the loss is [ 0.17182884]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6174976636365517, auc for val: 0.6172682375406018\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.1612038]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6196907089682964, auc for val: 0.6190505422348099\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.16032681]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6164888329632872, auc for val: 0.6161510262193828\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.14311773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6131868019696005, auc for val: 0.6114767747227009\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: iteration 300, the loss is [ 0.16109361]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6170118181934356, auc for val: 0.6142476642368604\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.16524056]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6186713611396639, auc for val: 0.6175284362838513\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 500, the loss is [ 0.17348784]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6125395654501457, auc for val: 0.6114161871887889\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 600, the loss is [ 0.16596884]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6152917365209037, auc for val: 0.6108606199889328\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 700, the loss is [ 0.16169187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.612865198034521, auc for val: 0.609825645077873\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 800, the loss is [ 0.18125392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6137328188300898, auc for val: 0.614151651382996\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.14609271]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6114461000591312, auc for val: 0.6103686988313186\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.1756151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6135919022893873, auc for val: 0.6102437873964979\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.1800448]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6155101063950743, auc for val: 0.6170243688010639\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.14744295]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6128255447475307, auc for val: 0.6093113909204769\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 400, the loss is [ 0.16270167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6067645401247862, auc for val: 0.606866412345121\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 500, the loss is [ 0.12513974]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.612145738469074, auc for val: 0.6093699574081226\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 600, the loss is [ 0.19869725]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6101528265714193, auc for val: 0.6086046524670486\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 700, the loss is [ 0.18866575]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6175131413175761, auc for val: 0.6136287705030069\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 800, the loss is [ 0.17809021]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6150497197430156, auc for val: 0.6171233023361722\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 0, the loss is [ 0.1847214]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6139838779623376, auc for val: 0.6164536807169303\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.14587027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.611885254291702, auc for val: 0.6114216727068009\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.20067051]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6176179844420383, auc for val: 0.6163348925636363\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.1782843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6063309970153606, auc for val: 0.6070883527953197\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.19175565]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6160469344259467, auc for val: 0.6166567087850203\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 500, the loss is [ 0.15742998]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.617111160650237, auc for val: 0.6157683430509948\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 600, the loss is [ 0.13848463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.607975367675679, auc for val: 0.6092736513584579\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 700, the loss is [ 0.15862766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6123426315149103, auc for val: 0.6124551453026263\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 800, the loss is [ 0.14592153]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6102387375176519, auc for val: 0.6106352852335049\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.17528069]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6127244690903619, auc for val: 0.6101314107086373\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.13379432]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6153148388767646, auc for val: 0.6196104948419391\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.14960742]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6178378582576773, auc for val: 0.6223552385579361\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.16652115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6192750368451168, auc for val: 0.6203548500659826\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.18239506]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6133422279860111, auc for val: 0.6154523406266817\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 500, the loss is [ 0.1519507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.618337134515701, auc for val: 0.6168147375625941\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 600, the loss is [ 0.15778309]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6139957719078295, auc for val: 0.6160486883552572\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 700, the loss is [ 0.16387221]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6182288415317729, auc for val: 0.6173676146283315\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 800, the loss is [ 0.16849506]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200642836387263, auc for val: 0.6190171855741171\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: iteration 0, the loss is [ 0.15993632]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200218330994458, auc for val: 0.618693439773533\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.21150658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215460825316469, auc for val: 0.6240318662136235\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.23232685]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621337965075242, auc for val: 0.6231374523764819\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.17256682]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6163620532559626, auc for val: 0.6189343765550654\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.18341437]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6182330543766034, auc for val: 0.6188468425729203\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 500, the loss is [ 0.18675588]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6160075770267059, auc for val: 0.6155078410881568\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 600, the loss is [ 0.15456027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6186990513015552, auc for val: 0.6208450320963698\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 700, the loss is [ 0.16217199]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6206234412235477, auc for val: 0.6210162734795708\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 800, the loss is [ 0.1903028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220615778132773, auc for val: 0.62362535148914\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.18197107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6190440036245507, auc for val: 0.6207469668719017\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 100, the loss is [ 0.19583812]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6202588276697487, auc for val: 0.6201752839268038\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.14476673]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207907332044249, auc for val: 0.6216263086907324\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.18795586]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6189984723125346, auc for val: 0.6206076700482517\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.14413352]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6174652960829712, auc for val: 0.6188786192340214\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 500, the loss is [ 0.16775596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6205308718754032, auc for val: 0.6220985067923794\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 600, the loss is [ 0.16757096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6189916182753319, auc for val: 0.617897226481998\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 700, the loss is [ 0.17513375]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6225922170133139, auc for val: 0.6215279352347818\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 800, the loss is [ 0.17816205]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6214178694537824, auc for val: 0.6222716151061052\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.11607278]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6198897932685242, auc for val: 0.6198024704307273\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.1748689]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.619617823498581, auc for val: 0.6221434923001871\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 200, the loss is [ 0.15959515]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187614601961191, auc for val: 0.6191531056341667\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.16001625]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6223564317334606, auc for val: 0.6225509091655954\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.16949157]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6208557852237521, auc for val: 0.6220970859204229\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 500, the loss is [ 0.16330378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6195786567877095, auc for val: 0.6213545587847256\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 600, the loss is [ 0.19468737]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6221775086123027, auc for val: 0.6201932565787824\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 700, the loss is [ 0.18012348]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6212902749730075, auc for val: 0.619172209721222\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 800, the loss is [ 0.19793181]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6211826251661857, auc for val: 0.6212186600252254\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.2288516]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.622607252640514, auc for val: 0.6223592618558659\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.162275]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6192224088648515, auc for val: 0.6173554858447874\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.16784088]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6213534014030935, auc for val: 0.6221832040425055\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.16323608]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.619491510966167, auc for val: 0.6212400432710892\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.15888447]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6198449123994056, auc for val: 0.6186324237226817\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 500, the loss is [ 0.14226827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6192681934747136, auc for val: 0.619893789645836\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: iteration 600, the loss is [ 0.18534395]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6168435842104678, auc for val: 0.6216186768291037\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 700, the loss is [ 0.16301398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6210380219321445, auc for val: 0.6214350184784524\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 800, the loss is [ 0.19823514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.618090243319511, auc for val: 0.619529495116631\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.15687208]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.622538120879466, auc for val: 0.6219737970862933\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.17521232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6228513377727096, auc for val: 0.6217135870662822\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 200, the loss is [ 0.13707134]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.626602302753831, auc for val: 0.6256614497260319\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.16970876]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6259132976746186, auc for val: 0.6266508940858087\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.20426473]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6260839957656237, auc for val: 0.6270244054881282\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 500, the loss is [ 0.17229]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247235328019656, auc for val: 0.6243123994639118\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 600, the loss is [ 0.15220179]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215469981759207, auc for val: 0.6217133991202562\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 700, the loss is [ 0.15848985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220574734142441, auc for val: 0.6226133774127409\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 800, the loss is [ 0.12415484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247511117354161, auc for val: 0.6250900136167147\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.16200487]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6257215876113204, auc for val: 0.6275624774189114\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.1677015]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6263949736357639, auc for val: 0.6285603242190236\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.18459603]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6260730112807538, auc for val: 0.6287033486388558\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 300, the loss is [ 0.17829022]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.625121991029223, auc for val: 0.6252782578504001\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.12785308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6253417814428555, auc for val: 0.6249679865269062\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 500, the loss is [ 0.15408973]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6241717607392386, auc for val: 0.6243007593400354\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 600, the loss is [ 0.14861879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6259664875169662, auc for val: 0.6240946289095429\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 700, the loss is [ 0.20331916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273524712627931, auc for val: 0.6260678504299263\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 800, the loss is [ 0.16176353]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272512868506442, auc for val: 0.6261637029031817\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.20582011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279999480944249, auc for val: 0.6272316310174654\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.16391386]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271274896732838, auc for val: 0.6260923134846692\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.16606495]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6258442274409083, auc for val: 0.6255819623397462\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.17766467]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.626633981525871, auc for val: 0.6261472476021195\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.11349712]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6255545784552277, auc for val: 0.6238702276193773\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 500, the loss is [ 0.16376074]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6270009749354484, auc for val: 0.6264082532603071\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 600, the loss is [ 0.17781009]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271043945059183, auc for val: 0.6268264030967732\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 700, the loss is [ 0.17729577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288212208721361, auc for val: 0.6273437345571016\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 800, the loss is [ 0.16217966]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6269799268660866, auc for val: 0.6264988883518812\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.17882794]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6260560449627993, auc for val: 0.6237300587261666\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.15516585]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279940810453815, auc for val: 0.6259576501570467\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.17470054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6269697968073354, auc for val: 0.6264247348738131\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: iteration 300, the loss is [ 0.19948843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276233353957539, auc for val: 0.6254808987496767\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.15125354]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291850585321969, auc for val: 0.6255533118475441\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 500, the loss is [ 0.14314985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6289653883133007, auc for val: 0.6270013420047922\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 600, the loss is [ 0.17078473]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271389858553589, auc for val: 0.6266462568308607\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 700, the loss is [ 0.13952336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266017064178885, auc for val: 0.626895134958478\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 800, the loss is [ 0.12756364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272381239424607, auc for val: 0.6292194471732536\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.20442438]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277380643247121, auc for val: 0.6285300749326271\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.15389358]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247678699734796, auc for val: 0.6235371734786125\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.14803052]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273499096076451, auc for val: 0.6282357990689184\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.16106182]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6254137158668891, auc for val: 0.625411628109364\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 400, the loss is [ 0.17115426]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.627095200883971, auc for val: 0.6275025013360707\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 500, the loss is [ 0.16266172]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6259415500077748, auc for val: 0.6295320853637018\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 600, the loss is [ 0.14821421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6255366743864434, auc for val: 0.6256891066102431\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 700, the loss is [ 0.14321849]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268652908465001, auc for val: 0.6286753509458507\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 800, the loss is [ 0.15225951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6264206412796683, auc for val: 0.6268946688523336\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 0, the loss is [ 0.12445203]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6269774186995287, auc for val: 0.6267683603520531\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.15401056]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6258891965043638, auc for val: 0.6255214149009864\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.16616686]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268140653958103, auc for val: 0.6250715234866777\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.15349177]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279216102668299, auc for val: 0.6259780748781779\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.17570542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291139881962384, auc for val: 0.626537659111096\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 500, the loss is [ 0.19220306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272066715693805, auc for val: 0.6251673057934166\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 600, the loss is [ 0.20035513]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.62874805304141, auc for val: 0.6283856521943616\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 700, the loss is [ 0.12396194]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6292601238938433, auc for val: 0.6284699798173033\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 800, the loss is [ 0.17247424]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6302157067530225, auc for val: 0.6289132542785236\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.17449991]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6296517533595757, auc for val: 0.6285422626059258\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.18622953]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291815898898878, auc for val: 0.6273147783393639\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.16102006]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6298225900416818, auc for val: 0.6283586092671685\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.15180896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6299252628588738, auc for val: 0.6279501586986171\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.12566422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297290869620813, auc for val: 0.6282114462758439\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 500, the loss is [ 0.1711061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6300137941276531, auc for val: 0.6287555312264854\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 600, the loss is [ 0.13336384]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313183564132103, auc for val: 0.6301091097348585\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 700, the loss is [ 0.12889203]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6314126357730273, auc for val: 0.6312892103023211\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 800, the loss is [ 0.20997234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6318193836496011, auc for val: 0.6318185189363992\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: iteration 0, the loss is [ 0.17061719]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316962878529719, auc for val: 0.6313533725696474\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.19363125]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6310436407152887, auc for val: 0.6319958447589482\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.21334679]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316287104301566, auc for val: 0.6298962195122978\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.16844472]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316004648217219, auc for val: 0.6298268060330052\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.14183944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308053140317479, auc for val: 0.6294072227948478\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 500, the loss is [ 0.13287549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.630265001744845, auc for val: 0.6290478599693649\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 600, the loss is [ 0.16780663]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6306384620177125, auc for val: 0.6300564698118988\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 700, the loss is [ 0.18611714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6310658377844929, auc for val: 0.6309270420691568\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 800, the loss is [ 0.13543227]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313379071112338, auc for val: 0.6296827804873414\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.15361708]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311797060263845, auc for val: 0.629725285107606\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 100, the loss is [ 0.15669908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6298669124497267, auc for val: 0.6279209781986218\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.16582811]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629762299125233, auc for val: 0.6292274561799079\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.16527869]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6299020659704324, auc for val: 0.6300758357704169\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.15913549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312007343853555, auc for val: 0.6292447710207958\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 500, the loss is [ 0.17418374]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303322514341028, auc for val: 0.6289813383529257\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 600, the loss is [ 0.13408133]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313022160765757, auc for val: 0.631771769241894\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 700, the loss is [ 0.15328696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6327812795537262, auc for val: 0.631441565615857\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 800, the loss is [ 0.15934531]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324748938181728, auc for val: 0.6301300481751273\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.18829899]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326029644401537, auc for val: 0.630575457703203\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.18713611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316324039255125, auc for val: 0.6316237780350817\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 200, the loss is [ 0.16936502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6315779252554911, auc for val: 0.631204901473982\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.19837256]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6322445910415025, auc for val: 0.6297490076550065\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.15247017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631619664983971, auc for val: 0.6298196402775209\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 500, the loss is [ 0.15952496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312365880500619, auc for val: 0.6286929589825391\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 600, the loss is [ 0.16449752]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6318977111195789, auc for val: 0.6299482717906827\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 700, the loss is [ 0.20260374]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320829518461261, auc for val: 0.6296705113707646\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 800, the loss is [ 0.15402202]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324205220480359, auc for val: 0.6300731193238547\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.18891571]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313785638503567, auc for val: 0.6287348045387392\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.15989658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631709231086917, auc for val: 0.6288557440475439\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.19915563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329127375029922, auc for val: 0.6298983458083385\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.16608833]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633433268905425, auc for val: 0.6302727205094041\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.17469691]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633537215400343, auc for val: 0.6303873137073979\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 500, the loss is [ 0.15723979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336271372951677, auc for val: 0.6302037292821834\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: iteration 600, the loss is [ 0.17909606]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336957783061314, auc for val: 0.6305191916749153\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 700, the loss is [ 0.11303186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340697273966918, auc for val: 0.63137643480001\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 800, the loss is [ 0.14216597]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340283354986384, auc for val: 0.6324499937772323\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.15953694]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634041721404773, auc for val: 0.6321441654977928\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.18854234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343793694434028, auc for val: 0.6316896167809598\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 200, the loss is [ 0.15275468]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339636901317275, auc for val: 0.6306999744513689\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.13251865]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338168283960789, auc for val: 0.630188503148131\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.1443512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343951746260976, auc for val: 0.6308657791825247\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 500, the loss is [ 0.21331331]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343127650955296, auc for val: 0.6312245293039629\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 600, the loss is [ 0.19258831]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6350839696157322, auc for val: 0.631682914625673\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 700, the loss is [ 0.13227381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6350772163720575, auc for val: 0.631152757728531\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 800, the loss is [ 0.19872695]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6352622769224439, auc for val: 0.6318554954375526\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.15279371]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63542921458006, auc for val: 0.6323490742791162\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.182142]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353905570156373, auc for val: 0.6318171281358067\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.21991885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6351301565494546, auc for val: 0.631232406748399\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 300, the loss is [ 0.18205748]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6354302337232098, auc for val: 0.6316807494874537\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.14501804]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353138723101164, auc for val: 0.632219709776453\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 500, the loss is [ 0.19077432]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6352265953178551, auc for val: 0.6319925907867515\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 600, the loss is [ 0.18063669]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357453516256778, auc for val: 0.6327550113828132\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 700, the loss is [ 0.1627554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362572615485671, auc for val: 0.6333039616295809\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 800, the loss is [ 0.18426499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363113904557707, auc for val: 0.6333827686512524\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.18290597]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363648632774942, auc for val: 0.6335638521413478\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.14111938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6356120510254034, auc for val: 0.6331291304772834\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.1834808]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357829597470558, auc for val: 0.6335301634426755\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.18885276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357110895557075, auc for val: 0.6336400053651323\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.19410031]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357140357567159, auc for val: 0.6334147846302932\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 500, the loss is [ 0.13075645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365324082470349, auc for val: 0.6330144621008793\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 600, the loss is [ 0.15512203]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365155496792173, auc for val: 0.6328167867356096\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 700, the loss is [ 0.14416654]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6364154505752949, auc for val: 0.6324841548469164\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 800, the loss is [ 0.16467054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6364182264939855, auc for val: 0.6329516542979137\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.17604277]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368098204810143, auc for val: 0.6332470641026459\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.19718632]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362669538820503, auc for val: 0.632099657372891\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 200, the loss is [ 0.16497055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358152880344458, auc for val: 0.6324052125041063\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: iteration 300, the loss is [ 0.17287394]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6359764837846761, auc for val: 0.6327644212138478\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 400, the loss is [ 0.1433854]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363154750671174, auc for val: 0.6320783630881462\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 500, the loss is [ 0.1910692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365259191225975, auc for val: 0.6317321840499\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 600, the loss is [ 0.16163303]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6367123477286993, auc for val: 0.6327051467961707\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 700, the loss is [ 0.18433173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368134553089717, auc for val: 0.6330283600830147\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 800, the loss is [ 0.17754221]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6361519309204382, auc for val: 0.6314360926275802\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 0, the loss is [ 0.16094035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363488201787877, auc for val: 0.6321228273589752\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 100, the loss is [ 0.14442195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357833464571944, auc for val: 0.6320770888140901\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 200, the loss is [ 0.13277949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362411444006274, auc for val: 0.632289846221459\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 300, the loss is [ 0.17575446]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6364545916240103, auc for val: 0.6318263876100205\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 400, the loss is [ 0.17294945]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365558250416015, auc for val: 0.6316942039169675\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 500, the loss is [ 0.17010155]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368636593749379, auc for val: 0.6320324766923874\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 600, the loss is [ 0.15237677]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368831377242327, auc for val: 0.6321089080762904\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 700, the loss is [ 0.16282186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637376078057798, auc for val: 0.6328946126790254\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 800, the loss is [ 0.16972774]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6372037658790223, auc for val: 0.6327799781329059\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 0, the loss is [ 0.14128458]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637130324189807, auc for val: 0.6327210921370159\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 100, the loss is [ 0.17917222]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374101533814769, auc for val: 0.6329405542056186\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 200, the loss is [ 0.14794891]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6373920976586268, auc for val: 0.6327646693026022\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 300, the loss is [ 0.17481458]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374511337574877, auc for val: 0.6325424694868874\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 400, the loss is [ 0.1626334]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374145507310248, auc for val: 0.6331182784737428\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 500, the loss is [ 0.14594406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374974714177284, auc for val: 0.6331385716326556\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 600, the loss is [ 0.15344296]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6376680078062331, auc for val: 0.6331882019132524\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 700, the loss is [ 0.19076981]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6376477977763123, auc for val: 0.6333541582542026\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 800, the loss is [ 0.16835241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6376423958924924, auc for val: 0.633094055989913\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 0, the loss is [ 0.13651668]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6377430994484006, auc for val: 0.6334645978450218\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 100, the loss is [ 0.20388758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637610146833144, auc for val: 0.6330340874249134\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 200, the loss is [ 0.17416401]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6376724905674747, auc for val: 0.6327012763610089\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 300, the loss is [ 0.15377004]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378632853729773, auc for val: 0.6330382097077499\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 400, the loss is [ 0.18591225]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378355464375305, auc for val: 0.6332017214973886\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 500, the loss is [ 0.17603506]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637792237066279, auc for val: 0.6334505470001188\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 600, the loss is [ 0.12518451]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380229767952607, auc for val: 0.6333733550612972\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 700, the loss is [ 0.17788999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380123020340616, auc for val: 0.6336732066571104\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 800, the loss is [ 0.15546426]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382766501436985, auc for val: 0.633711348423625\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: iteration 0, the loss is [ 0.14879474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384253590135033, auc for val: 0.633935886287903\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 100, the loss is [ 0.18621586]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380374248209268, auc for val: 0.6340547182952696\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 200, the loss is [ 0.16300793]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6379786410150683, auc for val: 0.633775658541825\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 300, the loss is [ 0.1759529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378359654572511, auc for val: 0.6335610003736467\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 400, the loss is [ 0.16274253]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383527347257902, auc for val: 0.6333155416107289\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 500, the loss is [ 0.16401726]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384748731384946, auc for val: 0.633554699169882\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 600, the loss is [ 0.1898949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384971870014263, auc for val: 0.6334885935406469\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 700, the loss is [ 0.16477682]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389194873039186, auc for val: 0.6338970616508273\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 800, the loss is [ 0.14736868]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6390784325912892, auc for val: 0.6338911175445119\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 0, the loss is [ 0.15242924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386550666909616, auc for val: 0.633701761923326\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 100, the loss is [ 0.18128984]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387685768221051, auc for val: 0.6337262713380887\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 200, the loss is [ 0.19781247]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388642490495412, auc for val: 0.6335406796493166\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 300, the loss is [ 0.18616565]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386580642935774, auc for val: 0.6337182723552226\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 400, the loss is [ 0.14369778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384354109263519, auc for val: 0.6332738075691708\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 500, the loss is [ 0.21294631]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383920463660062, auc for val: 0.6333411937373297\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 600, the loss is [ 0.16983159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387401148631451, auc for val: 0.6338254629857393\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 700, the loss is [ 0.13738491]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387192442645965, auc for val: 0.6339833702248829\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 800, the loss is [ 0.1456892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638784640636046, auc for val: 0.6341832821478621\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 0, the loss is [ 0.17050965]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385064396772505, auc for val: 0.634058285510843\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 100, the loss is [ 0.17348459]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386189676898608, auc for val: 0.6340840453931653\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 200, the loss is [ 0.14781234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388483014882584, auc for val: 0.6342749697371814\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 300, the loss is [ 0.19186647]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6391656118818485, auc for val: 0.6341818149158858\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 400, the loss is [ 0.12278976]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6393640758071866, auc for val: 0.6341028562844199\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 500, the loss is [ 0.16366535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394899612811323, auc for val: 0.6344964140098718\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 600, the loss is [ 0.15504651]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394182808506058, auc for val: 0.6344382071256223\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 700, the loss is [ 0.15603426]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6395694875293512, auc for val: 0.6343065221160248\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 800, the loss is [ 0.17173953]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396980735587287, auc for val: 0.6344157262749667\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 0, the loss is [ 0.17883116]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394499208202294, auc for val: 0.6344909410215949\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 100, the loss is [ 0.16094013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397821811201433, auc for val: 0.634349962707499\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 200, the loss is [ 0.1431804]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396572440638272, auc for val: 0.6340807187485052\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 300, the loss is [ 0.1877213]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639703320155587, auc for val: 0.6339654414269769\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 400, the loss is [ 0.15162338]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639973678233925, auc for val: 0.6340641293792777\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 500, the loss is [ 0.13716432]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400114323667863, auc for val: 0.6340797953070308\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: iteration 600, the loss is [ 0.15436897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399945261848481, auc for val: 0.6341819702846005\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 700, the loss is [ 0.17272322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402468411395268, auc for val: 0.6342949910008435\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 800, the loss is [ 0.18425497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401691400734996, auc for val: 0.6341775761065129\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 0, the loss is [ 0.12237199]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400808004206374, auc for val: 0.634202356163553\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 100, the loss is [ 0.14995678]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403134886183729, auc for val: 0.6340032874917438\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 200, the loss is [ 0.1622954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404321871427499, auc for val: 0.6337705326272096\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 300, the loss is [ 0.20164652]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640434251632275, auc for val: 0.633484332177751\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 400, the loss is [ 0.15074164]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403551280943942, auc for val: 0.6338022516515294\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 500, the loss is [ 0.14719817]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640531268108366, auc for val: 0.6338325097087404\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 600, the loss is [ 0.12767303]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406069450331978, auc for val: 0.6340266191114104\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 700, the loss is [ 0.1795323]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406231050802235, auc for val: 0.6342199905126851\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 800, the loss is [ 0.1527912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405814070913948, auc for val: 0.6341834249868418\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 0, the loss is [ 0.14602123]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408426643025659, auc for val: 0.6344987295049118\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 100, the loss is [ 0.12793405]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406211988921904, auc for val: 0.6342854508605643\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 200, the loss is [ 0.13868919]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640551808345305, auc for val: 0.63414638834296\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 300, the loss is [ 0.17455915]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640562787342184, auc for val: 0.6341863794983704\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 400, the loss is [ 0.15474449]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407149200228206, auc for val: 0.634246249078463\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 500, the loss is [ 0.16318375]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407241548433493, auc for val: 0.6343972912757639\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 600, the loss is [ 0.15198578]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640878519126707, auc for val: 0.6343335612842975\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 700, the loss is [ 0.15207319]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409120678351203, auc for val: 0.6343498198685192\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 800, the loss is [ 0.18294561]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411156361333201, auc for val: 0.6343362451535486\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 0, the loss is [ 0.17487372]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408119417550158, auc for val: 0.6344221490171615\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 100, the loss is [ 0.17157212]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408674483025956, auc for val: 0.6342508149139211\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 200, the loss is [ 0.14858712]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409526113361156, auc for val: 0.6344758477027342\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 300, the loss is [ 0.14323591]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409619655784242, auc for val: 0.6344739807722094\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 400, the loss is [ 0.19020645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411558345865322, auc for val: 0.6343275971304059\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 500, the loss is [ 0.17928508]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411207894343284, auc for val: 0.6343998084995388\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 600, the loss is [ 0.14409183]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413344857815922, auc for val: 0.6344768638642481\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 700, the loss is [ 0.17400315]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416078536752586, auc for val: 0.6345111051242366\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 800, the loss is [ 0.14310388]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641473775016968, auc for val: 0.634367891505405\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 0, the loss is [ 0.1682597]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416698510477802, auc for val: 0.6344416289962688\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 100, the loss is [ 0.15721844]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414279736339498, auc for val: 0.6342223009958312\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 200, the loss is [ 0.18330142]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412519913031046, auc for val: 0.63414846076114\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: iteration 300, the loss is [ 0.13750881]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414359353178217, auc for val: 0.634197312945189\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 400, the loss is [ 0.13630524]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414830627850175, auc for val: 0.6344280342337221\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 500, the loss is [ 0.17067435]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414975059410576, auc for val: 0.6343432392516625\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 600, the loss is [ 0.17996114]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416359234360891, auc for val: 0.6344181908738542\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 700, the loss is [ 0.18201321]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6415243424497866, auc for val: 0.6343968853123478\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 800, the loss is [ 0.16115044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6417103412920724, auc for val: 0.6345275416306964\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 0, the loss is [ 0.16436364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416749550341636, auc for val: 0.6344964578639445\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 100, the loss is [ 0.17492725]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6415610033902652, auc for val: 0.6344236162491378\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 200, the loss is [ 0.18720482]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641691286677533, auc for val: 0.6346392955907241\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 300, the loss is [ 0.12902008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6415761428255238, auc for val: 0.6344045785696784\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 400, the loss is [ 0.19798936]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6415754788558873, auc for val: 0.6345289462139971\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 500, the loss is [ 0.15069894]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6417157233882056, auc for val: 0.6344771445303136\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 600, the loss is [ 0.20350812]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6417164534456232, auc for val: 0.6344737978380774\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 700, the loss is [ 0.15503499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419100816004848, auc for val: 0.6345398420716106\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 800, the loss is [ 0.15045497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419738696813377, auc for val: 0.6345367509859698\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 0, the loss is [ 0.17622723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6420921150986125, auc for val: 0.634423359389569\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 100, the loss is [ 0.1858979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419683512356771, auc for val: 0.6344162262113959\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 200, the loss is [ 0.16076794]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6418615347532619, auc for val: 0.634526455302666\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 300, the loss is [ 0.1433475]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6418958871818474, auc for val: 0.6344130073224573\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 400, the loss is [ 0.18476909]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421129441121012, auc for val: 0.6345175616967161\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 500, the loss is [ 0.17119327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419983523829222, auc for val: 0.634463181393556\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 600, the loss is [ 0.12888376]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421590205903392, auc for val: 0.6346511888152488\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 700, the loss is [ 0.19523373]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421716855599433, auc for val: 0.6346085927279181\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 800, the loss is [ 0.16448604]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421319562140331, auc for val: 0.6344752174570604\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 0, the loss is [ 0.14821404]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421172468517731, auc for val: 0.6343091257949716\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 100, the loss is [ 0.17309453]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421444067655031, auc for val: 0.6345188748129511\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 200, the loss is [ 0.17132063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642292568691286, auc for val: 0.6345760016340378\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 300, the loss is [ 0.14985965]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421747433758708, auc for val: 0.6344475242366173\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 400, the loss is [ 0.1456102]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422353941035719, auc for val: 0.634400341013279\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 500, the loss is [ 0.16320306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421731859458122, auc for val: 0.6343965545273421\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 600, the loss is [ 0.12693481]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422770749327664, auc for val: 0.6344975517098156\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 700, the loss is [ 0.16221958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64228713279738, auc for val: 0.6344361196717603\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 800, the loss is [ 0.18800829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6424020277573951, auc for val: 0.6344482797796418\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: iteration 0, the loss is [ 0.17667571]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425085754055386, auc for val: 0.6344277949157824\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 100, the loss is [ 0.16439095]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6424736675304098, auc for val: 0.634479990033147\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 200, the loss is [ 0.15773065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6423616348283266, auc for val: 0.6342986634661915\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 300, the loss is [ 0.16661018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6423922325434015, auc for val: 0.6344226163762795\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 400, the loss is [ 0.19170041]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422952205504577, auc for val: 0.6341649448805928\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 500, the loss is [ 0.15387756]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6423937272093919, auc for val: 0.63423002933642\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 600, the loss is [ 0.13073805]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425109741987514, auc for val: 0.6343657138374506\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 700, the loss is [ 0.17938422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642471344332343, auc for val: 0.6342586372275227\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 800, the loss is [ 0.18009572]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6424295830383767, auc for val: 0.6342190269760585\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 0, the loss is [ 0.18188733]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422202640983828, auc for val: 0.6344689400597923\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 100, the loss is [ 0.18518512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425686764065744, auc for val: 0.634264929660473\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 200, the loss is [ 0.16447666]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425890347668485, auc for val: 0.6341526882937513\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 300, the loss is [ 0.1984823]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642552761309465, auc for val: 0.6343159996076289\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 400, the loss is [ 0.1628076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6426245522727717, auc for val: 0.6342690544492569\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 500, the loss is [ 0.17148086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6426276327363246, auc for val: 0.6342920202006593\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 600, the loss is [ 0.17967047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642612053643407, auc for val: 0.6342596082819905\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 700, the loss is [ 0.19998135]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425518193073743, auc for val: 0.6342821517813213\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 800, the loss is [ 0.17702593]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425401222339039, auc for val: 0.63423000427695\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 0, the loss is [ 0.17952882]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6423093204365149, auc for val: 0.6342990142987732\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 100, the loss is [ 0.18873273]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427512340465071, auc for val: 0.6342260336039074\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 200, the loss is [ 0.16845782]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425752173963934, auc for val: 0.6342882775687952\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 300, the loss is [ 0.14301783]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6426485319342639, auc for val: 0.634185458562843\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 400, the loss is [ 0.17230569]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425539156427071, auc for val: 0.634165462358651\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 500, the loss is [ 0.14998519]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427659074662897, auc for val: 0.6342814826934688\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 600, the loss is [ 0.18426122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6426701056140481, auc for val: 0.6342489930904425\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 700, the loss is [ 0.18582031]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427362009700637, auc for val: 0.6342917921594811\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 800, the loss is [ 0.13759911]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425957582516977, auc for val: 0.6342879342540544\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 0, the loss is [ 0.15827842]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428134728906403, auc for val: 0.6342957152195304\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 100, the loss is [ 0.15344267]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427372439202738, auc for val: 0.6342664883595153\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 200, the loss is [ 0.17905031]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427516903227313, auc for val: 0.6343293675819708\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 300, the loss is [ 0.17517918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427902814901902, auc for val: 0.6343159833189733\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 400, the loss is [ 0.16998053]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428016826759111, auc for val: 0.6343305691835637\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 500, the loss is [ 0.14431934]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428679832518783, auc for val: 0.6342445625761232\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: iteration 600, the loss is [ 0.17089829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429361455708797, auc for val: 0.6344315751368517\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 700, the loss is [ 0.12989977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429144907306626, auc for val: 0.6343927818241137\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 800, the loss is [ 0.14929326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428922610426941, auc for val: 0.6344138129844221\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 0, the loss is [ 0.15123115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429021479293292, auc for val: 0.6344970580382541\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 100, the loss is [ 0.18250279]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6427914348958845, auc for val: 0.6344720424221946\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 200, the loss is [ 0.15463947]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428878775290675, auc for val: 0.6344494939109697\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 300, the loss is [ 0.15827151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429463130407256, auc for val: 0.6345123981928955\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 400, the loss is [ 0.1854904]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642933699704616, auc for val: 0.6345241611081756\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 500, the loss is [ 0.17125873]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430511155849713, auc for val: 0.634500925967469\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 600, the loss is [ 0.16006607]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429177576313245, auc for val: 0.6344676056430079\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 700, the loss is [ 0.17920282]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6428940744759466, auc for val: 0.6343824184802406\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 800, the loss is [ 0.13090028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429479785301035, auc for val: 0.6344175393276308\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 0, the loss is [ 0.18697596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430441091207462, auc for val: 0.6344322191652342\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 100, the loss is [ 0.19237582]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429986282054939, auc for val: 0.6344496029196648\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 200, the loss is [ 0.16417667]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642956714716392, auc for val: 0.6344142440073084\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 300, the loss is [ 0.20377417]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430864100929433, auc for val: 0.6344810036887139\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 400, the loss is [ 0.15193881]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430529450184235, auc for val: 0.6345759765745677\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 500, the loss is [ 0.16093837]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429532604510739, auc for val: 0.6344270268430228\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 600, the loss is [ 0.14237802]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431064166807124, auc for val: 0.6344289401335673\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 700, the loss is [ 0.18109094]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430275105754961, auc for val: 0.6343526628654057\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 800, the loss is [ 0.21029049]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432016666420106, auc for val: 0.6344361296955483\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 0, the loss is [ 0.14871496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429510558245348, auc for val: 0.6344131915095628\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 100, the loss is [ 0.16233452]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431729321385875, auc for val: 0.6344465920243285\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 200, the loss is [ 0.17907193]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431432020671881, auc for val: 0.6344649631218822\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 300, the loss is [ 0.17936106]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432683509135861, auc for val: 0.6345039919936396\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 400, the loss is [ 0.18260686]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643202034646602, auc for val: 0.6345203094676162\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 500, the loss is [ 0.15159892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431553720354473, auc for val: 0.634449455068791\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 600, the loss is [ 0.22649923]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431811801255485, auc for val: 0.6344392984655465\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 700, the loss is [ 0.17572127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431798388914238, auc for val: 0.6344960305999786\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 800, the loss is [ 0.13803639]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432480009012425, auc for val: 0.6344494525628441\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 0, the loss is [ 0.18282977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431843650155251, auc for val: 0.6344339144383886\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 100, the loss is [ 0.13170008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432153630447728, auc for val: 0.634506720969937\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 200, the loss is [ 0.17511666]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432087430587994, auc for val: 0.6345186016647266\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: iteration 300, the loss is [ 0.16556892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432542536555813, auc for val: 0.6344807606118537\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 400, the loss is [ 0.14669326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432195079467268, auc for val: 0.6344378663168284\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 500, the loss is [ 0.16148505]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433040550885049, auc for val: 0.634463021012947\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 600, the loss is [ 0.16186285]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643265627478642, auc for val: 0.6344355671104439\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 700, the loss is [ 0.15570559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433124101299414, auc for val: 0.6344627177933586\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 800, the loss is [ 0.1149137]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432184497692736, auc for val: 0.634438807299932\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 0, the loss is [ 0.15034457]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430556618059418, auc for val: 0.6343935148136151\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 100, the loss is [ 0.15184499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432578157483316, auc for val: 0.6344810776141507\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 200, the loss is [ 0.15056887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432696322435818, auc for val: 0.6344611954305479\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 300, the loss is [ 0.22039464]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432577408488465, auc for val: 0.634404231496017\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 400, the loss is [ 0.17434308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430986769126524, auc for val: 0.6342884805505034\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 500, the loss is [ 0.16732135]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432853907397039, auc for val: 0.6343283990334503\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 600, the loss is [ 0.14647228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433627940628861, auc for val: 0.6343879039982525\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 700, the loss is [ 0.19223997]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432631220174319, auc for val: 0.6343571535224534\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 800, the loss is [ 0.19536291]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432558472600044, auc for val: 0.6343528771238753\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 0, the loss is [ 0.16923639]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429497801371217, auc for val: 0.634192680702135\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 100, the loss is [ 0.15754561]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432875819940955, auc for val: 0.6343208072669737\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 200, the loss is [ 0.162265]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433322468991669, auc for val: 0.634330057970373\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 300, the loss is [ 0.14054082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432335704989847, auc for val: 0.6342829900205973\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 400, the loss is [ 0.15340002]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434019543582186, auc for val: 0.634485955440012\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 500, the loss is [ 0.14917411]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432822610388216, auc for val: 0.6343885618093434\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 600, the loss is [ 0.16948876]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434086826353982, auc for val: 0.6344160495421314\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 700, the loss is [ 0.20365787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643348131387199, auc for val: 0.6344234834339462\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 800, the loss is [ 0.17644343]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433097115069012, auc for val: 0.6344486230943827\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 0, the loss is [ 0.20897129]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433538165595771, auc for val: 0.634573108518211\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 100, the loss is [ 0.1553403]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433388427688975, auc for val: 0.6344490190340109\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 200, the loss is [ 0.1516933]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433643889040396, auc for val: 0.6344992795602813\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 300, the loss is [ 0.16541818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434507335561664, auc for val: 0.6345308507337273\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 400, the loss is [ 0.19052014]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434306241651824, auc for val: 0.6344399663004255\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 500, the loss is [ 0.21345702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643421348996324, auc for val: 0.6344473588441145\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 600, the loss is [ 0.17935501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434224882569144, auc for val: 0.6344274190237305\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 700, the loss is [ 0.14099705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434374686177244, auc for val: 0.6344472022224261\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 800, the loss is [ 0.15267636]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433858669691042, auc for val: 0.6344341512503813\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: iteration 0, the loss is [ 0.16743027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6430861816842964, auc for val: 0.6345932062132571\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 100, the loss is [ 0.2097268]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435270376579052, auc for val: 0.6344218244970233\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 200, the loss is [ 0.19533111]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434214145430354, auc for val: 0.6344319873651354\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 300, the loss is [ 0.19042332]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434521596609152, auc for val: 0.6344383888067807\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 400, the loss is [ 0.16198111]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433831207319434, auc for val: 0.6343871860444332\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 500, the loss is [ 0.16126201]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643434501160412, auc for val: 0.6344382973397147\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 600, the loss is [ 0.15709171]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434920823232468, auc for val: 0.6344098485762473\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 700, the loss is [ 0.15961313]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433568757668264, auc for val: 0.634364267906024\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 800, the loss is [ 0.16689463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434753447231221, auc for val: 0.6344167837846062\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 0, the loss is [ 0.20047173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435844809252997, auc for val: 0.6345056734840855\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 100, the loss is [ 0.188381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434688155595377, auc for val: 0.6344308960252112\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 200, the loss is [ 0.19038902]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643500693290582, auc for val: 0.6344241399920636\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 300, the loss is [ 0.18078353]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643424789812199, auc for val: 0.6344115726677924\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 400, the loss is [ 0.17451727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434063333114016, auc for val: 0.6343879979712654\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 500, the loss is [ 0.1454218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435304628600589, auc for val: 0.6344222129188104\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 600, the loss is [ 0.18204196]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435069958233195, auc for val: 0.6344158791377346\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 700, the loss is [ 0.17715186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434967603333013, auc for val: 0.6343607420385764\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 800, the loss is [ 0.1746002]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64338249100428, auc for val: 0.6343616880335737\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 0, the loss is [ 0.16442624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435984900662632, auc for val: 0.6344295879208702\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 100, the loss is [ 0.16405544]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434447624671776, auc for val: 0.6343531878613049\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 200, the loss is [ 0.18948872]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643468791211408, auc for val: 0.6343835799866812\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 300, the loss is [ 0.15583009]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435356803937524, auc for val: 0.6344213771854814\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 400, the loss is [ 0.15747507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435522572962203, auc for val: 0.6343686670960056\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 500, the loss is [ 0.15505956]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435496334953694, auc for val: 0.63439111536935\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 600, the loss is [ 0.17136109]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435776532459139, auc for val: 0.6344465206048386\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 700, the loss is [ 0.14194795]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435783305876978, auc for val: 0.6343736226062242\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 800, the loss is [ 0.17512195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435670049971229, auc for val: 0.6343854581939676\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 0, the loss is [ 0.18732291]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435982848463117, auc for val: 0.6343356637738415\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 100, the loss is [ 0.17415255]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434741705248976, auc for val: 0.6344426000507364\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 200, the loss is [ 0.146657]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435686918201002, auc for val: 0.6344428957524839\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 300, the loss is [ 0.20235127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434756975004702, auc for val: 0.6344629157631725\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 400, the loss is [ 0.18732497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435725586896, auc for val: 0.6343970945589235\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 500, the loss is [ 0.18626866]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435856351039506, auc for val: 0.6344428982584309\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: iteration 600, the loss is [ 0.18293819]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436221903812753, auc for val: 0.6344453991935501\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 700, the loss is [ 0.14289436]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435146234353909, auc for val: 0.6343578764881667\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 800, the loss is [ 0.16269484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434546142615875, auc for val: 0.6343541927460572\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 0, the loss is [ 0.12750195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436526083839629, auc for val: 0.6343921966854861\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 100, the loss is [ 0.16019391]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436340326932729, auc for val: 0.6344040661035142\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 200, the loss is [ 0.1664983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436045992052838, auc for val: 0.634457020522824\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 300, the loss is [ 0.12894189]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434394284489388, auc for val: 0.6344440108989049\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 400, the loss is [ 0.17328194]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435945918920254, auc for val: 0.6344594525444003\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 500, the loss is [ 0.15055822]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436537260017711, auc for val: 0.6344337039388395\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 600, the loss is [ 0.18179332]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436928985871119, auc for val: 0.6344855707771455\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 700, the loss is [ 0.16049816]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435179800763026, auc for val: 0.634424517137089\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 800, the loss is [ 0.19091345]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435813015233143, auc for val: 0.6343728319799415\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 0, the loss is [ 0.13114978]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438920885504937, auc for val: 0.6343977548759614\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 100, the loss is [ 0.15994498]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436827295713531, auc for val: 0.6343881470751128\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 200, the loss is [ 0.1744481]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436331673684673, auc for val: 0.6344069404247383\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 300, the loss is [ 0.18393643]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435837385005782, auc for val: 0.6344084139215822\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 400, the loss is [ 0.17332278]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435866176862579, auc for val: 0.634396536985713\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 500, the loss is [ 0.17883508]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436040514883055, auc for val: 0.634375575991921\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 600, the loss is [ 0.19224596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436117112553672, auc for val: 0.6343860069963635\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 700, the loss is [ 0.13061135]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436122199380422, auc for val: 0.6344240071768719\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 800, the loss is [ 0.17595468]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435245048340349, auc for val: 0.6344730047058478\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 0, the loss is [ 0.17741251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435310477562449, auc for val: 0.6342347242281493\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 100, the loss is [ 0.17937133]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643574337494401, auc for val: 0.63436797545463\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 200, the loss is [ 0.15902026]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437141575190078, auc for val: 0.6344996216220486\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 300, the loss is [ 0.15517639]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436605168884275, auc for val: 0.634432201623605\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 400, the loss is [ 0.19749574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437087540119796, auc for val: 0.6344625398711206\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 500, the loss is [ 0.15119547]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437223372539096, auc for val: 0.6344168952992484\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 600, the loss is [ 0.16189724]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437020066427742, auc for val: 0.634442232929499\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 700, the loss is [ 0.14145583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643685010720586, auc for val: 0.6344982608928205\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 800, the loss is [ 0.12314595]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436170937379787, auc for val: 0.6343855446491395\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 0, the loss is [ 0.13283263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434116094351983, auc for val: 0.6344040285143091\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 100, the loss is [ 0.14521977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436048133915308, auc for val: 0.6343971459308372\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 200, the loss is [ 0.17641746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436278040551772, auc for val: 0.6344523557024588\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: iteration 300, the loss is [ 0.15864463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436749859385106, auc for val: 0.6344479176702985\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 400, the loss is [ 0.16295844]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436205711146963, auc for val: 0.6344690553333548\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 500, the loss is [ 0.15400165]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436656225753152, auc for val: 0.6345049780837894\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 600, the loss is [ 0.14386308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437665279501662, auc for val: 0.6344413934372496\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 700, the loss is [ 0.13455456]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643679476429317, auc for val: 0.634408863739071\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 800, the loss is [ 0.13849559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436711971376178, auc for val: 0.6344114273228656\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 0, the loss is [ 0.1508577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434516292581626, auc for val: 0.6344888961688321\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 100, the loss is [ 0.18382286]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436343264167441, auc for val: 0.6344585992694423\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 200, the loss is [ 0.21092443]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643690904204742, auc for val: 0.6344663338748986\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 300, the loss is [ 0.17418171]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437501183927814, auc for val: 0.6345061997329582\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 400, the loss is [ 0.15233693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435742336863429, auc for val: 0.6344508408574894\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 500, the loss is [ 0.20277353]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436573241142945, auc for val: 0.6344166359337325\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 600, the loss is [ 0.15264377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436299527969609, auc for val: 0.634413310542046\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 700, the loss is [ 0.17213227]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436010034889255, auc for val: 0.6344373626214788\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 800, the loss is [ 0.1458627]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437366382632489, auc for val: 0.6344547852180882\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 0, the loss is [ 0.16290721]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437724033471401, auc for val: 0.6342784404737948\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 100, the loss is [ 0.13255045]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436228562060072, auc for val: 0.6344412919463955\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 200, the loss is [ 0.13967828]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437989935919268, auc for val: 0.6344610626153562\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 300, the loss is [ 0.14576527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436226539232904, auc for val: 0.6344090817564612\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 400, the loss is [ 0.18676421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436040477781142, auc for val: 0.6344388185766935\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 500, the loss is [ 0.1821221]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436359614516358, auc for val: 0.6344390190524546\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 600, the loss is [ 0.16263324]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436400874161553, auc for val: 0.6344621953034062\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 700, the loss is [ 0.19351661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643691359089644, auc for val: 0.6344863689212692\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 800, the loss is [ 0.13803308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643677493950477, auc for val: 0.6344710350314953\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 0, the loss is [ 0.14130485]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434751709625001, auc for val: 0.6344659642477142\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 100, the loss is [ 0.14505002]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436264804444606, auc for val: 0.6343960708795686\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 200, the loss is [ 0.15856086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437304703022385, auc for val: 0.6345106703424299\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 300, the loss is [ 0.18182179]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436734618228772, auc for val: 0.6344867435603476\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 400, the loss is [ 0.19817175]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436780374934905, auc for val: 0.6344649643748558\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 500, the loss is [ 0.21819171]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437644418951549, auc for val: 0.6344536876132963\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 600, the loss is [ 0.14618443]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643737112162881, auc for val: 0.6344501655047693\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 700, the loss is [ 0.166218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437045238529233, auc for val: 0.6344725072753656\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 800, the loss is [ 0.16811898]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437889606165127, auc for val: 0.6344351285697165\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: iteration 0, the loss is [ 0.16104364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437910399468025, auc for val: 0.6342854759200344\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 100, the loss is [ 0.14472061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437851766079503, auc for val: 0.6344760481784952\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 200, the loss is [ 0.14382459]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437212948447691, auc for val: 0.634450471230305\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 300, the loss is [ 0.14887063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435548054246295, auc for val: 0.6343756875065631\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 400, the loss is [ 0.16460232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436484156360013, auc for val: 0.6344545759715126\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 500, the loss is [ 0.17830743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437602653792799, auc for val: 0.6344786029914753\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 600, the loss is [ 0.16699614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437233364547816, auc for val: 0.6344269103164867\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 700, the loss is [ 0.17982124]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437707424955011, auc for val: 0.6344705952377945\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 800, the loss is [ 0.14963727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436521885139902, auc for val: 0.6344724333499288\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 0, the loss is [ 0.16889568]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438458060793476, auc for val: 0.6345979048639068\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 100, the loss is [ 0.16956641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437839891148741, auc for val: 0.6345039819698517\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 200, the loss is [ 0.17809461]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436695020440059, auc for val: 0.634460550149192\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 300, the loss is [ 0.13586842]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437301642114631, auc for val: 0.6344618319410893\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 400, the loss is [ 0.15518895]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437365848519545, auc for val: 0.6344447539121942\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 500, the loss is [ 0.16205075]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436823453346753, auc for val: 0.6344396906462539\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 600, the loss is [ 0.16313827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437097980443286, auc for val: 0.6344125048800813\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 700, the loss is [ 0.14666142]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437741148274297, auc for val: 0.6344870329972276\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 800, the loss is [ 0.15515028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643601471591384, auc for val: 0.6344615136858187\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 0, the loss is [ 0.132759]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643721766193645, auc for val: 0.6344086244211313\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 100, the loss is [ 0.18751761]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643693802714334, auc for val: 0.6344249932670216\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 200, the loss is [ 0.15227687]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437301645206458, auc for val: 0.6344868600868837\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 300, the loss is [ 0.18608364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436844713515378, auc for val: 0.6344253102693188\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 400, the loss is [ 0.20112446]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437965444019502, auc for val: 0.634488243369635\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 500, the loss is [ 0.17362529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437842178327035, auc for val: 0.6344629032334375\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 600, the loss is [ 0.15707092]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435607350831497, auc for val: 0.634419951301631\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 700, the loss is [ 0.19023234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437915754510681, auc for val: 0.6345593132799034\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 800, the loss is [ 0.16034944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643728573698866, auc for val: 0.6345033617479658\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 0, the loss is [ 0.19158229]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6440041149916291, auc for val: 0.6346022865122594\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 100, the loss is [ 0.18342307]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437814242133089, auc for val: 0.6344742589323278\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 200, the loss is [ 0.18355916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437138024227903, auc for val: 0.6344129120964709\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 300, the loss is [ 0.1795685]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435481029641971, auc for val: 0.6344594337497976\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 400, the loss is [ 0.18882826]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438288344279933, auc for val: 0.6344988046833222\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 500, the loss is [ 0.14063887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437673886372329, auc for val: 0.6344818030858111\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: iteration 600, the loss is [ 0.15017578]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438224171112152, auc for val: 0.6344791455290036\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 700, the loss is [ 0.17738484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643768288281307, auc for val: 0.6344589789204148\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 800, the loss is [ 0.15814629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438140800796649, auc for val: 0.6344994549765722\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 0, the loss is [ 0.13277444]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643982254544982, auc for val: 0.6344880128225099\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 100, the loss is [ 0.18246867]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437180165043512, auc for val: 0.6345043929451617\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 200, the loss is [ 0.18442781]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438336681114876, auc for val: 0.6345171269149094\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 300, the loss is [ 0.16317119]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643604833874878, auc for val: 0.6344388010350643\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 400, the loss is [ 0.15160336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437597971995258, auc for val: 0.6344461133884489\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 500, the loss is [ 0.16415298]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436826960250408, auc for val: 0.6343894601913477\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 600, the loss is [ 0.1534611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643629669353811, auc for val: 0.6344761571871903\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 700, the loss is [ 0.12520266]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436729934885318, auc for val: 0.6344416778622355\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 800, the loss is [ 0.14805527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437931134799185, auc for val: 0.6344764052759446\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 0, the loss is [ 0.13336237]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6434392438669257, auc for val: 0.6345399523332793\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 100, the loss is [ 0.18253425]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643763419273701, auc for val: 0.6343968427112485\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 200, the loss is [ 0.18698433]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438043579100607, auc for val: 0.6344532503255426\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 300, the loss is [ 0.15009856]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437832221101358, auc for val: 0.6344905726473838\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 400, the loss is [ 0.20309727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437438871266336, auc for val: 0.6344576457566038\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 500, the loss is [ 0.16654538]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438510731595533, auc for val: 0.6344670292751947\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 600, the loss is [ 0.17257376]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437751648888397, auc for val: 0.6344865443375601\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 700, the loss is [ 0.1656141]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643685518475713, auc for val: 0.6344382772921386\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 800, the loss is [ 0.13837492]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438494241341488, auc for val: 0.634474390494546\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 0, the loss is [ 0.17464398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.644025853620331, auc for val: 0.634574985472524\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 100, the loss is [ 0.16739838]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437929560286788, auc for val: 0.6345442562972744\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 200, the loss is [ 0.15996072]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643783902698337, auc for val: 0.6344919496652677\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 300, the loss is [ 0.14814068]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437064339830345, auc for val: 0.6344475906442132\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 400, the loss is [ 0.18141823]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437744482808656, auc for val: 0.6344702494171067\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 500, the loss is [ 0.18951161]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643796787187588, auc for val: 0.6345062160216137\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 600, the loss is [ 0.19497509]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437743961835972, auc for val: 0.6344514372728784\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 700, the loss is [ 0.146084]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437773816507959, auc for val: 0.6344778261479012\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 800, the loss is [ 0.12340195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437976257680986, auc for val: 0.6345194825051018\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 0, the loss is [ 0.20035857]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643572355943109, auc for val: 0.6342999252105126\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 100, the loss is [ 0.18617105]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437382562158019, auc for val: 0.6344951434947359\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 200, the loss is [ 0.16709372]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438496799827513, auc for val: 0.6344535598099987\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: iteration 300, the loss is [ 0.17872751]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436989364595426, auc for val: 0.6344661747472632\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 400, the loss is [ 0.16453937]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436857325846643, auc for val: 0.6343780430967555\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 500, the loss is [ 0.15501408]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437048151029339, auc for val: 0.634471434730044\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 600, the loss is [ 0.16377009]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437388370153185, auc for val: 0.6344453415567688\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 700, the loss is [ 0.17345338]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438407076582511, auc for val: 0.6344900326158025\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 800, the loss is [ 0.17477132]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437789225395855, auc for val: 0.6344815537440832\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 0, the loss is [ 0.13638325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437026606412719, auc for val: 0.6345453839734304\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 100, the loss is [ 0.12298427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437731256749925, auc for val: 0.6345145295008301\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 200, the loss is [ 0.21129656]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438411050351895, auc for val: 0.6344667248026326\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 300, the loss is [ 0.16492055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437564438050314, auc for val: 0.6344834181686612\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 400, the loss is [ 0.16957803]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438356059134417, auc for val: 0.6345002255552787\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 500, the loss is [ 0.17059234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438358478488272, auc for val: 0.6345023004794057\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 600, the loss is [ 0.12347358]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437858855636551, auc for val: 0.6345063864260108\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 700, the loss is [ 0.13499287]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437778364584027, auc for val: 0.6344879451619405\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 800, the loss is [ 0.13951093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438284185773946, auc for val: 0.6344721125887111\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 0, the loss is [ 0.19484241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437112795700587, auc for val: 0.6342668229034415\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 100, the loss is [ 0.13684934]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437886262355293, auc for val: 0.6344875893174646\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 200, the loss is [ 0.17518318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437641489446402, auc for val: 0.6344751523024381\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 300, the loss is [ 0.14407706]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643756057945145, auc for val: 0.6345487745197392\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 400, the loss is [ 0.16652842]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438233747270273, auc for val: 0.6345171369386975\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 500, the loss is [ 0.18364902]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437653873755499, auc for val: 0.634475157314332\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 600, the loss is [ 0.17728147]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437771072512372, auc for val: 0.6344927114731597\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 700, the loss is [ 0.14757243]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437268975426885, auc for val: 0.6344349305999024\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 800, the loss is [ 0.12637739]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437537703030776, auc for val: 0.6344274290475185\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 0, the loss is [ 0.1950278]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436311388987153, auc for val: 0.6343239284239787\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 100, the loss is [ 0.16944012]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436815437787813, auc for val: 0.6344735823266343\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 200, the loss is [ 0.17577705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437364228402714, auc for val: 0.6344859416573034\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 300, the loss is [ 0.15110251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437042563326775, auc for val: 0.6344680003296623\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 400, the loss is [ 0.1509136]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436920910794528, auc for val: 0.6345375265765705\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 500, the loss is [ 0.14129612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436688281805262, auc for val: 0.6344630961913574\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 600, the loss is [ 0.14476365]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436718961994794, auc for val: 0.634454935574909\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 700, the loss is [ 0.19000046]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437632086430537, auc for val: 0.6344931374841518\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 800, the loss is [ 0.17638797]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438694418524915, auc for val: 0.6345282508137011\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: iteration 0, the loss is [ 0.16883609]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438603098351776, auc for val: 0.6344220588030691\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 100, the loss is [ 0.17733471]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437399190771276, auc for val: 0.6344573462959356\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 200, the loss is [ 0.20897159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436537503499009, auc for val: 0.6344426814940143\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 300, the loss is [ 0.16649891]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643713930269796, auc for val: 0.634410649226318\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 400, the loss is [ 0.18011829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438988265669253, auc for val: 0.634525122138855\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 500, the loss is [ 0.17580394]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437345053670734, auc for val: 0.6344719158718706\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 600, the loss is [ 0.18381059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437805285886082, auc for val: 0.6344801316191533\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 700, the loss is [ 0.13967133]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438392075815649, auc for val: 0.6344482133720459\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 800, the loss is [ 0.17392494]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437674992473084, auc for val: 0.6344874001184652\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 0, the loss is [ 0.15505685]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438857576502527, auc for val: 0.6347931256540773\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 100, the loss is [ 0.16565394]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437150795015253, auc for val: 0.6344792557906722\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 200, the loss is [ 0.16689064]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437319325040561, auc for val: 0.6344683198379065\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 300, the loss is [ 0.16285619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436913955731911, auc for val: 0.634411811985732\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 400, the loss is [ 0.20613633]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438060034571608, auc for val: 0.6344783022778338\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 500, the loss is [ 0.14179619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436476149303596, auc for val: 0.6344790665916726\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 600, the loss is [ 0.16726314]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438485591185259, auc for val: 0.6345486604991502\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 700, the loss is [ 0.15838398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643834936455814, auc for val: 0.6345056271240657\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 800, the loss is [ 0.16971162]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438045691590731, auc for val: 0.6345428792793907\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 0, the loss is [ 0.14747924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437871495021296, auc for val: 0.6344780404063708\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 100, the loss is [ 0.16303474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437958012815679, auc for val: 0.6345248903387564\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 200, the loss is [ 0.16601929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438338076301364, auc for val: 0.6345390288918048\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 300, the loss is [ 0.16281876]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438310147064026, auc for val: 0.6345175429021136\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 400, the loss is [ 0.1784291]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437067447115489, auc for val: 0.6344823355995515\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 500, the loss is [ 0.11855064]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643842753133046, auc for val: 0.6345372258629288\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 600, the loss is [ 0.17389347]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436721598549427, auc for val: 0.634458457683436\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 700, the loss is [ 0.18748391]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436677384664476, auc for val: 0.6344835321892501\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 800, the loss is [ 0.13114327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437811498910457, auc for val: 0.6344752174570604\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.0005358686327667781. Weight decay is 0.04687949688795907. dropout is 0.75\n",
      " Val aus is 0.6344752174570604. Train auc is 0.6437811498910457\n",
      "This is round you consume 5:20:54.805021 time to run this model.\n",
      "You have finished 1!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.84127337]\n",
      "  acc for train: 0.4447114935877093, acc for val: 0.44570553865108553\n",
      "  auc for train: 0.5016415444994549, auc for val: 0.5054608732760237\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.27271196]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5157570579591673, auc for val: 0.5176669164193699\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.23053378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5236998035466891, auc for val: 0.5291491718987833\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.15770121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5195079111707781, auc for val: 0.5256656800151849\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.18005697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49827025969488836, auc for val: 0.5063485661632761\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 500, the loss is [ 0.23693654]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48134635819251603, auc for val: 0.4904199387318008\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.20512325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4731281329941601, auc for val: 0.4832646493352163\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.15985098]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46755646324937067, auc for val: 0.4775568137280669\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.15797782]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4514525704316439, auc for val: 0.4618339658945022\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.21526173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.455018839156779, auc for val: 0.4657727094130707\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.16246471]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46875288443695284, auc for val: 0.47942863335553404\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.18497954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48400193667652935, auc for val: 0.49415393134370766\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.14950603]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4910106722344043, auc for val: 0.5001499646400853\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.14428629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48873447340145715, auc for val: 0.5009103804785364\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.18300012]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5433425562838269, auc for val: 0.555066773514233\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 600, the loss is [ 0.17187841]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5614418373972541, auc for val: 0.5698603497877022\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.18879315]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5567140390502835, auc for val: 0.5669337720504792\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.16675934]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5606847113522133, auc for val: 0.5723589781826639\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.14297134]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5707835621391124, auc for val: 0.5842307530539175\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.1765916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.578335300954661, auc for val: 0.5902875655891535\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.19379723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5841278257060751, auc for val: 0.5942870106622231\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.19296511]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5986171951150889, auc for val: 0.6010436314544224\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.17810206]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5966395484127156, auc for val: 0.5986382067467231\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.18828633]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5978162254312616, auc for val: 0.6003867099746434\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.16939521]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6058562707061376, auc for val: 0.6072040348272907\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.15954193]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5996404619104894, auc for val: 0.6037981308221418\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.16500063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6082543290690825, auc for val: 0.6089172718628941\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.13591169]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6071273140421071, auc for val: 0.6080144768859668\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.14862877]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6062512909774591, auc for val: 0.6082421459310378\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.18281634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6085024219034527, auc for val: 0.6070357918096911\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.14553128]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.612304038878834, auc for val: 0.6096965374347787\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.15556356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6130745246267841, auc for val: 0.6108636534377925\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 500, the loss is [ 0.14418019]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6143572346590335, auc for val: 0.6115283270646568\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 600, the loss is [ 0.19477403]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6159261812285922, auc for val: 0.6147435472967027\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.15814605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.618030549743848, auc for val: 0.618446620281387\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.14950515]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6161920017430725, auc for val: 0.616038411466556\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.14544427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6168037036742655, auc for val: 0.6154101968627869\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.1862253]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6148051460250141, auc for val: 0.6131133961872959\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: iteration 200, the loss is [ 0.14751926]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6164933448649889, auc for val: 0.6145100982848457\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.16910174]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6182533934902604, auc for val: 0.6154952111152101\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.17212789]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6188910414842903, auc for val: 0.6180990792609389\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.10741019]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.619429355214858, auc for val: 0.6160036264160655\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.16805504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6177947810052639, auc for val: 0.6144754974214607\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 700, the loss is [ 0.1457382]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6190553876506373, auc for val: 0.6149735406076284\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 800, the loss is [ 0.17072694]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6204614012502243, auc for val: 0.618395715726734\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.12972119]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6202690161640115, auc for val: 0.6196672871190996\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.15032773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.62084067268738, auc for val: 0.6193109765370788\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.13375746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6226755053954262, auc for val: 0.6212031494661872\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 300, the loss is [ 0.18266901]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6244597950187838, auc for val: 0.6220639410122526\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.15439029]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6252325879646009, auc for val: 0.6228601893870458\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 500, the loss is [ 0.15865263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6251505543227805, auc for val: 0.6222161008619215\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 600, the loss is [ 0.13692613]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6255579829421469, auc for val: 0.6222584112712926\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 700, the loss is [ 0.17299908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268232832112961, auc for val: 0.6232255965567246\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 800, the loss is [ 0.18689424]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268772325607039, auc for val: 0.624211369704127\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.17030692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266941084982456, auc for val: 0.6239018438998694\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.15223616]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6263388992743367, auc for val: 0.6243290239163974\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.20859325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6255936477735797, auc for val: 0.6226769307349429\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.13596107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6259585513406587, auc for val: 0.6225758771686616\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.17409728]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6253806857349941, auc for val: 0.6224830330847955\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 500, the loss is [ 0.19938587]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6265656397263697, auc for val: 0.6236731035624503\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 600, the loss is [ 0.14780001]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272314922848441, auc for val: 0.6249157726149388\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 700, the loss is [ 0.17655843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277490090023221, auc for val: 0.6250364565171482\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 800, the loss is [ 0.1691388]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6292151526661095, auc for val: 0.6259866564937246\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.16381122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628344790193823, auc for val: 0.6241805127255797\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.15474972]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272448723165095, auc for val: 0.6260126105869406\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.15669823]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277438134205933, auc for val: 0.6248664255063546\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 300, the loss is [ 0.12696318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276839980269853, auc for val: 0.6239157406290312\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.1727827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6296393103830794, auc for val: 0.6279264023209319\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 500, the loss is [ 0.11831658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6267842096416834, auc for val: 0.62569332537204\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 600, the loss is [ 0.15902117]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.626558858424374, auc for val: 0.6236351372122266\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 700, the loss is [ 0.19625658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6281571455725501, auc for val: 0.6281671436385974\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: iteration 800, the loss is [ 0.17396322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273852481741379, auc for val: 0.6247402523272129\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.16387697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.626742700331537, auc for val: 0.6234820025491696\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.14684004]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6267691133373978, auc for val: 0.6229861821380026\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.16758111]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271093725776873, auc for val: 0.6263468788590332\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.13069731]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.626210127194329, auc for val: 0.6259663508050766\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 400, the loss is [ 0.1798638]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.624385591890117, auc for val: 0.6241441677230737\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 500, the loss is [ 0.15899339]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6257925911638368, auc for val: 0.6242824609149449\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 600, the loss is [ 0.13648434]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266685697061902, auc for val: 0.6262381207586596\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 700, the loss is [ 0.189926]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6243606313468217, auc for val: 0.6216804885181317\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 800, the loss is [ 0.23064317]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6284779749279176, auc for val: 0.6274991784503312\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 0, the loss is [ 0.15406814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271363493007258, auc for val: 0.6273635653687906\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.20307605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6261467725101875, auc for val: 0.6253019453145426\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.20138617]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6250423513109894, auc for val: 0.6255991055232636\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.16890809]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274502699708657, auc for val: 0.6274101960308125\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.17127572]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6269910170914064, auc for val: 0.6265546231194019\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 500, the loss is [ 0.16765419]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6294182304461121, auc for val: 0.6256399637363406\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 600, the loss is [ 0.15140267]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6246000124203289, auc for val: 0.6194213747797723\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 700, the loss is [ 0.16431718]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266606705544991, auc for val: 0.6231786050383328\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 800, the loss is [ 0.13952893]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266920900769282, auc for val: 0.6259825166692589\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.16980076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6262112656046671, auc for val: 0.625256873351563\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.16653576]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291018203922574, auc for val: 0.6268175182616378\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.16440551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6293601886012012, auc for val: 0.6261550210497544\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.14208063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276448809399213, auc for val: 0.6241413147023992\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.13744405]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288057222439906, auc for val: 0.6259785259486403\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 500, the loss is [ 0.1383411]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6290822043021138, auc for val: 0.6274038572378426\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 600, the loss is [ 0.18055102]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628747340761992, auc for val: 0.6262003837025876\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 700, the loss is [ 0.19802769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6299321345967803, auc for val: 0.6275004978314337\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 800, the loss is [ 0.15280092]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6298719909285454, auc for val: 0.628102592949484\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 0, the loss is [ 0.19252287]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6304374683603299, auc for val: 0.6279135205003106\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.15237175]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6294596027110704, auc for val: 0.6260764608638637\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.140486]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629828242981774, auc for val: 0.6271774850203509\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.17374066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6296015785113653, auc for val: 0.6286567931552444\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.18298624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631990371831182, auc for val: 0.6298912126301655\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: iteration 500, the loss is [ 0.13687104]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312008271401359, auc for val: 0.630236865419539\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 600, the loss is [ 0.16217864]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6306715076087377, auc for val: 0.6295618209309606\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 700, the loss is [ 0.15499836]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6298611633538456, auc for val: 0.6277421350251563\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 800, the loss is [ 0.1577993]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308415807644098, auc for val: 0.6282635474201956\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.13522504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303367201275358, auc for val: 0.6282826740607741\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 100, the loss is [ 0.18687038]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297054035748167, auc for val: 0.6279681777106157\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.17640339]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6306878295901506, auc for val: 0.6297296291667533\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.18781747]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6302928288746287, auc for val: 0.6278000148833205\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.12440879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629046315545182, auc for val: 0.6279376916122265\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 500, the loss is [ 0.13850701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308674648361352, auc for val: 0.6301943407516983\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 600, the loss is [ 0.13314527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313723740146774, auc for val: 0.6300677766448224\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 700, the loss is [ 0.15329778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316162805166252, auc for val: 0.6297227879314072\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 800, the loss is [ 0.16406612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631945483309794, auc for val: 0.630472688816191\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.18320028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311830733340961, auc for val: 0.6293614591904925\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.1599883]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6302168801782901, auc for val: 0.6278527387555051\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 200, the loss is [ 0.17856872]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631401439343484, auc for val: 0.6287553282447773\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.14044128]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6315012301923527, auc for val: 0.6279375161959355\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.19113527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308671479239688, auc for val: 0.6272273633897019\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 500, the loss is [ 0.18672393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6317865071041632, auc for val: 0.629616248847114\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 600, the loss is [ 0.16782619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6321115435071876, auc for val: 0.6293902775811444\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 700, the loss is [ 0.13782264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311862541274031, auc for val: 0.6287006096387703\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 800, the loss is [ 0.18107907]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319498682147424, auc for val: 0.6298972306619177\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.1346963]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6305996558137543, auc for val: 0.6295866423361264\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.12962787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303628444341427, auc for val: 0.6276287985595896\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.20634593]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316604983436551, auc for val: 0.6291319946343865\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.17118643]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291168534687009, auc for val: 0.6250689160488103\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.1707671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6305678546826994, auc for val: 0.6280397676048892\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 500, the loss is [ 0.17402868]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6304798353430123, auc for val: 0.6291500387058552\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 600, the loss is [ 0.15474845]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312981519485763, auc for val: 0.6291640056015333\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 700, the loss is [ 0.17162636]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6302141276801815, auc for val: 0.6295299127076412\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 800, the loss is [ 0.18480974]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312422335697716, auc for val: 0.6282035024238121\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.15158591]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308126008472968, auc for val: 0.6272257357771168\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.14231044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6307954194928433, auc for val: 0.6277116476737935\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: iteration 200, the loss is [ 0.14981256]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6318212498757829, auc for val: 0.6294634048739106\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.13997671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631852056598296, auc for val: 0.628879373874905\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.17529619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319903150961748, auc for val: 0.6279769372484004\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 500, the loss is [ 0.16390738]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333943824685816, auc for val: 0.6298087494318017\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 600, the loss is [ 0.14715046]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336846359062478, auc for val: 0.6295644333807218\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 700, the loss is [ 0.15243566]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340055590985348, auc for val: 0.6307330516989699\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 800, the loss is [ 0.17016912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6346638015137547, auc for val: 0.6311749366125714\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.13465568]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6347009467114828, auc for val: 0.6312934954717137\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.17183961]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341857225056982, auc for val: 0.6314234989908651\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.15874402]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342489752368766, auc for val: 0.6314744436406703\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 300, the loss is [ 0.13956879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634116672600744, auc for val: 0.6300744562465861\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.14653732]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634310324717257, auc for val: 0.6298243727584555\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 500, the loss is [ 0.13029744]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6346986136195729, auc for val: 0.6304196517006299\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 600, the loss is [ 0.170801]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343431783831825, auc for val: 0.6298327789577113\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 700, the loss is [ 0.18556364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343925196750997, auc for val: 0.6295210679676582\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 800, the loss is [ 0.18782894]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635264279498153, auc for val: 0.6306945352933768\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.15352771]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635161646488221, auc for val: 0.6304898908894632\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.22112559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635035905866324, auc for val: 0.6318062460609019\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.10878966]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357635549059244, auc for val: 0.6321495006589839\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.17611335]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6346172268650503, auc for val: 0.6301080396954837\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.16407593]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339046173947279, auc for val: 0.6301538083117331\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 500, the loss is [ 0.12789206]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353348282430629, auc for val: 0.6321204216498426\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 600, the loss is [ 0.13037066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358199968081689, auc for val: 0.6318103295015599\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 700, the loss is [ 0.16945241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6360917061690661, auc for val: 0.6310256134949217\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 800, the loss is [ 0.16968469]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363053984196606, auc for val: 0.6321675522482936\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.18127659]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636371595264865, auc for val: 0.6326235030424803\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.18782733]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636592295912076, auc for val: 0.632469751916458\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.17350285]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6364583964251027, auc for val: 0.6319242373230456\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 300, the loss is [ 0.18965958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6361988343848393, auc for val: 0.6319112778180667\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.13136643]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6356810196153334, auc for val: 0.630593757381267\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 500, the loss is [ 0.18464804]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365840269779937, auc for val: 0.6311694072404869\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 600, the loss is [ 0.13066079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636527588012984, auc for val: 0.6317698058324093\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 700, the loss is [ 0.15122962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6366070633233694, auc for val: 0.6317684977280683\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: iteration 800, the loss is [ 0.19155177]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371064902306156, auc for val: 0.6323584189555285\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.16040839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636538995382357, auc for val: 0.6313264298803347\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.15954676]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362947224990267, auc for val: 0.6312416712345069\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.1653078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6360312918114637, auc for val: 0.6307607787496976\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.14820614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6359189308347537, auc for val: 0.6310584388948477\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 400, the loss is [ 0.17741363]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362104959796063, auc for val: 0.6302060184647799\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 500, the loss is [ 0.15148818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365981479657634, auc for val: 0.6308570822934154\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 600, the loss is [ 0.14827307]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636300936914723, auc for val: 0.6316403060086073\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 700, the loss is [ 0.16982625]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6372499053532152, auc for val: 0.6333277706321534\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 800, the loss is [ 0.18209726]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6372642103819284, auc for val: 0.6326437874305788\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 0, the loss is [ 0.22523217]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371407947358979, auc for val: 0.6327548422313899\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.13414857]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6373853592557168, auc for val: 0.6328144311454171\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.14157273]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381618732914371, auc for val: 0.6332817464093087\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.16211641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381139355339389, auc for val: 0.6328655111163609\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.19425108]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638156940128441, auc for val: 0.6332650793557237\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 500, the loss is [ 0.14517267]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63831529333113, auc for val: 0.6328907560265721\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 600, the loss is [ 0.12815213]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382003861584022, auc for val: 0.6326412313646252\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 700, the loss is [ 0.15702009]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383564756033799, auc for val: 0.6324839606360229\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 800, the loss is [ 0.1794873]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388204107441545, auc for val: 0.6334247821059025\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.16785324]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384606406903972, auc for val: 0.633376530096163\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.17777602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386980108402651, auc for val: 0.6333348286319161\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.15071514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388907234281483, auc for val: 0.6332774800345187\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.15952225]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388596989637882, auc for val: 0.6336965345178565\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.14978787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6390375923522923, auc for val: 0.6337931412811627\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 500, the loss is [ 0.10484458]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6391552694146502, auc for val: 0.6335583728882035\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 600, the loss is [ 0.14454341]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639628672731522, auc for val: 0.6346434855341302\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 700, the loss is [ 0.14789815]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397176363148736, auc for val: 0.6344332616391917\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 800, the loss is [ 0.17777228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6392399702974768, auc for val: 0.6341188179139207\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 0, the loss is [ 0.15590842]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6393937187663882, auc for val: 0.6345721800648426\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.17849648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6393808302577632, auc for val: 0.6347217262117768\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.13653924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397101033126784, auc for val: 0.6344728894322852\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.16099712]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394333511062571, auc for val: 0.6340880511494659\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.17414528]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394118270502804, auc for val: 0.6336015303076649\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: iteration 500, the loss is [ 0.1395344]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6398645563314426, auc for val: 0.6338825985776405\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 600, the loss is [ 0.14513935]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640136951150167, auc for val: 0.633080779482637\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 700, the loss is [ 0.15365714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411269914827206, auc for val: 0.6339057610458836\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 800, the loss is [ 0.12906034]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406722300216152, auc for val: 0.6342044661709382\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.14693844]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403110530324305, auc for val: 0.6339925257022957\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 100, the loss is [ 0.13790943]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403734762266896, auc for val: 0.6347264624516318\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.18004358]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404972833751893, auc for val: 0.634821716003551\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.19639619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413106273196797, auc for val: 0.6353372118576921\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.12840632]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409143087906151, auc for val: 0.634660241548834\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 500, the loss is [ 0.17136167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408688618854491, auc for val: 0.6333694645785592\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 600, the loss is [ 0.15701889]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406187344749705, auc for val: 0.6326875249767738\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 700, the loss is [ 0.18511373]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403034797592013, auc for val: 0.6325157072257599\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 800, the loss is [ 0.139396]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407727977690657, auc for val: 0.63330436508705\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.15796112]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411097742630852, auc for val: 0.6341463106586025\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.16323464]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406132521263788, auc for val: 0.6336802082730653\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 200, the loss is [ 0.17089392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408366524014736, auc for val: 0.6340364549534372\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.14239427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409964661054759, auc for val: 0.6344189739822959\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.15571612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421370057842787, auc for val: 0.6347950276678602\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 500, the loss is [ 0.1717958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419667284907938, auc for val: 0.6346233226844619\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 600, the loss is [ 0.117594]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422503716817386, auc for val: 0.6341361578142786\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 700, the loss is [ 0.15969434]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6420035455684863, auc for val: 0.6342103188101875\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 800, the loss is [ 0.17993814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413867862601872, auc for val: 0.6337044871407027\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.1776066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414901144671982, auc for val: 0.6334427221805701\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.16831756]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641639594593002, auc for val: 0.6339136848503395\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.15790027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6420631776168115, auc for val: 0.6338838089500479\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.10162695]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6422229480352497, auc for val: 0.6342407096825904\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.14962906]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6425333865363416, auc for val: 0.6343603962178884\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 500, the loss is [ 0.16807066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6421263526658616, auc for val: 0.6336549633628542\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 600, the loss is [ 0.14273079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6424618160975255, auc for val: 0.6341087227063779\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 700, the loss is [ 0.11102507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6429769485533733, auc for val: 0.6345792142581088\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 800, the loss is [ 0.16229378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6432033461219012, auc for val: 0.6350216191557156\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.23027432]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6431910332339844, auc for val: 0.6351835559576564\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.17855376]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436847188522101, auc for val: 0.63522689631125\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: iteration 200, the loss is [ 0.14501467]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435745533038569, auc for val: 0.6353839703230117\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.19996281]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6433147039556611, auc for val: 0.6349660861169293\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.19053583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6436142288519945, auc for val: 0.6352090740160921\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 500, the loss is [ 0.15050662]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435909126963647, auc for val: 0.635364006696131\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 600, the loss is [ 0.13211539]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435154324116673, auc for val: 0.6351686167545372\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 700, the loss is [ 0.12118198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6438672488203, auc for val: 0.6356572789280608\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 800, the loss is [ 0.1713672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.643786550770022, auc for val: 0.6353453474146706\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.1762609]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6435452981369331, auc for val: 0.6353169337344613\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.14982723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6440344685297442, auc for val: 0.6357996994146629\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.15084274]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6441574326918811, auc for val: 0.6352405299159755\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 300, the loss is [ 0.17777541]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6443213801672635, auc for val: 0.6354767592760435\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.17808412]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6439081835145817, auc for val: 0.6351130761979098\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 500, the loss is [ 0.18354671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6440936630846885, auc for val: 0.635341069763119\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 600, the loss is [ 0.18406309]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6440607826744682, auc for val: 0.6350909273852335\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 700, the loss is [ 0.1514276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6441873303402504, auc for val: 0.6349465948610604\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 800, the loss is [ 0.19537424]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6444992414780729, auc for val: 0.6351474515260636\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.17056228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.644322165104593, auc for val: 0.6348806596362223\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.13995923]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6441818976927619, auc for val: 0.6341309291558355\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.15868193]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437133670936875, auc for val: 0.6344328356281994\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.16717945]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6439114387436001, auc for val: 0.6347015483264264\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.18330918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6437972502658292, auc for val: 0.6345374977581798\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 500, the loss is [ 0.16297989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6441102917752421, auc for val: 0.6347153936836742\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 600, the loss is [ 0.16544719]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.644552152205827, auc for val: 0.6353713428560122\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 700, the loss is [ 0.17329895]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6449141073303238, auc for val: 0.6354371590483673\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 800, the loss is [ 0.14798215]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6454483345944493, auc for val: 0.6359205462034281\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.12653044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6452878733074884, auc for val: 0.6358390277470883\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.14859071]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6453558522039113, auc for val: 0.63580900650187\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 200, the loss is [ 0.17862236]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6450749966033006, auc for val: 0.6356577362633908\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 300, the loss is [ 0.14312913]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6450705294557805, auc for val: 0.6354832722323309\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 400, the loss is [ 0.12941492]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6451907672457384, auc for val: 0.635628650989382\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 500, the loss is [ 0.1796325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.644825978076222, auc for val: 0.6353573584187049\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 600, the loss is [ 0.19504024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6451691722323547, auc for val: 0.635401273887138\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 700, the loss is [ 0.11803491]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.645329641171585, auc for val: 0.6355007587305891\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: iteration 800, the loss is [ 0.16282126]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6454882539330679, auc for val: 0.6357239371186124\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 0, the loss is [ 0.13929591]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.645756791157771, auc for val: 0.6355227058145309\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 100, the loss is [ 0.16229254]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6455842068983062, auc for val: 0.6354621070038573\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 200, the loss is [ 0.16093856]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6456976872706244, auc for val: 0.6354337321658267\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 300, the loss is [ 0.17858478]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6457909256126226, auc for val: 0.6356590381028642\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 400, the loss is [ 0.16122007]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6458507958088464, auc for val: 0.6357244295372004\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 500, the loss is [ 0.14348999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6459990055806369, auc for val: 0.6357232041291111\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 600, the loss is [ 0.16783372]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.645983802376467, auc for val: 0.6356106232065689\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 700, the loss is [ 0.16402723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6461558738565875, auc for val: 0.6357884138822889\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 800, the loss is [ 0.15733786]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6463722682085266, auc for val: 0.6356203963999204\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 0, the loss is [ 0.14482102]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6463248339548946, auc for val: 0.635452294968327\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 100, the loss is [ 0.1298013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6463529946927052, auc for val: 0.6355659634718729\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 200, the loss is [ 0.18226655]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6464897511042107, auc for val: 0.6355768367759632\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 300, the loss is [ 0.19003642]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6463859799931232, auc for val: 0.6355569170031552\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 400, the loss is [ 0.1441852]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6466451086366752, auc for val: 0.6356089868231694\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 500, the loss is [ 0.13880235]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6466617667768716, auc for val: 0.6356618510283866\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 600, the loss is [ 0.12216722]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6467329585442967, auc for val: 0.6356615465558244\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 700, the loss is [ 0.11687132]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64709850621603, auc for val: 0.6357666672741082\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 800, the loss is [ 0.16034384]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6470426281855548, auc for val: 0.6356456726344692\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 0, the loss is [ 0.17265821]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6470476268179668, auc for val: 0.6358290014530883\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 100, the loss is [ 0.16194294]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6473503328940855, auc for val: 0.6357282861896538\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 200, the loss is [ 0.13604109]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6472529408384294, auc for val: 0.6355874870507694\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 300, the loss is [ 0.13676439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6474102111290572, auc for val: 0.6356053093459274\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 400, the loss is [ 0.14093097]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6473812192311186, auc for val: 0.6354886374648862\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 500, the loss is [ 0.16249543]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6472914201590823, auc for val: 0.6354003867818954\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 600, the loss is [ 0.14553508]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6472086564598445, auc for val: 0.6352416776397075\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 700, the loss is [ 0.14670174]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.647536637981738, auc for val: 0.6353890686722101\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 800, the loss is [ 0.15519167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6476164908040798, auc for val: 0.6357581420423692\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 0, the loss is [ 0.16790923]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6476860413529612, auc for val: 0.6358084915297588\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 100, the loss is [ 0.14155559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6474979087642476, auc for val: 0.6358673223948145\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 200, the loss is [ 0.1967926]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6475287805696983, auc for val: 0.6358456609888323\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 300, the loss is [ 0.19024785]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6476056289874068, auc for val: 0.6359190977660545\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 400, the loss is [ 0.16566905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6477364523393834, auc for val: 0.6357736162651759\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: iteration 500, the loss is [ 0.14568195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6478083691400087, auc for val: 0.6356626353898016\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 600, the loss is [ 0.17798841]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6479547388888429, auc for val: 0.6359341334481337\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 700, the loss is [ 0.15853079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6479648858753414, auc for val: 0.6358932201042226\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 800, the loss is [ 0.16840248]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6481446407749926, auc for val: 0.6358607593195869\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 0, the loss is [ 0.17854728]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6483069379882406, auc for val: 0.6361266327798478\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 100, the loss is [ 0.14696799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6483769066292946, auc for val: 0.6359034418620895\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 200, the loss is [ 0.15439263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6483026294513947, auc for val: 0.6360195574228937\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 300, the loss is [ 0.1832065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6483249636430826, auc for val: 0.6359312127668899\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 400, the loss is [ 0.18145502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6483875731971548, auc for val: 0.6361517423689202\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 500, the loss is [ 0.18049207]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6482070390800525, auc for val: 0.6359470954590596\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 600, the loss is [ 0.16079743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6481052476651613, auc for val: 0.6356647829863921\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 700, the loss is [ 0.16734408]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6480634350468832, auc for val: 0.6357873200364176\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 800, the loss is [ 0.16747846]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6482682930230089, auc for val: 0.635931702679531\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 0, the loss is [ 0.14733207]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6482560683294292, auc for val: 0.6358200852936153\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 100, the loss is [ 0.13091017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6484108645408808, auc for val: 0.6359496903671918\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 200, the loss is [ 0.14604813]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.648419014130479, auc for val: 0.6359676830667467\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 300, the loss is [ 0.17262627]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6484804704334479, auc for val: 0.6359897742426417\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 400, the loss is [ 0.13235696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6486089165576984, auc for val: 0.6359862684227702\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 500, the loss is [ 0.16569847]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6486113958929786, auc for val: 0.6359179162120377\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 600, the loss is [ 0.16211662]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6485936657394077, auc for val: 0.6358834118276129\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 700, the loss is [ 0.15196753]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6485883841276199, auc for val: 0.635832923260164\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 800, the loss is [ 0.13162617]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6486138134690342, auc for val: 0.6359027151374556\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 0, the loss is [ 0.16649827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6485758173234918, auc for val: 0.6360903040659972\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 100, the loss is [ 0.15937904]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6487983192685383, auc for val: 0.6361252632798051\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 200, the loss is [ 0.138999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6489855371405255, auc for val: 0.6362271676150975\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 300, the loss is [ 0.15409115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490215860540449, auc for val: 0.6362734449385905\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 400, the loss is [ 0.18575634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490321167361518, auc for val: 0.6361593328824232\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 500, the loss is [ 0.17078535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490103011209819, auc for val: 0.636106745584351\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 600, the loss is [ 0.13222603]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490167847574282, auc for val: 0.6359311275646914\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 700, the loss is [ 0.13434052]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490790755442383, auc for val: 0.6358675805073568\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 800, the loss is [ 0.18027377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490966791648296, auc for val: 0.6358747988877285\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 0, the loss is [ 0.15376367]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6489257443172476, auc for val: 0.6358364503805852\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 100, the loss is [ 0.14022954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6491560779348822, auc for val: 0.6358308119998055\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: iteration 200, the loss is [ 0.20516577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6489930117845049, auc for val: 0.6357098800088418\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 300, the loss is [ 0.13881205]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6490654747561956, auc for val: 0.635812234161623\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 400, the loss is [ 0.16835487]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6491087235276572, auc for val: 0.635904880275675\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 500, the loss is [ 0.15544803]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6491767389076273, auc for val: 0.6358720573816959\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 600, the loss is [ 0.13015863]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6493669982861598, auc for val: 0.6359777720094218\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 700, the loss is [ 0.13936849]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6493315125487491, auc for val: 0.6361038036025575\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 800, the loss is [ 0.12529548]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6494411902842531, auc for val: 0.6361613915178946\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 0, the loss is [ 0.16393025]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6495275856423265, auc for val: 0.6362672352018917\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 100, the loss is [ 0.13037057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6494360896988783, auc for val: 0.6359310974933273\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 200, the loss is [ 0.1813346]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.649511039580823, auc for val: 0.635946990209285\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 300, the loss is [ 0.16903347]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6496156200546653, auc for val: 0.6360786288588627\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 400, the loss is [ 0.13818787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6496936205640422, auc for val: 0.6359858599534072\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 500, the loss is [ 0.15395375]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.649493832718805, auc for val: 0.636027401037045\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 600, the loss is [ 0.15347995]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6494510850550446, auc for val: 0.6358936586449498\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 700, the loss is [ 0.15902624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6495680363885413, auc for val: 0.636054040506769\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 800, the loss is [ 0.18895087]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6496702687751175, auc for val: 0.6360767331099472\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 0, the loss is [ 0.15375257]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6495991003509788, auc for val: 0.6360926709329513\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 100, the loss is [ 0.16285098]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6497500265238093, auc for val: 0.6360712112557037\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 200, the loss is [ 0.16758917]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6496893352158916, auc for val: 0.6360214180885511\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 300, the loss is [ 0.16004469]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6498018112085292, auc for val: 0.6361175925759976\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 400, the loss is [ 0.19684684]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.649768096932833, auc for val: 0.6360607451680029\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 500, the loss is [ 0.15093502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6497387499386765, auc for val: 0.6360594859296288\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 600, the loss is [ 0.15633665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6498443630051117, auc for val: 0.6360565000937625\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 700, the loss is [ 0.17396471]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6499006270500647, auc for val: 0.6360389722473786\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 800, the loss is [ 0.15613507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6500508250205733, auc for val: 0.6360791225304242\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 0, the loss is [ 0.13527806]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6500571781046661, auc for val: 0.6361653546730961\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 100, the loss is [ 0.15250921]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6500870415883581, auc for val: 0.6360459187324992\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 200, the loss is [ 0.17260629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6501198283162504, auc for val: 0.6360171504607874\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 300, the loss is [ 0.14741151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6501357803606809, auc for val: 0.6361339576629674\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 400, the loss is [ 0.18388222]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6502336899107161, auc for val: 0.6360936958652796\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 500, the loss is [ 0.18095875]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6503475241425216, auc for val: 0.6361506973890158\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 600, the loss is [ 0.16071126]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6503915936391984, auc for val: 0.6362555361882606\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 700, the loss is [ 0.14137667]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6503252235744416, auc for val: 0.6361844662779923\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: iteration 800, the loss is [ 0.12670904]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6502768213473804, auc for val: 0.6361649624923884\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 0, the loss is [ 0.16066013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504741816454229, auc for val: 0.63635320171418\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 100, the loss is [ 0.15828499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504441732323866, auc for val: 0.6360408466957445\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 200, the loss is [ 0.16446874]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6503931773497784, auc for val: 0.636012971794143\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 300, the loss is [ 0.18135764]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504243662219866, auc for val: 0.6360300485700645\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 400, the loss is [ 0.18356843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504584844447516, auc for val: 0.6360277405928654\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 500, the loss is [ 0.18302673]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.650558212606848, auc for val: 0.63615427212243\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 600, the loss is [ 0.18291701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505497216023624, auc for val: 0.6361388292239611\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 700, the loss is [ 0.20335229]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.65051985510414, auc for val: 0.6360663183941603\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 800, the loss is [ 0.16662237]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504287876877775, auc for val: 0.6360126535388723\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 0, the loss is [ 0.208928]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6504975696087119, auc for val: 0.6361336807558224\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 100, the loss is [ 0.19654435]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505335726859104, auc for val: 0.6361213928446432\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 200, the loss is [ 0.13640715]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505215879180295, auc for val: 0.6360807275894862\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 300, the loss is [ 0.16990255]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505777612951846, auc for val: 0.6361331783134463\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 400, the loss is [ 0.17529093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505420635358048, auc for val: 0.6360858033851615\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 500, the loss is [ 0.15910164]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505710359552397, auc for val: 0.6360579623138447\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 600, the loss is [ 0.1676944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505588316677117, auc for val: 0.6359678960722428\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 700, the loss is [ 0.15248658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6505647718384404, auc for val: 0.6360071755387015\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 800, the loss is [ 0.16127084]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6506611994762672, auc for val: 0.6360447785266082\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 0, the loss is [ 0.15319276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6508020118997287, auc for val: 0.636251377569192\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 100, the loss is [ 0.1642731]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.65067417865269, auc for val: 0.6359511951883733\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 200, the loss is [ 0.16964874]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6507788001705225, auc for val: 0.6358374352177614\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 300, the loss is [ 0.18540274]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6508314754557258, auc for val: 0.635826269970844\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 400, the loss is [ 0.18300766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509045860103752, auc for val: 0.6359758436831953\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 500, the loss is [ 0.16467096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509893594738173, auc for val: 0.6360638600601404\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 600, the loss is [ 0.1506267]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509643263499068, auc for val: 0.6360517087230733\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 700, the loss is [ 0.15031542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.650965899084504, auc for val: 0.6360706962835923\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 800, the loss is [ 0.18235472]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509021181148511, auc for val: 0.6360382430167977\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 0, the loss is [ 0.14792702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511071469916596, auc for val: 0.6361062418890013\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 100, the loss is [ 0.16489631]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509968694419088, auc for val: 0.6360357759119633\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 200, the loss is [ 0.15565525]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510363245428518, auc for val: 0.6360094208672253\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 300, the loss is [ 0.18691988]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509192134392456, auc for val: 0.6360029267055405\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 400, the loss is [ 0.14162198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509756652353333, auc for val: 0.6360207878428772\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: iteration 500, the loss is [ 0.18420471]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510821960330251, auc for val: 0.6361177203792954\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 600, the loss is [ 0.16478944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509878845182175, auc for val: 0.6360443211912783\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 700, the loss is [ 0.14213991]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510306724530119, auc for val: 0.6360412889953924\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 800, the loss is [ 0.14249653]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.650981528728777, auc for val: 0.6359621862719732\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 0, the loss is [ 0.14798197]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.65112532159522, auc for val: 0.636173422569505\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 100, the loss is [ 0.14631066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509634080002848, auc for val: 0.636006736997974\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 200, the loss is [ 0.17567918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509808033863941, auc for val: 0.6359596051465496\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 300, the loss is [ 0.16386576]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509684982280425, auc for val: 0.6359262810631678\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 400, the loss is [ 0.11114925]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510595416827535, auc for val: 0.6360776715871036\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 500, the loss is [ 0.19021615]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510627501479036, auc for val: 0.636060099886647\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 600, the loss is [ 0.15933314]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510689551335304, auc for val: 0.6360198405949061\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 700, the loss is [ 0.1400042]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511217793674517, auc for val: 0.6360814104600474\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 800, the loss is [ 0.17113681]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510860945164457, auc for val: 0.6360168986131127\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 0, the loss is [ 0.18347397]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512901487723991, auc for val: 0.636253741930199\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 100, the loss is [ 0.14282709]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511556831720828, auc for val: 0.636084265986669\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 200, the loss is [ 0.15278642]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511237895954302, auc for val: 0.6360812651151206\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 300, the loss is [ 0.15531614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511036936538893, auc for val: 0.6360688694482197\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 400, the loss is [ 0.18958068]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510547977395094, auc for val: 0.6360300159927533\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 500, the loss is [ 0.17651507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6510880354875214, auc for val: 0.6360098017711713\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 600, the loss is [ 0.1299957]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6511848821450686, auc for val: 0.6361007463472013\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 700, the loss is [ 0.18053547]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512186421024944, auc for val: 0.6360813202459549\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 800, the loss is [ 0.17601401]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512600964554334, auc for val: 0.6360421497881914\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 0, the loss is [ 0.13941938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6509954143512913, auc for val: 0.6359656119015402\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 100, the loss is [ 0.14179234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512292493845908, auc for val: 0.6360582542566717\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 200, the loss is [ 0.16046391]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512897574245214, auc for val: 0.6360521297221715\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 300, the loss is [ 0.14476469]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512696413088157, auc for val: 0.6360324467613562\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 400, the loss is [ 0.22658962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6512903971233236, auc for val: 0.6361127448215005\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 500, the loss is [ 0.16576746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513380699113325, auc for val: 0.6361295735086678\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 600, the loss is [ 0.14000988]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513484439151562, auc for val: 0.6361161278499684\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 700, the loss is [ 0.1745583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514107019286105, auc for val: 0.6361515832412848\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 800, the loss is [ 0.16711463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513499467744857, auc for val: 0.6360335080299162\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 0, the loss is [ 0.16511969]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514168854260466, auc for val: 0.6359556206907986\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 100, the loss is [ 0.14683518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513083673571846, auc for val: 0.6360009144300889\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: iteration 200, the loss is [ 0.14681476]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514323147972895, auc for val: 0.6359879799845802\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 300, the loss is [ 0.1677313]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513818124474086, auc for val: 0.6360649664357467\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 400, the loss is [ 0.1575232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514042620415024, auc for val: 0.6360385913434327\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 500, the loss is [ 0.15676704]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513396982215026, auc for val: 0.6359689911710875\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 600, the loss is [ 0.16398008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651455560459286, auc for val: 0.6360389121046501\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 700, the loss is [ 0.14849694]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514596396599373, auc for val: 0.6360036145879957\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 800, the loss is [ 0.15699278]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514044398214981, auc for val: 0.6360962293777099\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 0, the loss is [ 0.14598347]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514752447241934, auc for val: 0.6359272821889996\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 100, the loss is [ 0.17579924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514124190514828, auc for val: 0.6360211349165386\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 200, the loss is [ 0.17323674]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.65144411529234, auc for val: 0.6360204081919048\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 300, the loss is [ 0.15661816]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515436720126839, auc for val: 0.6362250338012156\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 400, the loss is [ 0.17247997]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6513699118544907, auc for val: 0.6359246233792186\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 500, the loss is [ 0.15087575]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514854592670902, auc for val: 0.6360471854887144\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 600, the loss is [ 0.14896648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515044387502575, auc for val: 0.6359897103409928\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 700, the loss is [ 0.15976956]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515098373876601, auc for val: 0.6360847082863168\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 800, the loss is [ 0.13701245]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515063372087257, auc for val: 0.6359785839362542\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 0, the loss is [ 0.18632156]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514469327187951, auc for val: 0.6357102784544169\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 100, the loss is [ 0.22121251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6514816085523815, auc for val: 0.6359862984941344\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 200, the loss is [ 0.1109416]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515488772563693, auc for val: 0.6360305685540698\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 300, the loss is [ 0.14764829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515844685023429, auc for val: 0.6360509331324726\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 400, the loss is [ 0.16660298]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515822103872138, auc for val: 0.6359778271402562\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 500, the loss is [ 0.13758148]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516267275030018, auc for val: 0.636038570042883\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 600, the loss is [ 0.17943178]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516229266439876, auc for val: 0.6360034805198305\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 700, the loss is [ 0.14595562]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516974054862391, auc for val: 0.6360841206417421\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 800, the loss is [ 0.14923878]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516263576433149, auc for val: 0.6360677655785605\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 0, the loss is [ 0.21561074]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515375649606461, auc for val: 0.6361454010700033\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 100, the loss is [ 0.15019938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516081521214944, auc for val: 0.6360503592706066\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 200, the loss is [ 0.15704533]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515733815234405, auc for val: 0.6359740932792065\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 300, the loss is [ 0.15421501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516524757662696, auc for val: 0.6360146846089265\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 400, the loss is [ 0.19809723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6515581115358287, auc for val: 0.6359594460189143\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 500, the loss is [ 0.15489902]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516872547122539, auc for val: 0.6360401901376269\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 600, the loss is [ 0.19031116]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516334791234678, auc for val: 0.6359704107900706\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 700, the loss is [ 0.13855027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516580471594506, auc for val: 0.635999329418603\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: iteration 800, the loss is [ 0.14992693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516284730706734, auc for val: 0.635970303034349\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 0, the loss is [ 0.14290582]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516792319648179, auc for val: 0.6358002820473434\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 100, the loss is [ 0.17638892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516460011734145, auc for val: 0.6360214218474716\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 200, the loss is [ 0.18321015]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651647769543303, auc for val: 0.6359821123096487\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 300, the loss is [ 0.15520406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516896013309025, auc for val: 0.6360094108434371\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 400, the loss is [ 0.19528663]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517080859673163, auc for val: 0.6360325018921905\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 500, the loss is [ 0.15441363]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517738219758535, auc for val: 0.6360297340737144\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 600, the loss is [ 0.1501679]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517537958322849, auc for val: 0.6359949966362172\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 700, the loss is [ 0.17139034]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517715368072468, auc for val: 0.6359762321049822\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 800, the loss is [ 0.11550098]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517299911681449, auc for val: 0.63595114757538\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 0, the loss is [ 0.17241403]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517954299749065, auc for val: 0.6361342433409269\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 100, the loss is [ 0.15254886]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517974244345722, auc for val: 0.6360668534138476\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 200, the loss is [ 0.17938544]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517751539345003, auc for val: 0.6360685937940482\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 300, the loss is [ 0.1402372]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517151972444434, auc for val: 0.6359923691507738\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 400, the loss is [ 0.17275791]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518272070670139, auc for val: 0.6360533714189165\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 500, the loss is [ 0.17361666]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517912574011095, auc for val: 0.6359997742241978\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 600, the loss is [ 0.1458527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517839827982734, auc for val: 0.6360452571624877\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 700, the loss is [ 0.15711226]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517670501812227, auc for val: 0.636011725085504\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 800, the loss is [ 0.16401233]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518360129739791, auc for val: 0.6360838224340475\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 0, the loss is [ 0.15426789]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519279109321046, auc for val: 0.6362181274112473\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 100, the loss is [ 0.17531987]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517308481450201, auc for val: 0.6359747498373239\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 200, the loss is [ 0.16655673]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651811457382596, auc for val: 0.6359891427439943\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 300, the loss is [ 0.15090118]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518206649950559, auc for val: 0.6359802366083094\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 400, the loss is [ 0.18926542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518393723202385, auc for val: 0.6359822313421319\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 500, the loss is [ 0.16467187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518058434768075, auc for val: 0.6359732901231887\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 600, the loss is [ 0.15522321]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518695607548445, auc for val: 0.6360526497061767\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 700, the loss is [ 0.15729301]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518384560575994, auc for val: 0.6359376041847471\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 800, the loss is [ 0.16026886]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518243524613511, auc for val: 0.6359417602978685\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 0, the loss is [ 0.16614375]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517402891903442, auc for val: 0.6357862161667583\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 100, the loss is [ 0.16189252]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518303185261227, auc for val: 0.6360394847135428\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 200, the loss is [ 0.19661425]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518542185730953, auc for val: 0.6360558798718767\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 300, the loss is [ 0.15293065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518758717901036, auc for val: 0.6359680501879841\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 400, the loss is [ 0.14588551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518431008305241, auc for val: 0.6359982443435463\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: iteration 500, the loss is [ 0.16730672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519325771159244, auc for val: 0.6360343876173179\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 600, the loss is [ 0.14255704]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519604530192635, auc for val: 0.6360646293858734\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 700, the loss is [ 0.15125313]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518337145878161, auc for val: 0.6360037799804985\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 800, the loss is [ 0.13643011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518514029244402, auc for val: 0.6360125996610115\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 0, the loss is [ 0.17184715]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519389685386597, auc for val: 0.6358040960986976\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 100, the loss is [ 0.17174844]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651856102963755, auc for val: 0.636040941921731\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 200, the loss is [ 0.14354949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519221626864756, auc for val: 0.6360103756330373\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 300, the loss is [ 0.14350294]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518410046497825, auc for val: 0.6360010259447311\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 400, the loss is [ 0.19333151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518446643669392, auc for val: 0.6360083107326985\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 500, the loss is [ 0.15587258]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518346357200813, auc for val: 0.6360055228666461\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 600, the loss is [ 0.17702392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518259871870603, auc for val: 0.6359127790206607\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 700, the loss is [ 0.13047414]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518784104111478, auc for val: 0.6360200398176937\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 800, the loss is [ 0.15031615]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518962454549162, auc for val: 0.6359954940666994\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 0, the loss is [ 0.17236814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517860755007109, auc for val: 0.6360417551015368\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 100, the loss is [ 0.14568254]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518543652029439, auc for val: 0.6359739754996968\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 200, the loss is [ 0.1158018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518432376438251, auc for val: 0.6359831272181891\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 300, the loss is [ 0.1445705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519436722881657, auc for val: 0.6360543687858278\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 400, the loss is [ 0.14978625]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518523020274452, auc for val: 0.6360142974401131\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 500, the loss is [ 0.1405437]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518973936045063, auc for val: 0.6359292731639017\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 600, the loss is [ 0.14946488]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519100816082143, auc for val: 0.6359213355767372\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 700, the loss is [ 0.13234875]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519522579798229, auc for val: 0.6360804256228711\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 800, the loss is [ 0.17762718]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519359628972964, auc for val: 0.6360111311760618\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 0, the loss is [ 0.16523004]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519436852738351, auc for val: 0.6361482152484992\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 100, the loss is [ 0.14232829]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519200709888817, auc for val: 0.6360232624655527\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 200, the loss is [ 0.09562134]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519793037278775, auc for val: 0.6360068698131658\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 300, the loss is [ 0.1670336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519419359186764, auc for val: 0.6359817928014047\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 400, the loss is [ 0.19759166]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519631049557311, auc for val: 0.6359929116883022\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 500, the loss is [ 0.20375742]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520491395750044, auc for val: 0.6360469812540328\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 600, the loss is [ 0.16072501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519848785993626, auc for val: 0.6360431797324138\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 700, the loss is [ 0.14137888]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519091353548628, auc for val: 0.6358977345677669\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 800, the loss is [ 0.18763447]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519251050227016, auc for val: 0.6359853512461633\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 0, the loss is [ 0.13659926]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651585624845272, auc for val: 0.6356789967178509\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 100, the loss is [ 0.15832511]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651980849254406, auc for val: 0.6360766391369342\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: iteration 200, the loss is [ 0.17163762]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520091182834229, auc for val: 0.635937124295894\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 300, the loss is [ 0.20423058]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519637984523059, auc for val: 0.6360636057065185\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 400, the loss is [ 0.17331086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520016047597313, auc for val: 0.6359771743410592\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 500, the loss is [ 0.16619442]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651990524196368, auc for val: 0.6360434290741416\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 600, the loss is [ 0.15843561]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520222835104759, auc for val: 0.6359867044575505\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 700, the loss is [ 0.15531908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520188463274964, auc for val: 0.6359826235228395\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 800, the loss is [ 0.16063583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520252825044135, auc for val: 0.6360443299620928\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 0, the loss is [ 0.13269542]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517385846666629, auc for val: 0.6359181367353749\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 100, the loss is [ 0.13860634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519684559017173, auc for val: 0.6359917827591728\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 200, the loss is [ 0.13787264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520374801445155, auc for val: 0.6360324304727005\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 300, the loss is [ 0.18321079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520336367728937, auc for val: 0.6359902240601305\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 400, the loss is [ 0.18204264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519553637963493, auc for val: 0.6359961380950818\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 500, the loss is [ 0.15343985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519547139718169, auc for val: 0.6359968121948283\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 600, the loss is [ 0.21886416]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519590601516443, auc for val: 0.6359887342746311\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 700, the loss is [ 0.14819501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519889044660151, auc for val: 0.6359436134456847\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 800, the loss is [ 0.15543614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652052500699064, auc for val: 0.6360558021875193\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 0, the loss is [ 0.16782385]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520337815476466, auc for val: 0.6359501815328064\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 100, the loss is [ 0.12199805]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520072782604663, auc for val: 0.6359793394792786\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 200, the loss is [ 0.16446702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520515901563028, auc for val: 0.6360686338892005\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 300, the loss is [ 0.1595441]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651964442170482, auc for val: 0.6359342700222459\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 400, the loss is [ 0.19661953]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520232510974269, auc for val: 0.6361185260412601\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 500, the loss is [ 0.19595937]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651959292811552, auc for val: 0.6359212453626448\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 600, the loss is [ 0.17950127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520760097073411, auc for val: 0.6360370652217016\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 700, the loss is [ 0.20056979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652070734588388, auc for val: 0.6360110071316847\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 800, the loss is [ 0.16851822]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520583165783868, auc for val: 0.6360713390590012\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 0, the loss is [ 0.12399536]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521224783064135, auc for val: 0.6361172179369192\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 100, the loss is [ 0.11027925]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520039327501284, auc for val: 0.6359658863027382\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 200, the loss is [ 0.14563814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520505351479713, auc for val: 0.6360542585241592\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 300, the loss is [ 0.1934308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520133709355134, auc for val: 0.6360799256864421\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 400, the loss is [ 0.13993078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520081973057489, auc for val: 0.6359613492856708\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 500, the loss is [ 0.14767586]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520943256073505, auc for val: 0.6360337523597501\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 600, the loss is [ 0.14456736]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520289942415428, auc for val: 0.6359590300317101\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 700, the loss is [ 0.16861296]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652048267989251, auc for val: 0.636031857863808\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: iteration 800, the loss is [ 0.15332493]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519878819218566, auc for val: 0.6360176516501902\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 0, the loss is [ 0.15398507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519490994476632, auc for val: 0.6360074800112636\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 100, the loss is [ 0.16966835]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520453001454605, auc for val: 0.6359990675471402\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 200, the loss is [ 0.18650976]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520210697368785, auc for val: 0.636018281895864\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 300, the loss is [ 0.15548688]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520057056031645, auc for val: 0.6359939140671075\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 400, the loss is [ 0.19199771]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520511140150966, auc for val: 0.6359969738284106\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 500, the loss is [ 0.19198582]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520541796378849, auc for val: 0.6360910207668431\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 600, the loss is [ 0.14710833]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520363664687854, auc for val: 0.6360466416982125\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 700, the loss is [ 0.16713999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520482815932855, auc for val: 0.6359977819963224\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 800, the loss is [ 0.17547478]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519935695676958, auc for val: 0.6359898494210521\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 0, the loss is [ 0.15786467]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521766484121987, auc for val: 0.6359710473006119\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 100, the loss is [ 0.19291979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652076172028207, auc for val: 0.6360083733813737\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 200, the loss is [ 0.14522602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520243160768974, auc for val: 0.6360113980594186\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 300, the loss is [ 0.18282212]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519991484585547, auc for val: 0.6358959440686258\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 400, the loss is [ 0.16538672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520033786176109, auc for val: 0.6360049527637007\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 500, the loss is [ 0.15434949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519808770035445, auc for val: 0.6359599584850785\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 600, the loss is [ 0.13325395]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520032093401367, auc for val: 0.6360475864402365\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 700, the loss is [ 0.1587538]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521477304861972, auc for val: 0.6360424179245218\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 800, the loss is [ 0.10965625]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651997436514491, auc for val: 0.6360166367416498\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 0, the loss is [ 0.19997174]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518319524015798, auc for val: 0.636041988154609\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 100, the loss is [ 0.15994263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520647425522779, auc for val: 0.6359979636774808\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 200, the loss is [ 0.14426368]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652025423878158, auc for val: 0.6360555277863214\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 300, the loss is [ 0.18007244]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520463117136365, auc for val: 0.6360236709349159\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 400, the loss is [ 0.15562569]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520207677427726, auc for val: 0.6360367870615831\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 500, the loss is [ 0.15639886]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519211246831872, auc for val: 0.6359387318609031\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 600, the loss is [ 0.16459373]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652059852906733, auc for val: 0.6360563560018093\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 700, the loss is [ 0.17364429]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520029931442027, auc for val: 0.6359553939025939\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 800, the loss is [ 0.16840477]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519730825874598, auc for val: 0.6359317490395506\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 0, the loss is [ 0.16131881]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517270069376765, auc for val: 0.6358233530485207\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 100, the loss is [ 0.21105927]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521011942534312, auc for val: 0.636015539136858\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 200, the loss is [ 0.14362484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520787185334076, auc for val: 0.6360741407077619\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 300, the loss is [ 0.13250951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520104665514517, auc for val: 0.6359224695177608\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 400, the loss is [ 0.13541707]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652066148482862, auc for val: 0.636025318595077\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: iteration 500, the loss is [ 0.13861623]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520160125143637, auc for val: 0.636025034170091\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 600, the loss is [ 0.11641718]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520734611151582, auc for val: 0.6360093306531327\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 700, the loss is [ 0.13837184]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519691446832574, auc for val: 0.6359980714332023\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 800, the loss is [ 0.16056678]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520290214496118, auc for val: 0.6359565478911934\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 0, the loss is [ 0.18405873]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519460157376926, auc for val: 0.6361476175801365\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 100, the loss is [ 0.10725912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520612378901959, auc for val: 0.6360626659763885\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 200, the loss is [ 0.19223374]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520564387578573, auc for val: 0.6359764751818425\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 300, the loss is [ 0.11371493]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519792026251668, auc for val: 0.6359279688184813\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 400, the loss is [ 0.1799763]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520051708718554, auc for val: 0.6359797203832247\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 500, the loss is [ 0.13742171]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520294605662014, auc for val: 0.6360209068753603\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 600, the loss is [ 0.17333484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651970972725388, auc for val: 0.6359865653774912\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 700, the loss is [ 0.19356525]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652117976066668, auc for val: 0.6360498969233828\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 800, the loss is [ 0.19298665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520693431893863, auc for val: 0.636073005513765\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 0, the loss is [ 0.21734659]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520696355215359, auc for val: 0.6362386009983453\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 100, the loss is [ 0.17225759]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520412555732609, auc for val: 0.6360198305711181\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 200, the loss is [ 0.15104863]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519724966091345, auc for val: 0.6360207389769105\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 300, the loss is [ 0.13663852]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520714508871798, auc for val: 0.6360760627691211\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 400, the loss is [ 0.13124955]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521167693269749, auc for val: 0.6360360340245056\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 500, the loss is [ 0.17316326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520787345336071, auc for val: 0.6360243838768411\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 600, the loss is [ 0.14919716]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520371709619142, auc for val: 0.635967557769396\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 700, the loss is [ 0.12370832]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520944121784787, auc for val: 0.6359840293591139\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 800, the loss is [ 0.16763777]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521274534409476, auc for val: 0.636025859879632\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 0, the loss is [ 0.12114815]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652109818051844, auc for val: 0.6360388607327365\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 100, the loss is [ 0.15834306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520358917961968, auc for val: 0.6360553486111099\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 200, the loss is [ 0.16964026]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520093817069992, auc for val: 0.6359888733546903\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 300, the loss is [ 0.13783789]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520509844675867, auc for val: 0.6360841043530865\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 400, the loss is [ 0.12825318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520815762308961, auc for val: 0.6359855742754474\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 500, the loss is [ 0.13683583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521281004055409, auc for val: 0.6360501287234814\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 600, the loss is [ 0.18346658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520698357172701, auc for val: 0.6360373797180516\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 700, the loss is [ 0.159991]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520576873144974, auc for val: 0.6360312852549156\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 800, the loss is [ 0.1683701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520677184348161, auc for val: 0.6360179536168052\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 0, the loss is [ 0.14510328]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519977118415976, auc for val: 0.6358429307595614\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 100, the loss is [ 0.17557222]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520598168869598, auc for val: 0.6360312539305779\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: iteration 200, the loss is [ 0.13278136]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520524495293434, auc for val: 0.6360132061001889\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 300, the loss is [ 0.11585113]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520849222823039, auc for val: 0.635962448143436\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 400, the loss is [ 0.15421635]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520614121918872, auc for val: 0.6360008818527777\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 500, the loss is [ 0.13051794]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520836045460567, auc for val: 0.6360256656687384\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 600, the loss is [ 0.14816828]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521430594327515, auc for val: 0.6360883243678568\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 700, the loss is [ 0.16420834]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520549783338399, auc for val: 0.63598465333992\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 800, the loss is [ 0.18548754]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520751946247083, auc for val: 0.6359676129002303\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 0, the loss is [ 0.1618301]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516277081529177, auc for val: 0.6356654996872378\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 100, the loss is [ 0.17867152]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520616529678381, auc for val: 0.6360031422169836\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 200, the loss is [ 0.19301927]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520887255374832, auc for val: 0.636000822963023\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 300, the loss is [ 0.16665643]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520684968793106, auc for val: 0.6360741958385963\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 400, the loss is [ 0.15042947]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521355060245044, auc for val: 0.6360603179040372\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 500, the loss is [ 0.18050233]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.652069533104799, auc for val: 0.6360039366021869\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 600, the loss is [ 0.16668049]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520860034938607, auc for val: 0.6359514019290018\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 700, the loss is [ 0.14694227]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.65208367326189, auc for val: 0.6359570064794968\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 800, the loss is [ 0.18045713]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520364646342613, auc for val: 0.6359347185867614\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 0, the loss is [ 0.18409649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518854225952511, auc for val: 0.6359884373199101\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 100, the loss is [ 0.13843814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521529896049509, auc for val: 0.6360207515066455\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 200, the loss is [ 0.16179501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520684011872955, auc for val: 0.6359658650021887\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 300, the loss is [ 0.15170364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521155165190741, auc for val: 0.6360288269208956\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 400, the loss is [ 0.16701272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520325445853544, auc for val: 0.6358848602649864\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 500, the loss is [ 0.18288037]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521067722167423, auc for val: 0.6360377418273951\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 600, the loss is [ 0.15451093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521640930478267, auc for val: 0.636087894597944\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 700, the loss is [ 0.17721809]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520766825659774, auc for val: 0.6359685012584465\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 800, the loss is [ 0.17238238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520900517762518, auc for val: 0.6360279247799708\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 0, the loss is [ 0.18910535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518254499822904, auc for val: 0.6357379679159394\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 100, the loss is [ 0.1651727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520686170740468, auc for val: 0.6360406938329767\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 200, the loss is [ 0.15633085]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521021920629814, auc for val: 0.6360387041110482\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 300, the loss is [ 0.20275897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521107868755254, auc for val: 0.6360425920878392\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 400, the loss is [ 0.15127602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6519560067415688, auc for val: 0.6359751608126342\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 500, the loss is [ 0.13497773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520353613161484, auc for val: 0.6360174524274026\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 600, the loss is [ 0.16755635]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520732930744142, auc for val: 0.6359812515168497\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 700, the loss is [ 0.19429238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520758326230063, auc for val: 0.6359833201761091\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: iteration 800, the loss is [ 0.13490067]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521411633704487, auc for val: 0.6359602942819782\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 0, the loss is [ 0.15400496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6518940362679339, auc for val: 0.6358669339730274\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 100, the loss is [ 0.15220235]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520060671149213, auc for val: 0.6359577745522564\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 200, the loss is [ 0.16376629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520560309460062, auc for val: 0.636034880035906\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 300, the loss is [ 0.16370682]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521577451425425, auc for val: 0.6360428627301167\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 400, the loss is [ 0.15443143]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521312542999619, auc for val: 0.6360949613685214\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 500, the loss is [ 0.15303044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520244270734512, auc for val: 0.6359963849308625\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 600, the loss is [ 0.20784916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521249802893192, auc for val: 0.6360116323654644\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 700, the loss is [ 0.17760068]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520471615020166, auc for val: 0.6359407103060699\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 800, the loss is [ 0.13863839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520375056520803, auc for val: 0.6359199886302176\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 0, the loss is [ 0.21546946]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520271420058736, auc for val: 0.6359933765414731\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 100, the loss is [ 0.17829661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520172579791775, auc for val: 0.6358906941096332\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 200, the loss is [ 0.1657149]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520553662034133, auc for val: 0.6360062671329091\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 300, the loss is [ 0.18253613]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520954487904456, auc for val: 0.6360497891676611\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 400, the loss is [ 0.18147966]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520041086750284, auc for val: 0.6359507378530433\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 500, the loss is [ 0.18029393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521054525481041, auc for val: 0.6360626045806868\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 600, the loss is [ 0.17394598]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521310789161312, auc for val: 0.6360161856711875\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 700, the loss is [ 0.15377156]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521560305704265, auc for val: 0.6360097140630258\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 800, the loss is [ 0.15451279]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520723221637504, auc for val: 0.636000291702256\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 0, the loss is [ 0.14723901]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521036173947736, auc for val: 0.636116619015583\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 100, the loss is [ 0.16643895]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521173236140834, auc for val: 0.6360416498517623\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 200, the loss is [ 0.12377574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520901949277962, auc for val: 0.6359690939149152\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 300, the loss is [ 0.12398871]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521533263048038, auc for val: 0.6359894647581855\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 400, the loss is [ 0.18065012]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521309479000038, auc for val: 0.6360576966834612\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 500, the loss is [ 0.16175207]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521216304504247, auc for val: 0.6360414731824977\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 600, the loss is [ 0.19603266]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520810261177528, auc for val: 0.6360679898608181\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 700, the loss is [ 0.17058888]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520922656009732, auc for val: 0.6360403066641631\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 800, the loss is [ 0.13866988]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520929949627299, auc for val: 0.6359463900349753\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 0, the loss is [ 0.14896312]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.651972407409954, auc for val: 0.6358268187732399\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 100, the loss is [ 0.22395226]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521479193967668, auc for val: 0.6360264049231072\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 200, the loss is [ 0.15767497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521011208998589, auc for val: 0.6360389409230409\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 300, the loss is [ 0.18977465]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520975356184134, auc for val: 0.6360514556224249\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 400, the loss is [ 0.17345949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520785494105245, auc for val: 0.635934173543286\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: iteration 500, the loss is [ 0.20992255]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520393769024793, auc for val: 0.6360068735720863\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 600, the loss is [ 0.17661555]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521373810623906, auc for val: 0.6359788683612402\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 700, the loss is [ 0.18529996]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521984768584463, auc for val: 0.6360611335897899\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 800, the loss is [ 0.12021872]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521538912587121, auc for val: 0.636070440676997\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 0, the loss is [ 0.20924591]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6517645038306135, auc for val: 0.6358409498084474\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 100, the loss is [ 0.16418985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520459437090453, auc for val: 0.6359786039838302\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 200, the loss is [ 0.15513523]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521968897468579, auc for val: 0.6360411198439689\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 300, the loss is [ 0.14800321]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521535144424168, auc for val: 0.6361014354826299\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 400, the loss is [ 0.13348156]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521953939987282, auc for val: 0.6360575275320379\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 500, the loss is [ 0.15262191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520882119078867, auc for val: 0.6360048612966347\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 600, the loss is [ 0.18339525]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520902131695697, auc for val: 0.6360025545724091\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 700, the loss is [ 0.19724634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521023552340992, auc for val: 0.635995822345758\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 800, the loss is [ 0.16584507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521321173831935, auc for val: 0.6360643963328012\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 0, the loss is [ 0.16277769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6516257716649897, auc for val: 0.6359722388784167\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 100, the loss is [ 0.14923029]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521465691190509, auc for val: 0.6360503417289776\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 200, the loss is [ 0.17813726]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520410763246477, auc for val: 0.635989460999265\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 300, the loss is [ 0.15456972]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520827385255904, auc for val: 0.6359639291581209\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 400, the loss is [ 0.12462079]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521142157878701, auc for val: 0.6360447196368534\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 500, the loss is [ 0.14431137]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521196189084203, auc for val: 0.6361170588092839\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 600, the loss is [ 0.15317994]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6520536121332201, auc for val: 0.6359088797671082\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 700, the loss is [ 0.16695563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521589072053497, auc for val: 0.6360226008955412\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 800, the loss is [ 0.16661216]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6521382494017264, auc for val: 0.6359832863458245\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.00029890640322661804. Weight decay is 0.03493291532559407. dropout is 0.75\n",
      " Val aus is 0.6359832863458245. Train auc is 0.6521382494017264\n",
      "This is round you consume 5:47:10.407010 time to run this model.\n",
      "You have finished 2!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.74245459]\n",
      "  acc for train: 0.941346674382572, acc for val: 0.942569396479307\n",
      "  auc for train: 0.48181177996053365, auc for val: 0.49053053995620244\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.41305611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5079059006060999, auc for val: 0.5108866683057565\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.29183438]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5222063296095584, auc for val: 0.5299522176548498\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.1897226]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5300151885411851, auc for val: 0.5412429022559178\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.25294885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5301128750932691, auc for val: 0.5414082747112137\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 500, the loss is [ 0.16168679]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5356525313758523, auc for val: 0.5480334974247485\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.19094718]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.532450558132915, auc for val: 0.5446350085168118\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.11982665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5303496696997245, auc for val: 0.5444630366500565\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.15347631]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.53119128483751, auc for val: 0.5454902769556601\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.19575194]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5305247931985987, auc for val: 0.5447925874768966\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: iteration 100, the loss is [ 0.20093232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5249345260430415, auc for val: 0.5385084041042841\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.18876381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5176796805161146, auc for val: 0.5323764595186714\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.17014645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5113951693367562, auc for val: 0.5256577524518085\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.17441703]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5090518396179659, auc for val: 0.5237527716275155\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.16229877]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5054398280999153, auc for val: 0.5204096215474716\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 600, the loss is [ 0.22239615]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5012173376997471, auc for val: 0.5166250012880568\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.18219678]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5012036625532887, auc for val: 0.5165704919286254\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.19411328]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5002943219715177, auc for val: 0.5158203642556369\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.13455477]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49946132676736255, auc for val: 0.5153836979766904\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.19332649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49499277957754995, auc for val: 0.5107556887202434\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.21438925]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4908106385117035, auc for val: 0.5074122517092664\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.17064518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4893866845916722, auc for val: 0.5060258929080136\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.17379032]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4802751694852257, auc for val: 0.4974101288213136\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.16212976]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47728816557161774, auc for val: 0.49456880340148024\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.18756163]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47552338560229335, auc for val: 0.4923829447591847\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.18259041]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47287555198785286, auc for val: 0.4891411401882491\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.1417383]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47487891595793813, auc for val: 0.49117109509603807\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.20229505]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4749715576548113, auc for val: 0.49130624081846075\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.1309664]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4753778524242829, auc for val: 0.4925294286388686\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.16845459]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47102399891661184, auc for val: 0.4874089356397027\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.14442252]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4754534364397431, auc for val: 0.49188245702170563\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.18279634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47394247003316625, auc for val: 0.4903153668159128\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 500, the loss is [ 0.16982134]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4721307413041897, auc for val: 0.48939876281796907\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 600, the loss is [ 0.11141495]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4691703192874386, auc for val: 0.4859177981819334\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.15331018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46646029668455935, auc for val: 0.4830062310673197\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.19258362]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47736239088413623, auc for val: 0.4942918924975996\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.15955222]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47773864245752873, auc for val: 0.4946260880972288\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.16902347]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4738417362546588, auc for val: 0.4909470834806329\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.16995519]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4725062756512428, auc for val: 0.48912925698751253\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.13712466]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4724785711896561, auc for val: 0.489053024826397\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.1761393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47706854659973774, auc for val: 0.49335092192387286\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.1346589]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4794080144732457, auc for val: 0.4970046390291584\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.11985503]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48467353547094577, auc for val: 0.5020445006772272\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: iteration 700, the loss is [ 0.17128272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4968013438226014, auc for val: 0.5136716625426798\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 800, the loss is [ 0.19602317]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48632590878183085, auc for val: 0.5032105704473628\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.11789013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4840565804500599, auc for val: 0.5014073160361243\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.16586407]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4904036132210405, auc for val: 0.5074521000256971\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.1590945]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49078934796588636, auc for val: 0.507843716895187\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 300, the loss is [ 0.15458141]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4917444028957736, auc for val: 0.5088217316306366\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.15555413]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48889250157593656, auc for val: 0.5063713903286724\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 500, the loss is [ 0.17590077]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4939232207263426, auc for val: 0.51136525406634\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 600, the loss is [ 0.13558011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49634142133092307, auc for val: 0.5139879970049723\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 700, the loss is [ 0.13733496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4958742812033027, auc for val: 0.5138734990329651\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 800, the loss is [ 0.12034583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5028020850461485, auc for val: 0.5205088983973205\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.24178833]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49883841310208765, auc for val: 0.5159855074167812\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.11357707]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5063237196298809, auc for val: 0.5237025449315297\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.13620904]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5133362146935971, auc for val: 0.5307021385872097\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.15282929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5183433364867975, auc for val: 0.535684760646576\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.16055603]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5191719107662313, auc for val: 0.5365277912931854\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 500, the loss is [ 0.14951612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5135739221616831, auc for val: 0.531037682386332\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 600, the loss is [ 0.19010445]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5204500805292752, auc for val: 0.5380257812630622\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 700, the loss is [ 0.12422509]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5183838086439075, auc for val: 0.5357717596090338\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 800, the loss is [ 0.14104849]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5358706457878984, auc for val: 0.552989277032683\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.09199238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5332051776346065, auc for val: 0.5502580466359546\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.18540518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5291354380483908, auc for val: 0.5474907882390172\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.20385215]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5375048414806928, auc for val: 0.5551769524865631\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 300, the loss is [ 0.18489574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5365666870128657, auc for val: 0.5535007282883448\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.12419978]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.539176193038015, auc for val: 0.5571001991586353\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 500, the loss is [ 0.2184072]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5481877906080218, auc for val: 0.5655210481807005\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 600, the loss is [ 0.15112971]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5421537065143782, auc for val: 0.5586635342028288\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 700, the loss is [ 0.07818948]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5451312192177851, auc for val: 0.5622738771242362\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 800, the loss is [ 0.2048554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5492894246033643, auc for val: 0.5649862602934781\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.15041938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5434951605452262, auc for val: 0.56009054447653\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.11467199]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5550935027356348, auc for val: 0.5701827448828461\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.15138605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5521170517652811, auc for val: 0.5676002587300077\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.16178088]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5554327391998789, auc for val: 0.570151979371365\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: iteration 400, the loss is [ 0.13332924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5543263738604836, auc for val: 0.5688382917805218\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 500, the loss is [ 0.114853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5577311342517781, auc for val: 0.5718095530589373\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 600, the loss is [ 0.2153535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5560806860663604, auc for val: 0.5706187759042248\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 700, the loss is [ 0.15304773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5618206115914912, auc for val: 0.5763934125409056\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 800, the loss is [ 0.15626672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5649223510041875, auc for val: 0.5785690281247846\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 0, the loss is [ 0.10007361]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5710845457589588, auc for val: 0.5838395672073137\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.13984694]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5776256115594174, auc for val: 0.590060377685909\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.18128186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5696594954774233, auc for val: 0.5823803053955525\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.15199047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5555295737220092, auc for val: 0.5691118146440407\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.17756234]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5722886270227855, auc for val: 0.5834004363294797\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 500, the loss is [ 0.16883953]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5742244968947667, auc for val: 0.5854760733983461\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 600, the loss is [ 0.16193466]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5735691956563379, auc for val: 0.5842390063904055\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 700, the loss is [ 0.18225263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5731989326407512, auc for val: 0.5836109822386093\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 800, the loss is [ 0.14179051]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5708432279656368, auc for val: 0.5822362359958158\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.14429563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5775557912487161, auc for val: 0.5885507325564737\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.16065463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5794308712608255, auc for val: 0.5898006275071749\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.15596962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5807224248430217, auc for val: 0.5911092443142368\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.16096982]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5812113883926726, auc for val: 0.5912301600165448\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.12587093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5833934291426781, auc for val: 0.5934356928488411\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 500, the loss is [ 0.1663523]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5822394434217247, auc for val: 0.5924631260421983\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 600, the loss is [ 0.16550958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5825866637536925, auc for val: 0.5925705697733633\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 700, the loss is [ 0.19869418]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5823718287642032, auc for val: 0.5924893557895856\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 800, the loss is [ 0.172672]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.583632975165103, auc for val: 0.5933922058973473\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 0, the loss is [ 0.19076826]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5858185330217904, auc for val: 0.5952060642233723\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.17332998]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5893182437764428, auc for val: 0.5984665243168478\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.17067069]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5871553643862698, auc for val: 0.5965606375927095\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.17801073]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5830455578267432, auc for val: 0.5924551245533851\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.15808655]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5852408313602002, auc for val: 0.5940813789151864\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 500, the loss is [ 0.17300946]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5849361430371283, auc for val: 0.5944082997506361\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 600, the loss is [ 0.1113819]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5889602061500966, auc for val: 0.5972457760358573\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 700, the loss is [ 0.16205719]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5911326055817482, auc for val: 0.5994353961046197\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 800, the loss is [ 0.12159357]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5930405493855131, auc for val: 0.6012561996627918\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.13847023]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5893433768436295, auc for val: 0.5983646325112905\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: iteration 100, the loss is [ 0.15358487]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5892958834588251, auc for val: 0.598272927380342\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.15740569]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5919137842553752, auc for val: 0.6006934353831138\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.13139804]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5909566586523111, auc for val: 0.6000252822488216\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.22086073]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5913310878261554, auc for val: 0.600673741145537\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 500, the loss is [ 0.12362178]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5900786786936834, auc for val: 0.5992559978638907\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 600, the loss is [ 0.17062275]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5920566510426314, auc for val: 0.6001091575483274\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 700, the loss is [ 0.14941198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5931823746138811, auc for val: 0.6010913258909514\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 800, the loss is [ 0.12237314]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.595630528596995, auc for val: 0.6032825773312194\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.13643876]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5962325309289134, auc for val: 0.603418860753586\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.13439371]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5983022596303558, auc for val: 0.6048259362187971\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 200, the loss is [ 0.14499003]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5979063806816546, auc for val: 0.6046032101542096\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.16287723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6026553169155326, auc for val: 0.6085265333278322\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.16754097]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6034446386086274, auc for val: 0.6085190643527594\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 500, the loss is [ 0.18376319]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6018653971859911, auc for val: 0.6073101190822011\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 600, the loss is [ 0.17291249]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6002156619756521, auc for val: 0.6055310194942228\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 700, the loss is [ 0.15281782]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6010254157690711, auc for val: 0.6066458539246999\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 800, the loss is [ 0.12020255]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6019749215669248, auc for val: 0.6080325234633823\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.13195381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6053179649370218, auc for val: 0.6109872818277423\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.16436245]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6066884047594521, auc for val: 0.6129034040924561\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.1313971]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6091995034505778, auc for val: 0.6144715643376234\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.16716352]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6071196332506283, auc for val: 0.6120468964628096\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.1524158]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6118799018770985, auc for val: 0.616158943758971\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 500, the loss is [ 0.15375149]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6096901532048409, auc for val: 0.6143803804436536\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 600, the loss is [ 0.18197815]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6087488619249317, auc for val: 0.6132245199016498\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 700, the loss is [ 0.12685682]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6070710993890747, auc for val: 0.6117582940631388\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 800, the loss is [ 0.1360534]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6145816438742522, auc for val: 0.617163289732662\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.14944568]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6184177752899023, auc for val: 0.6199184957774392\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.17567451]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6189470863960747, auc for val: 0.6204960025433959\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 200, the loss is [ 0.18380028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6170304595081328, auc for val: 0.6182270830343738\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.15434608]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6160170902661674, auc for val: 0.617418570554898\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.17659695]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6180640120357244, auc for val: 0.61905955737919\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 500, the loss is [ 0.13817276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.614953927166252, auc for val: 0.6166049735089325\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 600, the loss is [ 0.17321438]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6157043373787127, auc for val: 0.616981804038071\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: iteration 700, the loss is [ 0.12816933]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6138212626774885, auc for val: 0.6156546419701379\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 800, the loss is [ 0.16693166]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6140899272854232, auc for val: 0.6158983302814909\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.13664187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6149670287789848, auc for val: 0.6166293288079538\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.16961937]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620261474350112, auc for val: 0.6211506122870551\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.17324461]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6174795805510414, auc for val: 0.6185979080614952\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 300, the loss is [ 0.18189692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6169257405977808, auc for val: 0.618199350971752\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.16408819]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6173609252349327, auc for val: 0.6187025977568927\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 500, the loss is [ 0.12687586]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6167278938009151, auc for val: 0.6182332025569801\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 600, the loss is [ 0.12878095]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6174999379064716, auc for val: 0.6192838421428197\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 700, the loss is [ 0.17003684]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6160617270356221, auc for val: 0.6182242638439839\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 800, the loss is [ 0.1446847]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.616035388851951, auc for val: 0.6179509214086502\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.1356896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6173600122960067, auc for val: 0.6190165340278937\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.14462863]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.615742098622774, auc for val: 0.6170890660880776\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.12873799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6176415600018705, auc for val: 0.6185858118552625\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.1375519]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6196622490190233, auc for val: 0.6203448024714331\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.16305487]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6171704869942652, auc for val: 0.6182272509328237\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 500, the loss is [ 0.14837526]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620947337593025, auc for val: 0.6217652809942442\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 600, the loss is [ 0.13890657]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6196333269963524, auc for val: 0.6203664713952564\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 700, the loss is [ 0.14354667]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6173796987251919, auc for val: 0.6185292451133332\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 800, the loss is [ 0.15172523]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.619655121200627, auc for val: 0.6205238511325537\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.14099474]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6166079393768111, auc for val: 0.6178402813420698\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.15301162]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6170832514324726, auc for val: 0.618364990310405\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.1467054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6179211933263625, auc for val: 0.6189618605289329\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 300, the loss is [ 0.13432559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6193026175563672, auc for val: 0.6200528395968176\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.16145386]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6208855860206717, auc for val: 0.6213308838503182\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 500, the loss is [ 0.13354957]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621397123455822, auc for val: 0.6213805016011797\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 600, the loss is [ 0.12983377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6223713900650102, auc for val: 0.6223614934016811\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 700, the loss is [ 0.13606106]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6253557601293327, auc for val: 0.6247500718805841\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 800, the loss is [ 0.17158476]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6238340022451248, auc for val: 0.6234841363630513\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.14287739]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247698129542423, auc for val: 0.6244868108700844\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.15082513]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621723425729712, auc for val: 0.6216507567097934\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.11672302]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6219989776892746, auc for val: 0.6217300586560001\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.13176954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6231860576202172, auc for val: 0.6227705040493898\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: iteration 400, the loss is [ 0.16215523]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6253167252075452, auc for val: 0.6240788188898365\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 500, the loss is [ 0.13700038]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6266608579191557, auc for val: 0.625033089777336\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 600, the loss is [ 0.1207856]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6263181099135166, auc for val: 0.6248646964029154\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 700, the loss is [ 0.20446002]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6270894226476297, auc for val: 0.625604859177606\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 800, the loss is [ 0.18647043]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303683845998808, auc for val: 0.6280881962838931\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 0, the loss is [ 0.15304276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6306686849261784, auc for val: 0.6282955684111307\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.20138638]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6300728842561738, auc for val: 0.627863455437907\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.18198317]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303365194680276, auc for val: 0.6282888437023206\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.14040272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6283261726088905, auc for val: 0.6267339925417403\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.11678035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297712232945433, auc for val: 0.6278423716527113\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 500, the loss is [ 0.19743305]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6287367952391203, auc for val: 0.6267773404131749\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 600, the loss is [ 0.18158343]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6294678484564575, auc for val: 0.6274454396696063\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 700, the loss is [ 0.17516603]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277720484395237, auc for val: 0.6257714896183026\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 800, the loss is [ 0.16369781]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6282915928537973, auc for val: 0.6260287313440764\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.14638275]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6278923837765925, auc for val: 0.6256833203785896\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.12289223]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.627830248044857, auc for val: 0.6258940467159042\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.17554754]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628518123138957, auc for val: 0.6265152421620894\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.13996574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628341409282077, auc for val: 0.6262330336862227\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.14684948]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6289176192149116, auc for val: 0.6265759725349811\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 500, the loss is [ 0.17815325]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6286926285045153, auc for val: 0.6263669063875628\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 600, the loss is [ 0.17102511]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297628190930729, auc for val: 0.6270791316119763\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 700, the loss is [ 0.14687932]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629104031975405, auc for val: 0.6267026794808368\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 800, the loss is [ 0.15325692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291809423069293, auc for val: 0.626705197957585\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 0, the loss is [ 0.12477908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629687950603448, auc for val: 0.6270694523916377\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.18446708]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279322118290482, auc for val: 0.625601656577323\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.14999369]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6289225072372477, auc for val: 0.6264025008589384\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.12887549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6296721158938147, auc for val: 0.6269625298974515\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.16660969]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6285799392531783, auc for val: 0.6259863520211625\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 500, the loss is [ 0.08002011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.630816947490898, auc for val: 0.627749185507078\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 600, the loss is [ 0.18911383]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6318071426466392, auc for val: 0.6283396279715169\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 700, the loss is [ 0.14568482]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6322123138465375, auc for val: 0.6287152318395924\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 800, the loss is [ 0.13835466]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297278282797112, auc for val: 0.6266835841645961\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.133494]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274792900817168, auc for val: 0.6246860975592838\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: iteration 100, the loss is [ 0.14968693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277391090527221, auc for val: 0.624802289551472\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.13636483]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6290759389485839, auc for val: 0.6260318976081276\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.17628843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6292816259978553, auc for val: 0.6261363955985788\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.14479095]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308829830200803, auc for val: 0.6274722758561708\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 500, the loss is [ 0.09777043]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6310714628981509, auc for val: 0.6275053819221623\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 600, the loss is [ 0.15414566]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313833679296168, auc for val: 0.6275763703891527\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 700, the loss is [ 0.16471423]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311322122551019, auc for val: 0.627267962237263\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 800, the loss is [ 0.1772065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631385171082548, auc for val: 0.6274991183076029\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.15909131]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320187743497868, auc for val: 0.6281535889712029\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.14443088]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319149849969259, auc for val: 0.6278711975612044\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 200, the loss is [ 0.14405623]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308354528425464, auc for val: 0.6269292847514006\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.15520139]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320710803163728, auc for val: 0.627897388466413\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.14618251]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332343168580549, auc for val: 0.6289858716110726\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 500, the loss is [ 0.17083761]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332510804295182, auc for val: 0.6288604564809022\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 600, the loss is [ 0.13473465]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335339604805071, auc for val: 0.6288356676530475\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 700, the loss is [ 0.13252027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6344922624460738, auc for val: 0.6297495940466077\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 800, the loss is [ 0.15467931]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635074552918538, auc for val: 0.6299727686757105\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.16914989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6350389697886077, auc for val: 0.630006060181781\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.12685862]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6352925945953773, auc for val: 0.6301262930135281\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.15731949]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6354129644836017, auc for val: 0.6302193651385722\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.14830242]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635874732177045, auc for val: 0.6305207428561164\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.15075073]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357913079864752, auc for val: 0.6304357423864018\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 500, the loss is [ 0.17415309]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6349813169727052, auc for val: 0.6298306451438296\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 600, the loss is [ 0.20086588]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6356705636781204, auc for val: 0.6302652577991987\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 700, the loss is [ 0.11765322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6355986264714434, auc for val: 0.6302006043662578\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 800, the loss is [ 0.15440799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357748052105359, auc for val: 0.6302880042802377\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.12718034]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6359895716387833, auc for val: 0.6304047964467356\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.1239557]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357236177893061, auc for val: 0.6303484389513819\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 200, the loss is [ 0.13559811]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6354999826900255, auc for val: 0.6302602496640929\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.12767053]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357380719213286, auc for val: 0.6303154870011316\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.13703381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363722889160311, auc for val: 0.6307802223925731\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 500, the loss is [ 0.16241258]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6359222558617443, auc for val: 0.6305076292353963\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 600, the loss is [ 0.15606059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353013661057779, auc for val: 0.629970324124399\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: iteration 700, the loss is [ 0.09937729]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6354165246439609, auc for val: 0.6299462394676549\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 800, the loss is [ 0.14648181]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634316691714567, auc for val: 0.6289852200648491\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.16148885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6347083143009863, auc for val: 0.6295643018185035\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.13525893]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6345138510439186, auc for val: 0.6290503383509609\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.14336613]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6354314849851975, auc for val: 0.6299258360470734\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 300, the loss is [ 0.13805382]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353474104290253, auc for val: 0.6297281431401744\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.17737818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358839611231045, auc for val: 0.6301191573294078\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 500, the loss is [ 0.13494045]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63533555884155, auc for val: 0.6295296132469732\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 600, the loss is [ 0.15331693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6357239644602979, auc for val: 0.6297848426972955\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 700, the loss is [ 0.1578968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362384980294467, auc for val: 0.6302657577356279\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 800, the loss is [ 0.17609955]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358375323312923, auc for val: 0.6299574197502545\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.19014381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.635299117498014, auc for val: 0.6293964321870089\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.10354224]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6366162491384559, auc for val: 0.6302827781277417\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.08849683]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6366316792053596, auc for val: 0.6303378250128073\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.15562266]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6362427679184672, auc for val: 0.6299234729390399\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.12768145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6361872233414276, auc for val: 0.6298725809141221\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 500, the loss is [ 0.14895691]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6363700709173447, auc for val: 0.6300247244751354\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 600, the loss is [ 0.15245652]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6365750970888056, auc for val: 0.6300788140884421\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 700, the loss is [ 0.11926918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368706941293713, auc for val: 0.6303116240838107\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 800, the loss is [ 0.17669228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378670859228088, auc for val: 0.6311674237834258\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.19465789]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371488521117851, auc for val: 0.6304640332752074\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.16185991]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374781056881962, auc for val: 0.6308672627031566\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 200, the loss is [ 0.15916799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6375611889276525, auc for val: 0.6309660208219738\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 300, the loss is [ 0.16917357]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6376302642628757, auc for val: 0.6311255694564112\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 400, the loss is [ 0.12954649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378105113039327, auc for val: 0.6312724555405906\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 500, the loss is [ 0.14326912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380807171871352, auc for val: 0.6313840741794797\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 600, the loss is [ 0.13635269]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637893077280897, auc for val: 0.6312238464334019\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 700, the loss is [ 0.22398312]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381014487308089, auc for val: 0.6313069649369096\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 800, the loss is [ 0.12709017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6379800260758267, auc for val: 0.6312137048658395\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 0, the loss is [ 0.13484077]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381026327455809, auc for val: 0.6313940227891223\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 100, the loss is [ 0.10467177]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382743026747977, auc for val: 0.6313672692988092\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 200, the loss is [ 0.1784118]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6379984806442328, auc for val: 0.6310712066948799\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 300, the loss is [ 0.16647355]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383015236520915, auc for val: 0.6313542534100225\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: iteration 400, the loss is [ 0.14712897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381515574139426, auc for val: 0.6312088759059449\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 500, the loss is [ 0.18935063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638689861714441, auc for val: 0.6316055598002956\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 600, the loss is [ 0.14230533]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638354772316429, auc for val: 0.6312516311209109\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 700, the loss is [ 0.17018513]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638456642650179, auc for val: 0.6313380725101582\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 800, the loss is [ 0.14087687]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383504559727227, auc for val: 0.6312755566500197\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 0, the loss is [ 0.1909586]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6377010685472058, auc for val: 0.6306075187892901\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 100, the loss is [ 0.15704799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638331166379406, auc for val: 0.6312435770072105\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 200, the loss is [ 0.12455306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637943154040927, auc for val: 0.630944325585707\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 300, the loss is [ 0.14919148]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378339512871943, auc for val: 0.6307950024680571\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 400, the loss is [ 0.13935535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378669906945678, auc for val: 0.6308121043034487\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 500, the loss is [ 0.16528374]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378297222875728, auc for val: 0.6308523899076333\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 600, the loss is [ 0.1742887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6379966847570926, auc for val: 0.6309402709634395\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 700, the loss is [ 0.1606465]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380175371138679, auc for val: 0.6308621067171769\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 800, the loss is [ 0.16561641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381086398543426, auc for val: 0.6309435111529276\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 0, the loss is [ 0.12670489]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6368271488517948, auc for val: 0.6299069412065939\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 100, the loss is [ 0.11816096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63787743704712, auc for val: 0.6306804230527718\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 200, the loss is [ 0.1171594]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380300435500931, auc for val: 0.6307475385786533\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 300, the loss is [ 0.16203561]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384619949101913, auc for val: 0.6310902932403062\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 400, the loss is [ 0.14806843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387192063897278, auc for val: 0.6312881076856353\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 500, the loss is [ 0.16262333]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385694620673911, auc for val: 0.6311787093157999\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 600, the loss is [ 0.22347264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387864427841339, auc for val: 0.631430975483779\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 700, the loss is [ 0.15341769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385492557476614, auc for val: 0.6311515674036997\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 800, the loss is [ 0.16277714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388837273215403, auc for val: 0.6314640990913998\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 0, the loss is [ 0.16975127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382452271429653, auc for val: 0.6309784415483448\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 100, the loss is [ 0.16332224]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385347298852754, auc for val: 0.6311367409681962\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 200, the loss is [ 0.21711649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638469203966316, auc for val: 0.6310265782845217\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 300, the loss is [ 0.1696519]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385562905020946, auc for val: 0.6311300087415451\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 400, the loss is [ 0.1290915]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386204298143827, auc for val: 0.6311877808439876\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 500, the loss is [ 0.18842286]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385888779618003, auc for val: 0.6311069227046858\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 600, the loss is [ 0.14300421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387183894519993, auc for val: 0.6312631158760724\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 700, the loss is [ 0.1563008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389078539993595, auc for val: 0.631364753328008\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 800, the loss is [ 0.12683381]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6391043696105352, auc for val: 0.6314677239437543\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 0, the loss is [ 0.17169127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6392855516970744, auc for val: 0.6315835613444403\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: iteration 100, the loss is [ 0.14637214]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386794258740971, auc for val: 0.6310399437529166\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 200, the loss is [ 0.16450991]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638544446025819, auc for val: 0.6309524874551291\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 300, the loss is [ 0.18022412]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6388895731915756, auc for val: 0.6312626347342459\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 400, the loss is [ 0.14926839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387581530398826, auc for val: 0.6310206404430738\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 500, the loss is [ 0.11563395]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387995084543892, auc for val: 0.6310210163351259\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 600, the loss is [ 0.16657972]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638823264963339, auc for val: 0.6311475766830812\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 700, the loss is [ 0.19565159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385144613425473, auc for val: 0.63079439602888\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 800, the loss is [ 0.16995142]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6390752549671036, auc for val: 0.6312570427134859\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 0, the loss is [ 0.1707551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6391450931331001, auc for val: 0.6312632637269462\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 100, the loss is [ 0.16416323]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394949717397789, auc for val: 0.6315628271388528\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 200, the loss is [ 0.15777145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389560316052608, auc for val: 0.6311769676826257\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 300, the loss is [ 0.16554463]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389097366895149, auc for val: 0.6310997982973272\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 400, the loss is [ 0.18727149]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6391132630934722, auc for val: 0.6312046784446979\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 500, the loss is [ 0.17635319]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394011892364023, auc for val: 0.631499430438339\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 600, the loss is [ 0.13260901]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389305539540647, auc for val: 0.631044262752594\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 700, the loss is [ 0.12995547]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6392038797988976, auc for val: 0.6313169924838831\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 800, the loss is [ 0.13373362]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639412962523384, auc for val: 0.6314166214192873\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 0, the loss is [ 0.13155271]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394362489974841, auc for val: 0.6314604028195552\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 100, the loss is [ 0.19500256]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63944734053683, auc for val: 0.6314827596258337\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 200, the loss is [ 0.17208612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394782909519569, auc for val: 0.6315039261072808\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 300, the loss is [ 0.17766011]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6393444058419746, auc for val: 0.63147979258457\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 400, the loss is [ 0.128273]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6395847415167636, auc for val: 0.6315754671355875\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 500, the loss is [ 0.11183223]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394766390666135, auc for val: 0.6314186399596066\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 600, the loss is [ 0.14973697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396442756315, auc for val: 0.631577964311786\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 700, the loss is [ 0.2062902]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639669031495913, auc for val: 0.631574338206458\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 800, the loss is [ 0.18969885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394618414327207, auc for val: 0.6314331706933627\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 0, the loss is [ 0.15558337]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6390051108649233, auc for val: 0.6308964619977545\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 100, the loss is [ 0.21286833]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397148251493664, auc for val: 0.6315534586559439\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 200, the loss is [ 0.14335161]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6394860352804603, auc for val: 0.6314664885118768\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 300, the loss is [ 0.173454]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6395063369057268, auc for val: 0.6313901548599073\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 400, the loss is [ 0.1924879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6398046858260359, auc for val: 0.6315973027048871\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 500, the loss is [ 0.15208676]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639332500534022, auc for val: 0.6312705785862778\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 600, the loss is [ 0.13831897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6398331925391774, auc for val: 0.6316570457346556\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: iteration 700, the loss is [ 0.15485018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397398612878076, auc for val: 0.6315841527479352\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 800, the loss is [ 0.13131252]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396764364192156, auc for val: 0.6315243119862333\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 0, the loss is [ 0.16532099]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401874886695689, auc for val: 0.6320529302319091\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 100, the loss is [ 0.13319191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396203138253027, auc for val: 0.6315624800651913\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 200, the loss is [ 0.11832357]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400980158624728, auc for val: 0.6318445319193697\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 300, the loss is [ 0.16761521]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399523637264564, auc for val: 0.6316296970819268\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 400, the loss is [ 0.16869198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401655699420015, auc for val: 0.6318675979086529\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 500, the loss is [ 0.14852017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401412886728816, auc for val: 0.6318862571901134\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 600, the loss is [ 0.21341802]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400541628709124, auc for val: 0.631765595841427\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 700, the loss is [ 0.14847416]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401937163028212, auc for val: 0.6319187618288217\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 800, the loss is [ 0.17683108]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6396633953289769, auc for val: 0.6314594605834782\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 0, the loss is [ 0.17591989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640346166127511, auc for val: 0.6320747319709241\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 100, the loss is [ 0.14883642]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402413979025341, auc for val: 0.6318395764091511\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 200, the loss is [ 0.15757239]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401405344219254, auc for val: 0.631816025519121\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 300, the loss is [ 0.14207935]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640211489587365, auc for val: 0.6318994409773497\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 400, the loss is [ 0.15784636]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402187899296528, auc for val: 0.631871772816377\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 500, the loss is [ 0.1620246]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399198895048784, auc for val: 0.6316270846321657\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 600, the loss is [ 0.12586054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399496559052337, auc for val: 0.6316852413974748\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 700, the loss is [ 0.15740743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401648663969921, auc for val: 0.6317984450478498\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 800, the loss is [ 0.14571254]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400504546120873, auc for val: 0.6317311691413595\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 0, the loss is [ 0.20208938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401690798601878, auc for val: 0.6318373987411967\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 100, the loss is [ 0.16946103]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404069852824343, auc for val: 0.6319163348191394\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 200, the loss is [ 0.17928585]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6400595985329314, auc for val: 0.6317149205809258\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 300, the loss is [ 0.12842701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64022974318708, auc for val: 0.6318173148288593\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 400, the loss is [ 0.18109922]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403183003499021, auc for val: 0.6318597317409784\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 500, the loss is [ 0.11414348]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401421163547053, auc for val: 0.6316992333526231\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 600, the loss is [ 0.16767122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403239886141066, auc for val: 0.6318839304183115\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 700, the loss is [ 0.16576377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640224220876637, auc for val: 0.6317878260973813\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 800, the loss is [ 0.16699235]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404735235425264, auc for val: 0.6319359225539681\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 0, the loss is [ 0.14682443]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403179342004065, auc for val: 0.6318093145930195\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 100, the loss is [ 0.16929972]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404479147206118, auc for val: 0.63197257328201\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 200, the loss is [ 0.14642502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402596923916483, auc for val: 0.6317758464176847\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 300, the loss is [ 0.14979823]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402219253504132, auc for val: 0.631781518628749\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: iteration 400, the loss is [ 0.1369554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640537491181175, auc for val: 0.6319857508043789\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 500, the loss is [ 0.13741215]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404904501305164, auc for val: 0.6319761555332654\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 600, the loss is [ 0.11020505]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402884471465318, auc for val: 0.6318215423614705\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 700, the loss is [ 0.14484403]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404756552019716, auc for val: 0.6319330344500355\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 800, the loss is [ 0.15200105]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404720200648316, auc for val: 0.631975810965551\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 0, the loss is [ 0.14469898]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407638031061225, auc for val: 0.6322342405102093\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 100, the loss is [ 0.09906605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403545010720786, auc for val: 0.6318758976051607\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 200, the loss is [ 0.12892328]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404214620620824, auc for val: 0.6319085225293257\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 300, the loss is [ 0.13675679]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404289156816448, auc for val: 0.6318670942133032\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 400, the loss is [ 0.16939661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403515946010346, auc for val: 0.6318311651980013\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 500, the loss is [ 0.19464652]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404907621730568, auc for val: 0.6319127463030164\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 600, the loss is [ 0.16400985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401954086910855, auc for val: 0.6315714989684921\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 700, the loss is [ 0.14115056]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401138100691851, auc for val: 0.6315680545443224\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 800, the loss is [ 0.14460191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406383025645154, auc for val: 0.6319991162727738\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 0, the loss is [ 0.10831322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410905026796552, auc for val: 0.6323325713650607\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 100, the loss is [ 0.12565961]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406306002848458, auc for val: 0.6320110884346295\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 200, the loss is [ 0.17411982]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405888403049054, auc for val: 0.631993165901591\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 300, the loss is [ 0.15001793]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404047185874882, auc for val: 0.6318853963973142\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 400, the loss is [ 0.13822776]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404850332513405, auc for val: 0.63190725201419\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 500, the loss is [ 0.16275814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404255158324645, auc for val: 0.631834644705429\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 600, the loss is [ 0.10967629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408336635332661, auc for val: 0.6321634913611586\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 700, the loss is [ 0.12327016]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404832942537991, auc for val: 0.6319559049754515\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 800, the loss is [ 0.11894412]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403388825583795, auc for val: 0.6317649630898062\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 0, the loss is [ 0.17909846]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403979995084907, auc for val: 0.6318486141070543\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 100, the loss is [ 0.18792278]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403278223237721, auc for val: 0.6318069890741913\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 200, the loss is [ 0.17020714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404260320901132, auc for val: 0.6317919859694232\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 300, the loss is [ 0.18894905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640554283352029, auc for val: 0.6319379273115787\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 400, the loss is [ 0.17176962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404766525477478, auc for val: 0.63188391914155\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 500, the loss is [ 0.15689765]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405708297227151, auc for val: 0.6319922349422756\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 600, the loss is [ 0.15350573]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404828198903929, auc for val: 0.6318435508411141\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 700, the loss is [ 0.16541336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406853107645225, auc for val: 0.6319486740653448\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 800, the loss is [ 0.14129001]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406019811838287, auc for val: 0.6319473722258716\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 0, the loss is [ 0.17775533]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401626467750969, auc for val: 0.6316871584469399\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: iteration 100, the loss is [ 0.18079738]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640773110739154, auc for val: 0.6320453785605848\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 200, the loss is [ 0.13816428]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406180450750651, auc for val: 0.6319472870236731\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 300, the loss is [ 0.20396636]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408016770472419, auc for val: 0.6320395184034944\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 400, the loss is [ 0.15726267]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408184366766272, auc for val: 0.6320713389186683\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 500, the loss is [ 0.16751398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407497532303513, auc for val: 0.6320118815668592\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 600, the loss is [ 0.18185598]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407544753762219, auc for val: 0.6319958297232661\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 700, the loss is [ 0.16469406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406149607467295, auc for val: 0.6319154865560754\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 800, the loss is [ 0.13749477]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407872164223847, auc for val: 0.6320613213954829\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 0, the loss is [ 0.15189807]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6395379026715262, auc for val: 0.6310133468842919\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 100, the loss is [ 0.20450433]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404102733621042, auc for val: 0.6318233240897969\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 200, the loss is [ 0.17013864]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408642324943588, auc for val: 0.632089507034514\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 300, the loss is [ 0.13744055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407333222620712, auc for val: 0.6320509154505105\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 400, the loss is [ 0.16159746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404319267337039, auc for val: 0.6317891241779341\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 500, the loss is [ 0.16108263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405355097844742, auc for val: 0.6319087305229278\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 600, the loss is [ 0.18887413]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407488151703388, auc for val: 0.6319952708970822\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 700, the loss is [ 0.1373082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408850873245947, auc for val: 0.6320481451260874\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 800, the loss is [ 0.18984488]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408530132625986, auc for val: 0.6320543949579385\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 0, the loss is [ 0.13897412]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408705245921835, auc for val: 0.6321864433298527\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 100, the loss is [ 0.17034459]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405024329660063, auc for val: 0.6318490463829141\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 200, the loss is [ 0.15586852]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404507275866234, auc for val: 0.631795925318128\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 300, the loss is [ 0.17039302]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406266407378614, auc for val: 0.6318318004555692\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 400, the loss is [ 0.18835446]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407849491090732, auc for val: 0.6320366916952634\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 500, the loss is [ 0.17403847]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640800905559356, auc for val: 0.6320071177615871\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 600, the loss is [ 0.16667129]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406252824213979, auc for val: 0.6318629030169236\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 700, the loss is [ 0.19297117]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405373007246926, auc for val: 0.6318300650872625\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 800, the loss is [ 0.17233975]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640775038801856, auc for val: 0.6319930606518165\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 0, the loss is [ 0.13289768]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405659058351969, auc for val: 0.6318429606905925\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 100, the loss is [ 0.15955308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408352477076199, auc for val: 0.6321060763561654\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 200, the loss is [ 0.12208602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408980872162517, auc for val: 0.6320873757265792\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 300, the loss is [ 0.11770308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64112869283728, auc for val: 0.6322687787249188\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 400, the loss is [ 0.14534338]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409730536394657, auc for val: 0.6321260750663042\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 500, the loss is [ 0.16535828]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407994026227306, auc for val: 0.632017250558335\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 600, the loss is [ 0.14584282]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407389101192258, auc for val: 0.6319590887811318\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: iteration 700, the loss is [ 0.16110529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408440517594894, auc for val: 0.6320541756875748\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 800, the loss is [ 0.12200464]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407124162621147, auc for val: 0.631987005030859\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 0, the loss is [ 0.16980968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409000409411099, auc for val: 0.6320178382029096\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 100, the loss is [ 0.16377629]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407775427944489, auc for val: 0.6320155189489489\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 200, the loss is [ 0.136931]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407428355788283, auc for val: 0.6319403242498969\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 300, the loss is [ 0.15042284]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408477757866272, auc for val: 0.6320403102827505\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 400, the loss is [ 0.18338554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407956550204196, auc for val: 0.6320058961124182\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 500, the loss is [ 0.16760281]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406005987511222, auc for val: 0.6317998170538395\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 600, the loss is [ 0.15828064]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409773097698606, auc for val: 0.6320832572026631\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 700, the loss is [ 0.12403136]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406045035727862, auc for val: 0.6318039882026429\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 800, the loss is [ 0.21283333]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406407043722584, auc for val: 0.6318425196439181\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 0, the loss is [ 0.15020773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411253824191672, auc for val: 0.6323202057695241\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 100, the loss is [ 0.14898853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408467723344945, auc for val: 0.6320571677883086\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 200, the loss is [ 0.14629175]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407347582606633, auc for val: 0.6319220132950714\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 300, the loss is [ 0.10301082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409749265130735, auc for val: 0.632113020335339\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 400, the loss is [ 0.10856697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408123821856315, auc for val: 0.6320121096080373\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 500, the loss is [ 0.1155182]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410276016436856, auc for val: 0.6321589230197535\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 600, the loss is [ 0.19051999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407228034061989, auc for val: 0.6319129743441947\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 700, the loss is [ 0.16031018]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407968417405392, auc for val: 0.6319374198573084\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 800, the loss is [ 0.15157014]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641005046772916, auc for val: 0.6321464183441576\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 0, the loss is [ 0.15902328]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640765891170821, auc for val: 0.6320915681759324\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 100, the loss is [ 0.13327123]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409162576458469, auc for val: 0.6320704204890879\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 200, the loss is [ 0.15409535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408570543564941, auc for val: 0.6320362368658806\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 300, the loss is [ 0.18309157]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408051800861154, auc for val: 0.632045881002961\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 400, the loss is [ 0.11980535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407242954441374, auc for val: 0.6319020609449522\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 500, the loss is [ 0.23503853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410305983960493, auc for val: 0.6321485483991189\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 600, the loss is [ 0.16361758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409719090454755, auc for val: 0.6320818588842296\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 700, the loss is [ 0.17429093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640892897122514, auc for val: 0.6320684996807022\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 800, the loss is [ 0.18001367]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407284203265179, auc for val: 0.6319377243298707\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 0, the loss is [ 0.18127289]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406611591202082, auc for val: 0.6319575225642485\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 100, the loss is [ 0.11855612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409009813972876, auc for val: 0.6320469598131502\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 200, the loss is [ 0.14005512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410826095570248, auc for val: 0.632166316816416\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 300, the loss is [ 0.1556136]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409041102479177, auc for val: 0.6320493705341769\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: iteration 400, the loss is [ 0.17840277]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409743850570429, auc for val: 0.6321615141689652\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 500, the loss is [ 0.15989481]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410213423965122, auc for val: 0.6320804279884852\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 600, the loss is [ 0.12645507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406035837545471, auc for val: 0.6317921438440851\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 700, the loss is [ 0.16432288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409953600820152, auc for val: 0.6321013338514428\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 800, the loss is [ 0.14255482]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408628683807216, auc for val: 0.6320228074958368\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 0, the loss is [ 0.19393113]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407366534727139, auc for val: 0.6319735242889015\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 100, the loss is [ 0.15868549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409617241841082, auc for val: 0.6321334651040463\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 200, the loss is [ 0.21316494]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409850977704064, auc for val: 0.6320940202450849\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 300, the loss is [ 0.10795083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408299051868597, auc for val: 0.6319521397900643\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 400, the loss is [ 0.1938086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409455932002471, auc for val: 0.6320599719430162\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 500, the loss is [ 0.15755956]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410731826568048, auc for val: 0.6321570560892287\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 600, the loss is [ 0.14740439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641140907559721, auc for val: 0.6322222771191681\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 700, the loss is [ 0.10859246]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410632515570578, auc for val: 0.6321224289134001\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 800, the loss is [ 0.18780062]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640949129321659, auc for val: 0.6320726395051681\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 0, the loss is [ 0.16369115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414416514084602, auc for val: 0.6324998771584773\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 100, the loss is [ 0.15503244]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410532466399644, auc for val: 0.6321858845036687\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 200, the loss is [ 0.09207983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409548931037137, auc for val: 0.6320283945047027\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 300, the loss is [ 0.10740681]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408209938486273, auc for val: 0.6319942534825947\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 400, the loss is [ 0.15054123]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640961314826344, auc for val: 0.6321222773036059\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 500, the loss is [ 0.16202825]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408986462956908, auc for val: 0.6320153823748367\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 600, the loss is [ 0.15726097]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641121102095234, auc for val: 0.6321944811548975\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 700, the loss is [ 0.11753444]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408990696439676, auc for val: 0.6320366503471379\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 800, the loss is [ 0.15700042]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408804260104011, auc for val: 0.6320322912523084\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 0, the loss is [ 0.11511767]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413969509473897, auc for val: 0.6325411037457653\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 100, the loss is [ 0.17823763]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408174309829207, auc for val: 0.6319710496662259\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 200, the loss is [ 0.1577238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640819630662538, auc for val: 0.6319608968219018\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 300, the loss is [ 0.16106151]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409589565360521, auc for val: 0.6320687665640592\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 400, the loss is [ 0.20020607]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410881173358856, auc for val: 0.6321447606602083\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 500, the loss is [ 0.1578334]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410034688595099, auc for val: 0.6321050363881549\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 600, the loss is [ 0.16443327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407637902750444, auc for val: 0.6319013805803381\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 700, the loss is [ 0.12097385]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409501926006251, auc for val: 0.632026052697219\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 800, the loss is [ 0.13627213]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408943131788283, auc for val: 0.6320109643902524\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 0, the loss is [ 0.21357822]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412365007910024, auc for val: 0.632290252184875\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: iteration 100, the loss is [ 0.13501377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410333617155489, auc for val: 0.632148585988324\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 200, the loss is [ 0.16401981]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410296161229246, auc for val: 0.6320789206613566\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 300, the loss is [ 0.14171724]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410826549295716, auc for val: 0.632156349412171\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 400, the loss is [ 0.15935645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409351338620256, auc for val: 0.6320403516308764\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 500, the loss is [ 0.167307]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409385909872828, auc for val: 0.6320972616875464\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 600, the loss is [ 0.1505051]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409320084896998, auc for val: 0.6320212274962449\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 700, the loss is [ 0.15208596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409931111650684, auc for val: 0.6320814253553964\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 800, the loss is [ 0.15050392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410209735416686, auc for val: 0.632130565723352\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 0, the loss is [ 0.09833892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397844104812905, auc for val: 0.6311685426887673\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 100, the loss is [ 0.10839723]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640930523331074, auc for val: 0.6321103865850282\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 200, the loss is [ 0.16791962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409217491926213, auc for val: 0.6320334276992788\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 300, the loss is [ 0.20544739]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410983753189381, auc for val: 0.6321956789975699\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 400, the loss is [ 0.12522568]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408772786088146, auc for val: 0.6320560939900133\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 500, the loss is [ 0.11892713]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64110995312522, auc for val: 0.6321145176386794\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 600, the loss is [ 0.13384642]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411818764959756, auc for val: 0.6322186848441247\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 700, the loss is [ 0.19689769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407408464525624, auc for val: 0.6318482507447374\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 800, the loss is [ 0.1724977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640801043686683, auc for val: 0.6319237173390403\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 0, the loss is [ 0.16825342]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408422382489413, auc for val: 0.6320128325737506\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 100, the loss is [ 0.09435089]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407918952826913, auc for val: 0.6319457972381737\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 200, the loss is [ 0.15032624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407680528982739, auc for val: 0.6318768836953104\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 300, the loss is [ 0.20670187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641073060375086, auc for val: 0.6321323975706187\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 400, the loss is [ 0.14945744]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408671458447158, auc for val: 0.6319690887626881\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 500, the loss is [ 0.16030535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410077732223904, auc for val: 0.6320614830290653\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 600, the loss is [ 0.13228634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410607297091697, auc for val: 0.6321185998263639\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 700, the loss is [ 0.12365065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408696147450834, auc for val: 0.6319886301374971\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 800, the loss is [ 0.14722669]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410255564780731, auc for val: 0.6320395071267328\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 0, the loss is [ 0.15149309]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410090567166642, auc for val: 0.6320444751666865\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 100, the loss is [ 0.14469957]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407555496311702, auc for val: 0.6318468925214562\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 200, the loss is [ 0.13885342]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406724638409576, auc for val: 0.6318213920046497\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 300, the loss is [ 0.15163824]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64087483738029, auc for val: 0.6320089333201981\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 400, the loss is [ 0.17354757]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409618352579578, auc for val: 0.6320698328445132\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 500, the loss is [ 0.1730558]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409374691182137, auc for val: 0.6320790672592569\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 600, the loss is [ 0.16560416]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408676550684603, auc for val: 0.6320307350592131\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: iteration 700, the loss is [ 0.11965217]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408877562661054, auc for val: 0.6320151605985259\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 800, the loss is [ 0.14438637]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409969535318469, auc for val: 0.6320304406104391\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 0, the loss is [ 0.13981429]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410280299388841, auc for val: 0.6319841758166811\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 100, the loss is [ 0.1777982]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410164013493598, auc for val: 0.6320471427472821\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 200, the loss is [ 0.15963057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408998402043059, auc for val: 0.6319762031462586\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 300, the loss is [ 0.15600245]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409788967268576, auc for val: 0.632072040583832\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 400, the loss is [ 0.13999286]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412017618068694, auc for val: 0.6322231742481988\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 500, the loss is [ 0.14190137]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409513390497111, auc for val: 0.632093958849383\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 600, the loss is [ 0.18070979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410559927998298, auc for val: 0.6321045652701165\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 700, the loss is [ 0.1748043]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410212103755413, auc for val: 0.6320832196134579\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 800, the loss is [ 0.13261865]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410020904461773, auc for val: 0.63207347273255\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 0, the loss is [ 0.15191701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408580406489925, auc for val: 0.631950573573181\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 100, the loss is [ 0.13480714]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409980299510735, auc for val: 0.6320237221664966\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 200, the loss is [ 0.14609069]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411003562518649, auc for val: 0.6321136480750658\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 300, the loss is [ 0.15444057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410290221831475, auc for val: 0.6321406509071067\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 400, the loss is [ 0.1181696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411132792343499, auc for val: 0.6321058483149873\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 500, the loss is [ 0.13708399]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410452020178596, auc for val: 0.632131020552735\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 600, the loss is [ 0.15041746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412537458370717, auc for val: 0.6322644597252416\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 700, the loss is [ 0.1694999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410603406801616, auc for val: 0.6321158608262785\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 800, the loss is [ 0.15834543]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410378586218944, auc for val: 0.6320709555087752\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 0, the loss is [ 0.14838232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406809454153739, auc for val: 0.6318779524817115\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 100, the loss is [ 0.11157892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410566626439357, auc for val: 0.6321299029003671\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 200, the loss is [ 0.14743985]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410234796985398, auc for val: 0.6320940327748199\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 300, the loss is [ 0.17992441]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409174239599151, auc for val: 0.6320065852478467\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 400, the loss is [ 0.11401466]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410457166522996, auc for val: 0.6320991273650978\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 500, the loss is [ 0.13035658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410484262513222, auc for val: 0.6320552970988631\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 600, the loss is [ 0.15122229]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409789145821528, auc for val: 0.6320116835970451\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 700, the loss is [ 0.19118507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409758730756075, auc for val: 0.631995146852705\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 800, the loss is [ 0.18361719]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407926249536304, auc for val: 0.6319481615991808\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 0, the loss is [ 0.1589915]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412569044465273, auc for val: 0.63218439847709\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 100, the loss is [ 0.17993261]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410885911582221, auc for val: 0.6321372177596987\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 200, the loss is [ 0.13571259]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641040080176181, auc for val: 0.6320369097126537\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 300, the loss is [ 0.13495649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410356407777993, auc for val: 0.6321115130082104\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: iteration 400, the loss is [ 0.16999112]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407067415246492, auc for val: 0.6318314433581198\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 500, the loss is [ 0.12163928]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410255904881592, auc for val: 0.6320497852684077\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 600, the loss is [ 0.14570035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412028622650433, auc for val: 0.6322079130308884\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 700, the loss is [ 0.13799936]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641233560309872, auc for val: 0.632233357163887\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 800, the loss is [ 0.13563284]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409539197968845, auc for val: 0.6320173645789242\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 0, the loss is [ 0.17957245]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640203760640696, auc for val: 0.6313201387003582\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 100, the loss is [ 0.14840661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409991672792725, auc for val: 0.6320766227079456\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 200, the loss is [ 0.15250766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640972457148932, auc for val: 0.632032980387737\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 300, the loss is [ 0.16063549]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407792332503218, auc for val: 0.6318469752177076\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 400, the loss is [ 0.1663944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409643365452029, auc for val: 0.6320619541471038\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 500, the loss is [ 0.16246815]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407191673415112, auc for val: 0.6318910272602529\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 600, the loss is [ 0.16651025]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409834318172545, auc for val: 0.6320363421156552\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 700, the loss is [ 0.20609491]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410372567206652, auc for val: 0.632125268151366\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 800, the loss is [ 0.18031333]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411411073689771, auc for val: 0.6322037030399063\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 0, the loss is [ 0.1174785]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416666692496297, auc for val: 0.6325210022917989\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 100, the loss is [ 0.17368211]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410434697450397, auc for val: 0.6321123763069565\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 200, the loss is [ 0.15401961]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411306531322685, auc for val: 0.63218196520254\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 300, the loss is [ 0.16621624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410821961798867, auc for val: 0.6321905205056432\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 400, the loss is [ 0.16027825]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410102170016716, auc for val: 0.6320086451362917\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 500, the loss is [ 0.18709409]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410273359012396, auc for val: 0.6320781513356236\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 600, the loss is [ 0.13852322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408354240189984, auc for val: 0.631961503261079\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 700, the loss is [ 0.1274973]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409993852530067, auc for val: 0.6320767667998988\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 800, the loss is [ 0.17702085]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641008224938171, auc for val: 0.63203714777762\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 0, the loss is [ 0.16835059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412897155225495, auc for val: 0.6320883956470137\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 100, the loss is [ 0.12244853]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409340505634861, auc for val: 0.6320937458438869\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 200, the loss is [ 0.158767]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409336980953205, auc for val: 0.6320195434998521\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 300, the loss is [ 0.1239423]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407869174428091, auc for val: 0.6318330722236782\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 400, the loss is [ 0.15561344]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410366931580788, auc for val: 0.6320972165805001\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 500, the loss is [ 0.1452378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411844361414368, auc for val: 0.6322130928233647\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 600, the loss is [ 0.17085163]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407664451487468, auc for val: 0.6318828879443541\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 700, the loss is [ 0.17405674]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641020605227895, auc for val: 0.6320838561239992\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 800, the loss is [ 0.16532755]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410684076407093, auc for val: 0.6321264522113299\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 0, the loss is [ 0.15410531]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401955036101441, auc for val: 0.6312537950061567\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: iteration 100, the loss is [ 0.11855421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409073259788588, auc for val: 0.6320127436126317\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 200, the loss is [ 0.13493265]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408993213959008, auc for val: 0.6319784158974712\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 300, the loss is [ 0.11789122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641027365428178, auc for val: 0.6320663332895093\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 400, the loss is [ 0.17654398]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409296055225219, auc for val: 0.6320194883690178\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 500, the loss is [ 0.17898883]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408028109744324, auc for val: 0.6318840770162117\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 600, the loss is [ 0.12798314]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409871828978698, auc for val: 0.6320774133342283\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 700, the loss is [ 0.16960195]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410024044984047, auc for val: 0.6320226947282213\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 800, the loss is [ 0.17915377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641043041913615, auc for val: 0.6321387313516946\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 0, the loss is [ 0.13108996]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406762093562861, auc for val: 0.6319100536629508\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 100, the loss is [ 0.18365334]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410807696113641, auc for val: 0.6321593051766731\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 200, the loss is [ 0.15956788]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409317478487668, auc for val: 0.6320395184034944\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 300, the loss is [ 0.11546476]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410058579907663, auc for val: 0.6320120419474682\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 400, the loss is [ 0.15362228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408179885937421, auc for val: 0.6319764850652976\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 500, the loss is [ 0.1693909]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408992979753186, auc for val: 0.6319943336728993\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 600, the loss is [ 0.14162324]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410601438854356, auc for val: 0.632105818243623\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 700, the loss is [ 0.12073545]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410449684304041, auc for val: 0.6321249085479697\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 800, the loss is [ 0.17744908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410147788363634, auc for val: 0.6320387039707152\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 0, the loss is [ 0.17622806]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408313531662775, auc for val: 0.6319926083283806\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 100, the loss is [ 0.15331341]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410332450764125, auc for val: 0.6321022485221026\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 200, the loss is [ 0.13436888]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411203757480077, auc for val: 0.6321791597948587\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 300, the loss is [ 0.1285892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410273326548224, auc for val: 0.6320545854099113\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 400, the loss is [ 0.1795022]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410407823298687, auc for val: 0.6320700445970359\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 500, the loss is [ 0.24203107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410461722328626, auc for val: 0.6320683768892986\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 600, the loss is [ 0.13277426]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411497407520506, auc for val: 0.6321946916544466\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 700, the loss is [ 0.17155027]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409966718664971, auc for val: 0.6320302639411747\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 800, the loss is [ 0.16650036]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413304809393569, auc for val: 0.6322676372660543\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 0, the loss is [ 0.17766558]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405871927481183, auc for val: 0.6316987421870085\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 100, the loss is [ 0.12248865]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411725251136061, auc for val: 0.6322557753658673\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 200, the loss is [ 0.20025918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410285505250891, auc for val: 0.6320440541675884\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 300, the loss is [ 0.19153342]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408798926704136, auc for val: 0.6319828677123402\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 400, the loss is [ 0.1386182]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409732787243995, auc for val: 0.6320331244796902\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 500, the loss is [ 0.15405899]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640834443214491, auc for val: 0.63190069520383\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 600, the loss is [ 0.13107318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641181686967041, auc for val: 0.6322204690783981\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: iteration 700, the loss is [ 0.16315754]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408680716920155, auc for val: 0.631934396432237\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 800, the loss is [ 0.15422641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410046417437081, auc for val: 0.6321022372453411\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 0, the loss is [ 0.12385909]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412352508430408, auc for val: 0.6323572386544853\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 100, the loss is [ 0.12054906]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413257643587729, auc for val: 0.6323268126988243\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 200, the loss is [ 0.16596068]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411285904978391, auc for val: 0.6321256665969412\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 300, the loss is [ 0.16781501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409231734422745, auc for val: 0.6320062018379538\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 400, the loss is [ 0.18891661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408046002914422, auc for val: 0.6318445857972306\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 500, the loss is [ 0.1489929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409066419123532, auc for val: 0.6320044263744949\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 600, the loss is [ 0.13494889]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.64089970045377, auc for val: 0.632018868147132\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 700, the loss is [ 0.1744817]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410357828472045, auc for val: 0.6320693993156801\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 800, the loss is [ 0.16265868]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640746062440343, auc for val: 0.6318440119353645\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 0, the loss is [ 0.1178499]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6403103683475597, auc for val: 0.6313042697908969\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 100, the loss is [ 0.17905553]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640968625294362, auc for val: 0.6320647294834209\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 200, the loss is [ 0.10020211]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409250356490824, auc for val: 0.631994857415825\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 300, the loss is [ 0.17509408]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410256006911852, auc for val: 0.6320939989445352\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 400, the loss is [ 0.12625089]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410149121713603, auc for val: 0.6320870098583153\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 500, the loss is [ 0.13824816]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408913893935584, auc for val: 0.6319634716824578\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 600, the loss is [ 0.18907304]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409074547534124, auc for val: 0.6320373256998579\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 700, the loss is [ 0.15371332]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408474340625571, auc for val: 0.6318964701771657\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 800, the loss is [ 0.1126494]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409595738191157, auc for val: 0.6320491099156875\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 0, the loss is [ 0.14562459]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411417704110657, auc for val: 0.6321356590606564\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 100, the loss is [ 0.14763877]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411502669808381, auc for val: 0.6321056428273322\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 200, the loss is [ 0.16343924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410640216536221, auc for val: 0.6320689106560125\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 300, the loss is [ 0.16299872]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640912719592044, auc for val: 0.6319419581273495\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 400, the loss is [ 0.12408958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410784812736358, auc for val: 0.632165174104578\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 500, the loss is [ 0.16857527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411297076518734, auc for val: 0.6321382639925766\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 600, the loss is [ 0.19709103]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410814859101557, auc for val: 0.6321039224947076\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 700, the loss is [ 0.14075047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409966396342108, auc for val: 0.6320768532550709\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 800, the loss is [ 0.17763335]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412233059597151, auc for val: 0.6322429599528416\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 0, the loss is [ 0.20806648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410125606057899, auc for val: 0.6321158144662588\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 100, the loss is [ 0.17526826]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409147562551349, auc for val: 0.6320820631189112\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 200, the loss is [ 0.15836807]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408112442390673, auc for val: 0.6318925258165669\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 300, the loss is [ 0.12607868]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410324576656226, auc for val: 0.6320658609184974\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: iteration 400, the loss is [ 0.11611999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409538267329215, auc for val: 0.6320249638632417\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 500, the loss is [ 0.17333797]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410190235270019, auc for val: 0.6320649048997118\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 600, the loss is [ 0.1792306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409350887986615, auc for val: 0.6319912952121457\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 700, the loss is [ 0.1502279]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408117993764281, auc for val: 0.6319398167956267\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 800, the loss is [ 0.11813226]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410862927720592, auc for val: 0.6320926920931678\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 0, the loss is [ 0.16450593]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640471877377061, auc for val: 0.6317630084511359\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 100, the loss is [ 0.13267827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413074893481627, auc for val: 0.6323174329391539\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 200, the loss is [ 0.18001191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409206975080026, auc for val: 0.6319815796555754\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 300, the loss is [ 0.1811076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408622743636486, auc for val: 0.6318898519711038\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 400, the loss is [ 0.18142429]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409769264607305, auc for val: 0.6320188994714697\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 500, the loss is [ 0.14469995]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410084857336952, auc for val: 0.6320912637033703\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 600, the loss is [ 0.16792727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411184861785395, auc for val: 0.6321641378954881\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 700, the loss is [ 0.17316389]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640983882450896, auc for val: 0.6320969847804014\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 800, the loss is [ 0.13577388]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407604997219137, auc for val: 0.6318736347350078\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 0, the loss is [ 0.16752133]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410577399134145, auc for val: 0.6322255436211\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 100, the loss is [ 0.12207633]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410068403411864, auc for val: 0.6320849975828637\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 200, the loss is [ 0.21342781]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410039244400729, auc for val: 0.6320817548874286\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 300, the loss is [ 0.12956066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409870724423855, auc for val: 0.6319626559967051\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 400, the loss is [ 0.14094377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409196409537582, auc for val: 0.6319529780293401\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 500, the loss is [ 0.17859912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409943586395693, auc for val: 0.632026263196768\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 600, the loss is [ 0.12273378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409402368435656, auc for val: 0.6320392089190383\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 700, the loss is [ 0.18186328]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409598722576217, auc for val: 0.6320180061013595\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 800, the loss is [ 0.1834705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410621123737628, auc for val: 0.6320617536713427\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 0, the loss is [ 0.15359285]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407493143456486, auc for val: 0.6319055204048039\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 100, the loss is [ 0.13732272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410982121478201, auc for val: 0.6321144762905536\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 200, the loss is [ 0.17701399]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641096605944206, auc for val: 0.6321838872638992\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 300, the loss is [ 0.1491096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410720513576665, auc for val: 0.632138512081331\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 400, the loss is [ 0.14378777]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410419103052941, auc for val: 0.6320484207802588\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 500, the loss is [ 0.18025276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409811283295787, auc for val: 0.6320315306973898\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 600, the loss is [ 0.16336313]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408330856709842, auc for val: 0.63193702015876\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 700, the loss is [ 0.1530109]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409509389674247, auc for val: 0.6319928125630621\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 800, the loss is [ 0.18398361]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410569303960684, auc for val: 0.6321099192259101\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 0, the loss is [ 0.12540218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405200603163622, auc for val: 0.6316675619412966\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: iteration 100, the loss is [ 0.15974003]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408681920413432, auc for val: 0.6319070001665152\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 200, the loss is [ 0.16414921]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410734285342685, auc for val: 0.6321278831070744\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 300, the loss is [ 0.19627944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409698328070116, auc for val: 0.631985567870247\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 400, the loss is [ 0.1757511]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412912143625052, auc for val: 0.6322858116467677\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 500, the loss is [ 0.16574982]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640913397397602, auc for val: 0.6320197427226397\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 600, the loss is [ 0.18315095]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410833614118157, auc for val: 0.6321098640950759\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 700, the loss is [ 0.14543061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410383033810666, auc for val: 0.6320814917629922\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 800, the loss is [ 0.16434851]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410365359387259, auc for val: 0.6320739513684295\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 0, the loss is [ 0.11889885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407197710205403, auc for val: 0.6318567684586353\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 100, the loss is [ 0.14923173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409349822079597, auc for val: 0.6319852646506583\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 200, the loss is [ 0.13897771]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6410191400115469, auc for val: 0.6320200584719633\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 300, the loss is [ 0.18617307]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408846703145612, auc for val: 0.6319471592203754\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 400, the loss is [ 0.17029043]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6408839595810564, auc for val: 0.6319429868185984\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 500, the loss is [ 0.13738418]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411715594590464, auc for val: 0.6321460411991321\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 600, the loss is [ 0.09780879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409414411097978, auc for val: 0.63203136279894\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 700, the loss is [ 0.1668911]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409689373369024, auc for val: 0.6320086551600796\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 800, the loss is [ 0.20203276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411115556959386, auc for val: 0.6320909228945765\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.00016927428335591677. Weight decay is 0.0020690929073855823. dropout is 0.75\n",
      " Val aus is 0.6320909228945765. Train auc is 0.6411115556959386\n",
      "This is round you consume 3:25:58.710611 time to run this model.\n",
      "You have finished 3!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.9762581]\n",
      "  acc for train: 0.10717252515447367, acc for val: 0.10717019171535776\n",
      "  auc for train: 0.47878825501157424, auc for val: 0.47937969722226\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.5571208]\n",
      "  acc for train: 0.9622612891784428, acc for val: 0.9630943269428214\n",
      "  auc for train: 0.4954759866882328, auc for val: 0.49120781473762276\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.37900883]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49711665156318685, auc for val: 0.49095146763493247\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.30289191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5046088076450351, auc for val: 0.49741255332504886\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.29028955]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5075630745318539, auc for val: 0.5010895957851333\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 500, the loss is [ 0.25599921]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5188918061701592, auc for val: 0.5114442440221436\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.23292468]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5231787619929641, auc for val: 0.5186258383445257\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.19424382]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5241761766397427, auc for val: 0.5211207654557489\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.23499104]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5192817165033322, auc for val: 0.5184094360372261\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.2014033]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5160189142889241, auc for val: 0.515325308158309\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.22276825]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5082512086436782, auc for val: 0.5092728083578826\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.22038065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5088285914607109, auc for val: 0.5106074068235774\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.2041944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5022658327132798, auc for val: 0.5053973475192387\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.15783457]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.49590390499318293, auc for val: 0.49785379546324154\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.19296709]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5011326218215643, auc for val: 0.5051421180689164\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: iteration 600, the loss is [ 0.17297681]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5062200715734688, auc for val: 0.5110539740991732\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.19689558]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.508865417891177, auc for val: 0.5156822164086925\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.17422107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5179345347102027, auc for val: 0.524491994672076\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.18147729]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5189888055639116, auc for val: 0.5254697938960824\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.21577241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5258282429323046, auc for val: 0.5338422267688789\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.2474312]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5452261923060638, auc for val: 0.550976318710511\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.1687219]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5583561725425941, auc for val: 0.5659121626078143\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.1668141]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.565498713905114, auc for val: 0.5739118659337593\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.17693204]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.572838440336437, auc for val: 0.5801782032047174\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.1787352]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5769036864946117, auc for val: 0.5857454388957699\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.18049954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5787874713109754, auc for val: 0.5871365640082418\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.21526176]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.587690973773919, auc for val: 0.5901192925001897\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.21502773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5892553371751863, auc for val: 0.5926892764833793\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.16027035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5960032687835837, auc for val: 0.5937980590518194\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.15031187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5981158372852017, auc for val: 0.5959951343129462\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.21624772]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6021859613399823, auc for val: 0.6013879285264618\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.15013084]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6042081452550127, auc for val: 0.6013492905824386\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 500, the loss is [ 0.18680145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6060696580253915, auc for val: 0.604527519277649\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 600, the loss is [ 0.15463692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6078488655370348, auc for val: 0.6051164443911713\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.21093819]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6067838342785461, auc for val: 0.604951283688398\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.1756357]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.607878002287022, auc for val: 0.6064813560449115\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.16382453]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6054795304696435, auc for val: 0.6040412515364963\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.15827353]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6053265252757059, auc for val: 0.6034825619266618\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.15724473]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6024516194563012, auc for val: 0.6005270805965887\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.17904879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6041304551649677, auc for val: 0.6027293732393968\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.18228273]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6052110945022425, auc for val: 0.6025373700851914\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.18217453]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6033391457369286, auc for val: 0.6001098191183389\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.16243231]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6028091589894764, auc for val: 0.5995899817109973\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 700, the loss is [ 0.20525697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6012730030898882, auc for val: 0.5977764666997131\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 800, the loss is [ 0.17199707]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6018480684287323, auc for val: 0.5985126375008114\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.17341836]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.603573942173527, auc for val: 0.600602723860156\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.20308778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6037385754932151, auc for val: 0.6006021312036873\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.17361186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6033280388157484, auc for val: 0.6007420733086932\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: iteration 300, the loss is [ 0.19703826]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6045040383379191, auc for val: 0.6008497764053742\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.16875154]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6054153736885385, auc for val: 0.6015974520092102\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 500, the loss is [ 0.17492796]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6044655714618659, auc for val: 0.6010661072931839\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 600, the loss is [ 0.16134951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6060620314954591, auc for val: 0.6030013925347076\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 700, the loss is [ 0.20641173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6065285473834074, auc for val: 0.603049710952043\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 800, the loss is [ 0.17091009]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6045459207541697, auc for val: 0.6011717580192609\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.22545493]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6030982538426398, auc for val: 0.5991726701138074\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.13957627]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6060907703274389, auc for val: 0.6026537237109619\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.15785845]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.605763484311807, auc for val: 0.6023545324321868\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.17611393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.603485610018343, auc for val: 0.6012237225895005\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.19670843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6021981043320594, auc for val: 0.6000136947498325\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 500, the loss is [ 0.21507929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6026157001120892, auc for val: 0.5987659511546422\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 600, the loss is [ 0.21770063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6013987597119849, auc for val: 0.5982973553518268\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 700, the loss is [ 0.18559818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6061958814359206, auc for val: 0.6025379477059778\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 800, the loss is [ 0.19161817]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6048718320666601, auc for val: 0.6008897099240033\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.19231427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6025432608701632, auc for val: 0.5984315149840996\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.21865138]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.602733787923533, auc for val: 0.599808395040775\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.17497016]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6040058221897399, auc for val: 0.6008049299776257\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 300, the loss is [ 0.16832918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6018129347730088, auc for val: 0.5980415157034067\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.19648913]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6005773119369213, auc for val: 0.5965684548944172\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 500, the loss is [ 0.17282373]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5973298696822621, auc for val: 0.5931326812538443\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 600, the loss is [ 0.1921563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5979003413406064, auc for val: 0.5932267081447007\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 700, the loss is [ 0.17541763]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6001310070837375, auc for val: 0.5965179111961342\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 800, the loss is [ 0.19247887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5991420993643486, auc for val: 0.5940901221643156\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.17432518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5990329308525888, auc for val: 0.5959620733540008\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.18306702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5988473877454573, auc for val: 0.5946507100290124\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.16246635]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5991852633424817, auc for val: 0.5956531752894699\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.17413326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5979362158751385, auc for val: 0.5940600570650244\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 400, the loss is [ 0.18648314]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5978552635221708, auc for val: 0.5952237136081864\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 500, the loss is [ 0.18004845]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5980435081895773, auc for val: 0.5953325481399439\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 600, the loss is [ 0.18460514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5954432503571045, auc for val: 0.5929409399711019\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 700, the loss is [ 0.18498375]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5999173935974107, auc for val: 0.5987552745673924\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 800, the loss is [ 0.19577427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6003923340155851, auc for val: 0.5998691028601436\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: iteration 0, the loss is [ 0.14862671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6015580132544093, auc for val: 0.5999695249277777\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.21935856]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5975064042132332, auc for val: 0.5954346466861297\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.1755649]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5969130463949619, auc for val: 0.5948752854824957\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.21473356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5991279344726496, auc for val: 0.5997101293405458\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.18007462]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6018924086147768, auc for val: 0.6019256634073717\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 500, the loss is [ 0.18125242]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6004377122822135, auc for val: 0.5996957063625112\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 600, the loss is [ 0.17013611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5973617197414635, auc for val: 0.5980465113087776\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 700, the loss is [ 0.16987318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6018375593121119, auc for val: 0.6010195843868835\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 800, the loss is [ 0.22027695]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.603052025246562, auc for val: 0.6016215667373184\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.19158448]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6053957892896116, auc for val: 0.6041039190064292\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.19939417]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6056324808609651, auc for val: 0.6027672932296009\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.20405564]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6053535548689694, auc for val: 0.6029978315840019\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.18917167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6074472796958774, auc for val: 0.6047332086614671\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.18149766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6070669508542252, auc for val: 0.6047458361284667\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 500, the loss is [ 0.22160083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6081158988975646, auc for val: 0.6058210540426117\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 600, the loss is [ 0.19356999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6088502485425018, auc for val: 0.6069642695759869\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 700, the loss is [ 0.2002186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.608895942098088, auc for val: 0.6073503708561009\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 800, the loss is [ 0.20600083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6100850156384444, auc for val: 0.6085027506377033\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 0, the loss is [ 0.15653507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6107850972616463, auc for val: 0.6085457539414236\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.17786063]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6097407217197984, auc for val: 0.6073796127517981\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.20026205]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.609869311691254, auc for val: 0.6078056563213556\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.17035319]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6093791066188676, auc for val: 0.6068018917273718\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.19062951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6090692401828838, auc for val: 0.6068254275817198\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 500, the loss is [ 0.20393378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6096576392532986, auc for val: 0.6085333282031586\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 600, the loss is [ 0.17744355]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6095661072127818, auc for val: 0.6081484097300349\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 700, the loss is [ 0.20848745]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6094306428753675, auc for val: 0.6079845320721322\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 800, the loss is [ 0.18937124]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6100737470147637, auc for val: 0.608026747255517\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.21976122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6081652037832304, auc for val: 0.6065374403920407\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 100, the loss is [ 0.2013143]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6098028341855433, auc for val: 0.607943039854461\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.1656502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6099916936625527, auc for val: 0.6075356480485228\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.20956929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6106595237529453, auc for val: 0.6084562390081647\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.2014115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6102154619422386, auc for val: 0.6082374385095733\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 500, the loss is [ 0.18090998]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6108388423959459, auc for val: 0.6084496446085994\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: iteration 600, the loss is [ 0.20309345]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6100428187834883, auc for val: 0.6076722008601934\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 700, the loss is [ 0.2074092]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6103642383684418, auc for val: 0.6072015263743304\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 800, the loss is [ 0.18029809]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6132171084346645, auc for val: 0.6102508353724726\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.18948101]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.612935615686008, auc for val: 0.609820040527378\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.19642867]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6113325396858149, auc for val: 0.6083415355485023\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 200, the loss is [ 0.19485782]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6110404221089494, auc for val: 0.6079705363580634\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.19841634]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6101091450989071, auc for val: 0.6072824809925924\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.16537377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6116324437173133, auc for val: 0.6085931288697084\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 500, the loss is [ 0.18391268]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6117095141281295, auc for val: 0.6074009621673772\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 600, the loss is [ 0.19650754]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6124942784696802, auc for val: 0.6088657733987991\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 700, the loss is [ 0.185964]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6147723909110429, auc for val: 0.6104528848682539\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 800, the loss is [ 0.17720605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6124341329463497, auc for val: 0.6089960763786187\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.20104627]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6130491253533776, auc for val: 0.6092599826704743\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.16469356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6123505481354183, auc for val: 0.6085750948220279\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.20165749]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6131554476847003, auc for val: 0.6084064796712968\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.20229518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6113686694505844, auc for val: 0.606448734879667\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.19547793]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6099498362900928, auc for val: 0.604950224925785\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 500, the loss is [ 0.16583456]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6101062673045492, auc for val: 0.6055461754617588\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 600, the loss is [ 0.17461979]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6106995696245435, auc for val: 0.6064658843280519\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 700, the loss is [ 0.20163485]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6123234040672966, auc for val: 0.6077221431311932\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 800, the loss is [ 0.18001193]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6112515830042908, auc for val: 0.6078511931375062\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.1891441]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6099056733429747, auc for val: 0.6058168691110997\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.19815102]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.610681105471477, auc for val: 0.6063274996691148\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 200, the loss is [ 0.20514977]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6124451052958025, auc for val: 0.6075271065281284\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.1861423]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6127757828126843, auc for val: 0.6081411725550608\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.18833604]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6147418442883931, auc for val: 0.6094869500503814\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 500, the loss is [ 0.18201892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6147820777565349, auc for val: 0.6097982951721708\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 600, the loss is [ 0.18062072]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6148682239907273, auc for val: 0.610917723003523\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 700, the loss is [ 0.19350021]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.614767228025374, auc for val: 0.6102687466287495\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 800, the loss is [ 0.20245518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6155497661748992, auc for val: 0.6107401566100608\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.17177944]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.616454737542739, auc for val: 0.6119020715200485\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.15760024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.616622943467386, auc for val: 0.6112044672434835\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.22208308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6167875126316842, auc for val: 0.6116016849045481\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: iteration 300, the loss is [ 0.17951062]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6168100109993333, auc for val: 0.6110456077444748\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.16280112]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6180980708954298, auc for val: 0.6125167878402309\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 500, the loss is [ 0.15505159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6189907898205514, auc for val: 0.6133677335204815\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 600, the loss is [ 0.18387477]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.619424693282299, auc for val: 0.6138556251152987\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 700, the loss is [ 0.19041088]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6195592905171078, auc for val: 0.6139251826865444\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 800, the loss is [ 0.19098802]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6204254988119624, auc for val: 0.6139463642036737\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.17293437]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6195649252154264, auc for val: 0.6134146461015423\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.1863026]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200245710659722, auc for val: 0.6138863517846013\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.21232472]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620262689978805, auc for val: 0.6141877633324301\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.18804172]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6193474489562695, auc for val: 0.6131072691468485\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.19571218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200403900072927, auc for val: 0.6143257658344476\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 500, the loss is [ 0.17901076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6205964713025263, auc for val: 0.614322709832065\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 600, the loss is [ 0.16526602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6210807118560543, auc for val: 0.6154543779616033\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 700, the loss is [ 0.20230958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215657143128073, auc for val: 0.6152589792491951\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 800, the loss is [ 0.18982877]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6212770344599908, auc for val: 0.6147400815719833\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.15377803]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6217736342788259, auc for val: 0.6149744114242154\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.20446084]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6222533892884689, auc for val: 0.61626636744256\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.16832624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6224401938606138, auc for val: 0.6166930863648376\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 300, the loss is [ 0.18183912]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.622368164208339, auc for val: 0.6164232647850574\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.17843869]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6228938537814058, auc for val: 0.6177825117455742\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 500, the loss is [ 0.21512458]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6233613693339999, auc for val: 0.6180037442657417\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 600, the loss is [ 0.19823653]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6237449566510882, auc for val: 0.6180882899060736\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 700, the loss is [ 0.19759504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6246658025358213, auc for val: 0.6184601047822651\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 800, the loss is [ 0.19355795]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6245952433559985, auc for val: 0.6183564725965072\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.15690461]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6242472168303976, auc for val: 0.618252632417147\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.20857535]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6251224919823328, auc for val: 0.6188760418675183\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.2212127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247251610348401, auc for val: 0.6184103955643374\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.21912491]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6239180633518536, auc for val: 0.6181080342625906\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 400, the loss is [ 0.18404746]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6231897111537218, auc for val: 0.617513837889526\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 500, the loss is [ 0.18013076]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6247060765068838, auc for val: 0.6191080123706375\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 600, the loss is [ 0.17560142]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6262892235241405, auc for val: 0.6206430615379194\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 700, the loss is [ 0.18788178]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6262577570059562, auc for val: 0.6206392838227969\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 800, the loss is [ 0.19040406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6257620577587434, auc for val: 0.6196720396476101\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: iteration 0, the loss is [ 0.17912227]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6254299249966526, auc for val: 0.6192874569713862\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.21769387]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6258404724955103, auc for val: 0.6201236777069872\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.18507257]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6260583666149531, auc for val: 0.6202364390577141\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.17491852]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268842385611553, auc for val: 0.6213511719973371\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.18810607]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268334162845776, auc for val: 0.6211435317337692\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 500, the loss is [ 0.16026329]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277902145405625, auc for val: 0.622162538750461\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 600, the loss is [ 0.20163059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272766432249649, auc for val: 0.6212091336676547\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 700, the loss is [ 0.25722238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277869826548306, auc for val: 0.6220101007406736\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 800, the loss is [ 0.19714828]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272384236949926, auc for val: 0.6213140326096278\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.16708849]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6259396075680819, auc for val: 0.6201052652613075\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.193666]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277463274616206, auc for val: 0.6218108228222888\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.19274725]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288328633748774, auc for val: 0.6229129320538329\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.21219866]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6286262953097835, auc for val: 0.6228220864627099\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.18309993]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6289773222206438, auc for val: 0.6228793348222267\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 500, the loss is [ 0.1767707]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288538735693707, auc for val: 0.6228900013856885\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 600, the loss is [ 0.1972892]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288702759382601, auc for val: 0.6226938220707856\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 700, the loss is [ 0.18220198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6290682026588283, auc for val: 0.6229716062972003\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 800, the loss is [ 0.19376305]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6289730918297005, auc for val: 0.6227909099759185\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 0, the loss is [ 0.16384606]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6281445261300841, auc for val: 0.6216529180890923\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.19264893]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6288613175269767, auc for val: 0.622923483343732\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.17182514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291809110794866, auc for val: 0.623277447106375\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.18077745]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6299005801934415, auc for val: 0.6240124664248208\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.20898859]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.630299622853111, auc for val: 0.6244458812375177\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 500, the loss is [ 0.17001078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6300012589374457, auc for val: 0.6242743002984964\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 600, the loss is [ 0.19124858]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6303800908715337, auc for val: 0.6246439375067334\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 700, the loss is [ 0.20340939]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.629852258508448, auc for val: 0.6236950757058621\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 800, the loss is [ 0.1859716]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6302221549880609, auc for val: 0.6240276637404825\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.18419118]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312372068790386, auc for val: 0.6255757137608687\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 100, the loss is [ 0.15045078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6301930966931585, auc for val: 0.624594938724784\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.18806584]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6300487671630152, auc for val: 0.6240079995742696\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.20733668]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6306344114164519, auc for val: 0.6248000417170011\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.15596782]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631087134282075, auc for val: 0.6251087217641418\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 500, the loss is [ 0.20580506]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63089300772486, auc for val: 0.624967281102822\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: iteration 600, the loss is [ 0.17424908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311215837167017, auc for val: 0.6253954810397844\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 700, the loss is [ 0.19065554]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631845348959055, auc for val: 0.6256110826970133\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 800, the loss is [ 0.19803707]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631101232158445, auc for val: 0.6246731167537554\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.22434579]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6311625471649652, auc for val: 0.6245895333970766\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.17005551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308766345737267, auc for val: 0.6244988206211453\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 200, the loss is [ 0.21559408]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6305346264420525, auc for val: 0.624334520711171\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.2125503]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6314027335045577, auc for val: 0.6251459300653939\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.22351091]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631865557211176, auc for val: 0.6257033491600928\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 500, the loss is [ 0.17434326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320904131179579, auc for val: 0.626004462500227\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 600, the loss is [ 0.19467647]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6312553125348791, auc for val: 0.6255711466724371\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 700, the loss is [ 0.18480253]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6315342361307095, auc for val: 0.6251670401630333\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 800, the loss is [ 0.16943742]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319478599964506, auc for val: 0.6262471108435695\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.18718317]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6321542895477392, auc for val: 0.6266629389201277\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.18931064]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320283863730894, auc for val: 0.6263232139484138\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.17851169]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320331208089685, auc for val: 0.6264397467493958\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.21548532]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6321800757631714, auc for val: 0.6264952885589967\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.2096678]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320866403945605, auc for val: 0.6264655905809431\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 500, the loss is [ 0.18842047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6322926344621548, auc for val: 0.6266636067550067\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 600, the loss is [ 0.23080575]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6323624907926293, auc for val: 0.62664044303379\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 700, the loss is [ 0.16234846]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324032273008633, auc for val: 0.6265622048620905\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 800, the loss is [ 0.20895655]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6328351764966832, auc for val: 0.627019250755122\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.20644055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326488435053008, auc for val: 0.6269087359858923\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.18367204]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324428832159056, auc for val: 0.6267774180975323\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 200, the loss is [ 0.19193968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331303821893712, auc for val: 0.6275016017010929\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.16135962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326549497070864, auc for val: 0.627034335303168\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.17638651]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324274133417421, auc for val: 0.6267813148451379\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 500, the loss is [ 0.17025244]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331967966218313, auc for val: 0.6274199805009256\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 600, the loss is [ 0.23532318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6328692489604231, auc for val: 0.6271654301622438\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 700, the loss is [ 0.17076145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330493089460064, auc for val: 0.6272914028656246\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 800, the loss is [ 0.15989885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320548673991224, auc for val: 0.6262277348612633\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.18087791]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308495017907699, auc for val: 0.6252935153087903\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.19640021]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6327875516319775, auc for val: 0.6270135785440576\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.19172348]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331988986770424, auc for val: 0.6272312501135194\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: iteration 300, the loss is [ 0.1863111]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6325873511825589, auc for val: 0.6270856094850054\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.18032876]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6324903064162596, auc for val: 0.6269028720698814\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 500, the loss is [ 0.17495632]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6325844531367405, auc for val: 0.6272159011880635\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 600, the loss is [ 0.20005217]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326862482618226, auc for val: 0.6274330026545798\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 700, the loss is [ 0.18112279]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6327433818828421, auc for val: 0.6275868151763039\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 800, the loss is [ 0.20699501]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326633409228876, auc for val: 0.6271807314747065\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.17779495]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331076693262923, auc for val: 0.6275516341861853\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.1941558]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6327587879880942, auc for val: 0.6272942721749546\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.17874457]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330255637222214, auc for val: 0.6274211996441476\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.1800579]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331052954995746, auc for val: 0.627611986161078\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.18696173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333764532014152, auc for val: 0.6278645568016192\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 500, the loss is [ 0.20111378]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335519479512981, auc for val: 0.6280959271304289\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 600, the loss is [ 0.17754304]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338174767519941, auc for val: 0.6281855510723829\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 700, the loss is [ 0.20708783]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341154583633727, auc for val: 0.6281459420738922\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 800, the loss is [ 0.1803409]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337385381826046, auc for val: 0.6277744492118917\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.16730173]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634047461457063, auc for val: 0.6280641279158046\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.22117996]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336993903318721, auc for val: 0.6278494960600699\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 200, the loss is [ 0.1745238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335624082170676, auc for val: 0.6278835894691847\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 300, the loss is [ 0.20926534]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335155012743621, auc for val: 0.6276040172495759\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 400, the loss is [ 0.19701152]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335583714517283, auc for val: 0.6276746899672426\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 500, the loss is [ 0.19926521]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335353405943439, auc for val: 0.6275041377194703\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 600, the loss is [ 0.19296393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633441264367496, auc for val: 0.6270809747360044\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 700, the loss is [ 0.19471885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633193375980121, auc for val: 0.6271945643022194\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 800, the loss is [ 0.19973502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333429878177129, auc for val: 0.6272029767663427\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 0, the loss is [ 0.20849794]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336094747752906, auc for val: 0.6274446189719595\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 100, the loss is [ 0.18332583]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335048030925811, auc for val: 0.6272232448657857\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 200, the loss is [ 0.17113692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335463604033261, auc for val: 0.6274217434346493\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 300, the loss is [ 0.16978708]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339566661213897, auc for val: 0.6275664819222386\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 400, the loss is [ 0.16750923]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633704792138396, auc for val: 0.6273197777036552\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 500, the loss is [ 0.16982323]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335433932551965, auc for val: 0.6271615158730092\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 600, the loss is [ 0.22766255]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334315530965787, auc for val: 0.6271861280315995\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 700, the loss is [ 0.19510305]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338607331757251, auc for val: 0.6276356159884391\n",
      "--------------------------------------------------------------\n",
      "Epoch 30: iteration 800, the loss is [ 0.18108951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633956570970444, auc for val: 0.6275602809563544\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: iteration 0, the loss is [ 0.17169186]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63412688467018, auc for val: 0.6277216238488532\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 100, the loss is [ 0.16490951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338931311837915, auc for val: 0.6274086724150285\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 200, the loss is [ 0.20055103]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340095804047439, auc for val: 0.6274515692160006\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 300, the loss is [ 0.19644187]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343712986180723, auc for val: 0.6278119908040967\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 400, the loss is [ 0.1817783]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6345271725627767, auc for val: 0.6278545405314074\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 500, the loss is [ 0.19447796]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339843059638127, auc for val: 0.6275688826194772\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 600, the loss is [ 0.17552389]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338356788728059, auc for val: 0.6274412397024122\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 700, the loss is [ 0.18222986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340094765966853, auc for val: 0.6273495383303841\n",
      "--------------------------------------------------------------\n",
      "Epoch 31: iteration 800, the loss is [ 0.20547839]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336846617229951, auc for val: 0.6270871293418689\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 0, the loss is [ 0.22734673]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6322458745357765, auc for val: 0.6263488961463788\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 100, the loss is [ 0.17096528]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341499021554169, auc for val: 0.6272503040816344\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 200, the loss is [ 0.1946356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633569351608042, auc for val: 0.6269522505028033\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 300, the loss is [ 0.18004946]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334682119500746, auc for val: 0.6266337220839007\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 400, the loss is [ 0.19343768]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337423337082191, auc for val: 0.6269785103215547\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 500, the loss is [ 0.21108341]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337971573487279, auc for val: 0.6269550960056367\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 600, the loss is [ 0.19375086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338981643673592, auc for val: 0.6273585835461284\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 700, the loss is [ 0.180935]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340748462238399, auc for val: 0.6269044696111022\n",
      "--------------------------------------------------------------\n",
      "Epoch 32: iteration 800, the loss is [ 0.20581579]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338577423751263, auc for val: 0.6269953853687417\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 0, the loss is [ 0.22441284]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6352798871131655, auc for val: 0.6281580345212042\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 100, the loss is [ 0.19576561]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340667481131449, auc for val: 0.6272129993014222\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 200, the loss is [ 0.18586302]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337935556806047, auc for val: 0.6271848550105168\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 300, the loss is [ 0.17206311]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336783828427266, auc for val: 0.6266207776146039\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 400, the loss is [ 0.2087335]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340645005875201, auc for val: 0.6268944834122546\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 500, the loss is [ 0.17403665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339928349977582, auc for val: 0.6270633867468922\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 600, the loss is [ 0.16632453]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634010523643565, auc for val: 0.6270292432188371\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 700, the loss is [ 0.20387641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331694046665589, auc for val: 0.6265805295996246\n",
      "--------------------------------------------------------------\n",
      "Epoch 33: iteration 800, the loss is [ 0.20365387]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339455615963746, auc for val: 0.6269022969550418\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 0, the loss is [ 0.20674488]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336450834127856, auc for val: 0.6266814465917938\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 100, the loss is [ 0.17426315]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336818575140962, auc for val: 0.6267042043495943\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 200, the loss is [ 0.17379896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340436493901795, auc for val: 0.626938179610324\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 300, the loss is [ 0.199292]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341550240743912, auc for val: 0.6268534898780389\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 400, the loss is [ 0.21550566]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339151514778434, auc for val: 0.6267283178247289\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 500, the loss is [ 0.18014303]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342092905678525, auc for val: 0.6272340667979622\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: iteration 600, the loss is [ 0.20253289]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338069614517216, auc for val: 0.6266789018026018\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 700, the loss is [ 0.17884818]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335353694256216, auc for val: 0.6266011610613844\n",
      "--------------------------------------------------------------\n",
      "Epoch 34: iteration 800, the loss is [ 0.21259269]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339663360391342, auc for val: 0.6268722619271149\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 0, the loss is [ 0.17690162]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6344075776407426, auc for val: 0.6270081794812177\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 100, the loss is [ 0.16981298]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343629110351666, auc for val: 0.6269607932761714\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 200, the loss is [ 0.2034041]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343734704712556, auc for val: 0.6271248501092854\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 300, the loss is [ 0.21399392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341424736569409, auc for val: 0.6270211753224282\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 400, the loss is [ 0.20190884]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337483633873107, auc for val: 0.6267789755436011\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 500, the loss is [ 0.20017959]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343547360152998, auc for val: 0.626989084164977\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 600, the loss is [ 0.17515017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341977934582294, auc for val: 0.6269975191826235\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 700, the loss is [ 0.20996624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343202782327427, auc for val: 0.6270572083345312\n",
      "--------------------------------------------------------------\n",
      "Epoch 35: iteration 800, the loss is [ 0.19856192]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634395092538117, auc for val: 0.6270732940084089\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 0, the loss is [ 0.17721272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6347076037220728, auc for val: 0.6271377081234102\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 100, the loss is [ 0.16202669]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342483876353429, auc for val: 0.627052815409417\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 200, the loss is [ 0.17988515]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341747295183067, auc for val: 0.62703013032408\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 300, the loss is [ 0.16853227]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341600547072024, auc for val: 0.6268630387891329\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 400, the loss is [ 0.18119389]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341275631713988, auc for val: 0.6268371097553871\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 500, the loss is [ 0.16971365]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341714208779938, auc for val: 0.6268400078831078\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 600, the loss is [ 0.16447993]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342782427711046, auc for val: 0.6267814100711244\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 700, the loss is [ 0.1751896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340301364872911, auc for val: 0.626710035688294\n",
      "--------------------------------------------------------------\n",
      "Epoch 36: iteration 800, the loss is [ 0.16872293]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341928315412514, auc for val: 0.6268853442234974\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 0, the loss is [ 0.19011444]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6350588343069716, auc for val: 0.6274757916998304\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 100, the loss is [ 0.18507431]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337276146067071, auc for val: 0.626703227030259\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 200, the loss is [ 0.17247526]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342207165654771, auc for val: 0.6270231863449063\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 300, the loss is [ 0.22427699]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336406589324644, auc for val: 0.6267223386351555\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 400, the loss is [ 0.1800039]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335093133710742, auc for val: 0.6267500907453532\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 500, the loss is [ 0.18113078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338325750659665, auc for val: 0.6267197399681027\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 600, the loss is [ 0.19538997]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338141838799939, auc for val: 0.6267502135367569\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 700, the loss is [ 0.1749769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339529867711378, auc for val: 0.6267843294993948\n",
      "--------------------------------------------------------------\n",
      "Epoch 37: iteration 800, the loss is [ 0.18312247]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634103269689566, auc for val: 0.6268034335864501\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 0, the loss is [ 0.20673145]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340287650305673, auc for val: 0.6270429733025227\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 100, the loss is [ 0.18952419]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338479455379238, auc for val: 0.6265543812955153\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 200, the loss is [ 0.17638321]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336405538103799, auc for val: 0.6264477306965799\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: iteration 300, the loss is [ 0.1874814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339425538680288, auc for val: 0.6263279288877193\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 400, the loss is [ 0.18307801]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339255293464496, auc for val: 0.6263970103290325\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 500, the loss is [ 0.19390072]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341122488933792, auc for val: 0.6264513091889148\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 600, the loss is [ 0.20198362]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341226141627943, auc for val: 0.6264086504529088\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 700, the loss is [ 0.18973316]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338332490840375, auc for val: 0.6262029209739386\n",
      "--------------------------------------------------------------\n",
      "Epoch 38: iteration 800, the loss is [ 0.18414941]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340479610188513, auc for val: 0.6264280953487579\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 0, the loss is [ 0.17109887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6353216118462893, auc for val: 0.6272602301377537\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 100, the loss is [ 0.15633729]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633891296571531, auc for val: 0.626438666686233\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 200, the loss is [ 0.21215236]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341595941024218, auc for val: 0.6264802528769173\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 300, the loss is [ 0.23044905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338833964149964, auc for val: 0.626413139856983\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 400, the loss is [ 0.19906896]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339087282865957, auc for val: 0.6262895603329999\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 500, the loss is [ 0.19402023]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633838705615882, auc for val: 0.6262091294576637\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 600, the loss is [ 0.19826737]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339089454100776, auc for val: 0.6262983148588905\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 700, the loss is [ 0.17081763]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334659381439285, auc for val: 0.6259024140729814\n",
      "--------------------------------------------------------------\n",
      "Epoch 39: iteration 800, the loss is [ 0.19494148]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336944653622147, auc for val: 0.6259903602834103\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 0, the loss is [ 0.17498392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342878411903726, auc for val: 0.626385555645235\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 100, the loss is [ 0.21189293]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339343786935702, auc for val: 0.6260865485535653\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 200, the loss is [ 0.17836119]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336919196299707, auc for val: 0.6261831340163222\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 300, the loss is [ 0.17837183]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339988574883546, auc for val: 0.6264749152097793\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 400, the loss is [ 0.18862972]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336312061382015, auc for val: 0.6260386486293814\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 500, the loss is [ 0.1486332]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341189925523933, auc for val: 0.6265364850749204\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 600, the loss is [ 0.20769516]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633307464128138, auc for val: 0.6259019091246583\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 700, the loss is [ 0.22696052]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335641417266177, auc for val: 0.6261096659147622\n",
      "--------------------------------------------------------------\n",
      "Epoch 40: iteration 800, the loss is [ 0.18206497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334996146993475, auc for val: 0.6259269635828963\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 0, the loss is [ 0.19911231]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331211621323115, auc for val: 0.6257438577935615\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 100, the loss is [ 0.18926191]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335605250631382, auc for val: 0.625979047185619\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 200, the loss is [ 0.18799874]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337147917993851, auc for val: 0.6261432493636598\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 300, the loss is [ 0.19036673]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334524128737362, auc for val: 0.625922043155936\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 400, the loss is [ 0.18731032]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337943602510291, auc for val: 0.6261847490991722\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 500, the loss is [ 0.2094276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336359751252363, auc for val: 0.6261010178916196\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 600, the loss is [ 0.20155956]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337515332819313, auc for val: 0.6261362828309631\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 700, the loss is [ 0.16902383]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335399624104605, auc for val: 0.6260464396186454\n",
      "--------------------------------------------------------------\n",
      "Epoch 41: iteration 800, the loss is [ 0.16801998]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339661231669133, auc for val: 0.6263662310348426\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: iteration 0, the loss is [ 0.19640538]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341593348528108, auc for val: 0.6261967024664252\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 100, the loss is [ 0.18070407]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337008049968644, auc for val: 0.6261459733280632\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 200, the loss is [ 0.16970199]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63376594714292, auc for val: 0.6262493687018285\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 300, the loss is [ 0.19691288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331626876745443, auc for val: 0.6258419455715526\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 400, the loss is [ 0.15911905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633576243597409, auc for val: 0.625920621031006\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 500, the loss is [ 0.14489928]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333977937575181, auc for val: 0.6259277742567552\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 600, the loss is [ 0.18473938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334209130411264, auc for val: 0.6260799804664438\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 700, the loss is [ 0.19690092]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334243667653751, auc for val: 0.6260156803720318\n",
      "--------------------------------------------------------------\n",
      "Epoch 42: iteration 800, the loss is [ 0.18579297]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333158482327392, auc for val: 0.6260822395776762\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 0, the loss is [ 0.17714536]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333141599411445, auc for val: 0.6259803177007548\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 100, the loss is [ 0.19312926]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337015046770915, auc for val: 0.6262229873446468\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 200, the loss is [ 0.20182143]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339495001962377, auc for val: 0.6262899312131578\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 300, the loss is [ 0.19081512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339341372992542, auc for val: 0.6263540696739875\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 400, the loss is [ 0.19924624]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337386773147753, auc for val: 0.6262463277351279\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 500, the loss is [ 0.1645885]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332292123306018, auc for val: 0.6260426994927282\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 600, the loss is [ 0.21329336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337218514430176, auc for val: 0.6261838168868832\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 700, the loss is [ 0.19764359]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332305568884397, auc for val: 0.6259630216544695\n",
      "--------------------------------------------------------------\n",
      "Epoch 43: iteration 800, the loss is [ 0.16489808]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334115673786351, auc for val: 0.6261497460312916\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 0, the loss is [ 0.1805512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6326933265337071, auc for val: 0.6257315285342564\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 100, the loss is [ 0.17715093]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336076730909769, auc for val: 0.6262059205925132\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 200, the loss is [ 0.17003439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334448395232114, auc for val: 0.6261289253705323\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 300, the loss is [ 0.19321971]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336141776745444, auc for val: 0.6262706654925202\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 400, the loss is [ 0.17615727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337353369059501, auc for val: 0.6263822127119194\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 500, the loss is [ 0.17958646]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336669587001973, auc for val: 0.6262289514985383\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 600, the loss is [ 0.1759007]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339345796622611, auc for val: 0.6264053438558249\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 700, the loss is [ 0.17525026]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337063198096293, auc for val: 0.6262721001471854\n",
      "--------------------------------------------------------------\n",
      "Epoch 44: iteration 800, the loss is [ 0.21004541]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336656357851418, auc for val: 0.6263483761623735\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 0, the loss is [ 0.1983875]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6308016610393128, auc for val: 0.6247990293144077\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 100, the loss is [ 0.19950551]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336149984770554, auc for val: 0.6263841986749275\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 200, the loss is [ 0.17281775]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329162707644649, auc for val: 0.6258970074923005\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 300, the loss is [ 0.20805806]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336319825730092, auc for val: 0.6262835786374793\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 400, the loss is [ 0.15884969]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338618629289504, auc for val: 0.6264749603168255\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 500, the loss is [ 0.17853054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333946156695586, auc for val: 0.6261446276345171\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: iteration 600, the loss is [ 0.18219548]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339671900787748, auc for val: 0.6264203394427519\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 700, the loss is [ 0.21633802]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334210090423241, auc for val: 0.6261291045457438\n",
      "--------------------------------------------------------------\n",
      "Epoch 45: iteration 800, the loss is [ 0.18123096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334402148471557, auc for val: 0.6261059608721032\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 0, the loss is [ 0.20830174]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332145879162618, auc for val: 0.6261006933714814\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 100, the loss is [ 0.17157882]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331441561196706, auc for val: 0.6260166551854198\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 200, the loss is [ 0.15555644]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338756074096072, auc for val: 0.6263449004138661\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 300, the loss is [ 0.17224041]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338999443315954, auc for val: 0.6264322840391905\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 400, the loss is [ 0.20734642]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332057969273571, auc for val: 0.6260587989493145\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 500, the loss is [ 0.16615994]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.632980093473769, auc for val: 0.6258772756655184\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 600, the loss is [ 0.19401784]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331821439172831, auc for val: 0.6260409666303686\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 700, the loss is [ 0.18908507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334084587021696, auc for val: 0.6261753242324555\n",
      "--------------------------------------------------------------\n",
      "Epoch 46: iteration 800, the loss is [ 0.18768577]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333044482064529, auc for val: 0.6261535500588576\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 0, the loss is [ 0.1710618]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339022100216981, auc for val: 0.6266810418813511\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 100, the loss is [ 0.18847671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332553986283201, auc for val: 0.6260956163228327\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 200, the loss is [ 0.16466725]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331741034691434, auc for val: 0.6261039373198901\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 300, the loss is [ 0.23163675]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335895270868072, auc for val: 0.6264043903429863\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 400, the loss is [ 0.19522302]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335525726547442, auc for val: 0.626266707349213\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 500, the loss is [ 0.20099847]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338847516396338, auc for val: 0.6264538815435239\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 600, the loss is [ 0.19174483]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633509863175035, auc for val: 0.6264101640449048\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 700, the loss is [ 0.18299471]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332870506560654, auc for val: 0.6261692698644716\n",
      "--------------------------------------------------------------\n",
      "Epoch 47: iteration 800, the loss is [ 0.17822248]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332904398384459, auc for val: 0.6262005616248256\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 0, the loss is [ 0.15432149]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336115416609808, auc for val: 0.6261245474811004\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 100, the loss is [ 0.17411448]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334158557413159, auc for val: 0.6262356950019509\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 200, the loss is [ 0.23863451]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330460650021528, auc for val: 0.6260987349738907\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 300, the loss is [ 0.19854113]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337768276651403, auc for val: 0.6265257621276509\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 400, the loss is [ 0.20397258]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333817492674898, auc for val: 0.6263370329932182\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 500, the loss is [ 0.19115382]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334026768329327, auc for val: 0.6263080517160104\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 600, the loss is [ 0.19655]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330049766441181, auc for val: 0.6261223409947551\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 700, the loss is [ 0.16105658]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336589678758652, auc for val: 0.6265076554075069\n",
      "--------------------------------------------------------------\n",
      "Epoch 48: iteration 800, the loss is [ 0.21890287]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333653134295838, auc for val: 0.6263202444012033\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 0, the loss is [ 0.20622252]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6350021319956811, auc for val: 0.6273626694927333\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 100, the loss is [ 0.18798932]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334652768796399, auc for val: 0.6263099812952105\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 200, the loss is [ 0.2087369]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335655440243062, auc for val: 0.6264243639936552\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: iteration 300, the loss is [ 0.16661082]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335894586801566, auc for val: 0.6264227601875667\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 400, the loss is [ 0.14923276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335894351049832, auc for val: 0.6264930194239762\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 500, the loss is [ 0.18296327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335557654288771, auc for val: 0.626416352481054\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 600, the loss is [ 0.17976516]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334056507830796, auc for val: 0.6263050232790448\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 700, the loss is [ 0.20973493]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332728763342972, auc for val: 0.6262811491218501\n",
      "--------------------------------------------------------------\n",
      "Epoch 49: iteration 800, the loss is [ 0.18183024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335824679069485, auc for val: 0.6263731800259102\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 0, the loss is [ 0.20582637]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633100548773687, auc for val: 0.626429540027211\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 100, the loss is [ 0.19105929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331095626059517, auc for val: 0.6261762201085127\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 200, the loss is [ 0.22917457]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334654224273495, auc for val: 0.6263245483651985\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 300, the loss is [ 0.19458044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335477499472324, auc for val: 0.6264476129170703\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 400, the loss is [ 0.17329854]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335331222091791, auc for val: 0.6264782481193067\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 500, the loss is [ 0.1887373]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633507096609118, auc for val: 0.62644529742203\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 600, the loss is [ 0.17138869]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334605046461879, auc for val: 0.6263983685523136\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 700, the loss is [ 0.16196254]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329024666888616, auc for val: 0.626102980048131\n",
      "--------------------------------------------------------------\n",
      "Epoch 50: iteration 800, the loss is [ 0.18208115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336345278414793, auc for val: 0.6265263222068083\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 0, the loss is [ 0.17058507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333768078338591, auc for val: 0.6261931177092228\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 100, the loss is [ 0.178986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633322440314983, auc for val: 0.626302006118841\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 200, the loss is [ 0.18898684]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338106398744258, auc for val: 0.6265920820153557\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 300, the loss is [ 0.2223496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334154166247263, auc for val: 0.6263652825338981\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 400, the loss is [ 0.167502]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333832979631401, auc for val: 0.6263227039881967\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 500, the loss is [ 0.17767522]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335450691794872, auc for val: 0.6264825032173353\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 600, the loss is [ 0.17214336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334365575261643, auc for val: 0.6263745332372974\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 700, the loss is [ 0.17056032]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332688308345494, auc for val: 0.6262998723049592\n",
      "--------------------------------------------------------------\n",
      "Epoch 51: iteration 800, the loss is [ 0.16526134]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333479689040125, auc for val: 0.626333488331168\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 0, the loss is [ 0.17086306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633216328691603, auc for val: 0.6264366067977882\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 100, the loss is [ 0.17970121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333586803806452, auc for val: 0.6263770304134961\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 200, the loss is [ 0.17978059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336342187361738, auc for val: 0.6265232962757898\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 300, the loss is [ 0.20722198]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334464594081556, auc for val: 0.626420522376884\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 400, the loss is [ 0.19026075]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335590648710075, auc for val: 0.6264828866272283\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 500, the loss is [ 0.19799037]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337548351202271, auc for val: 0.6265806060310085\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 600, the loss is [ 0.17438799]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337642990450635, auc for val: 0.6266405207181475\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 700, the loss is [ 0.20670518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334145313576429, auc for val: 0.6263983785761016\n",
      "--------------------------------------------------------------\n",
      "Epoch 52: iteration 800, the loss is [ 0.21349089]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331444108861343, auc for val: 0.6262076534548731\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: iteration 0, the loss is [ 0.21568422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63303385777739, auc for val: 0.6260740789612276\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 100, the loss is [ 0.15906999]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334017053811993, auc for val: 0.6263520386039333\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 200, the loss is [ 0.22670411]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333988991626136, auc for val: 0.6263759152670751\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 300, the loss is [ 0.18276615]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333730183373054, auc for val: 0.6264507741692275\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 400, the loss is [ 0.16987462]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336228472319823, auc for val: 0.626546839647979\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 500, the loss is [ 0.2105327]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333423466502937, auc for val: 0.6263830810225595\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 600, the loss is [ 0.18267488]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633335490835291, auc for val: 0.6263029095127393\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 700, the loss is [ 0.14211483]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332308983806227, auc for val: 0.6262953265170772\n",
      "--------------------------------------------------------------\n",
      "Epoch 53: iteration 800, the loss is [ 0.16812822]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336882029459198, auc for val: 0.626704814547692\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 0, the loss is [ 0.1796688]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329714523611305, auc for val: 0.6261610641409768\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 100, the loss is [ 0.18865986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334156364535559, auc for val: 0.6264625270607194\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 200, the loss is [ 0.20136259]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334958997930965, auc for val: 0.6264802353352883\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 300, the loss is [ 0.17675622]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335250546302661, auc for val: 0.6264992617379861\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 400, the loss is [ 0.19205119]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339531543481078, auc for val: 0.6267266125277864\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 500, the loss is [ 0.21883947]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334304992476817, auc for val: 0.6265169274114557\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 600, the loss is [ 0.19459347]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633728596802536, auc for val: 0.6267286686573108\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 700, the loss is [ 0.18388927]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633135996945412, auc for val: 0.6263071495750856\n",
      "--------------------------------------------------------------\n",
      "Epoch 54: iteration 800, the loss is [ 0.18350159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334349364044897, auc for val: 0.6264627613667652\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 0, the loss is [ 0.20554954]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6325258917104681, auc for val: 0.6256292157296008\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 100, the loss is [ 0.19991514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335460200705777, auc for val: 0.6265059776759816\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 200, the loss is [ 0.20297346]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338789686109622, auc for val: 0.6266666514806277\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 300, the loss is [ 0.18427038]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335800600701446, auc for val: 0.6265572368221368\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 400, the loss is [ 0.20118035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336585170103367, auc for val: 0.6265747120436335\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 500, the loss is [ 0.17698981]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333470381870867, auc for val: 0.6264193470877347\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 600, the loss is [ 0.17750901]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339787315561013, auc for val: 0.6267811757650786\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 700, the loss is [ 0.17453407]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334622024451476, auc for val: 0.6264773522432495\n",
      "--------------------------------------------------------------\n",
      "Epoch 55: iteration 800, the loss is [ 0.19172376]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339343223450411, auc for val: 0.6267360674658673\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 0, the loss is [ 0.21541123]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336320772601809, auc for val: 0.6268097623556319\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 100, the loss is [ 0.17624864]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334139122967795, auc for val: 0.6264509383087568\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 200, the loss is [ 0.17852047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333046010199537, auc for val: 0.6262982133680366\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 300, the loss is [ 0.17741838]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333043295576296, auc for val: 0.6263549417435481\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 400, the loss is [ 0.20460612]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340226817855897, auc for val: 0.6268267789888251\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 500, the loss is [ 0.16800483]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338894059972189, auc for val: 0.6266729288778958\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: iteration 600, the loss is [ 0.17004167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335451541274069, auc for val: 0.6266106899249022\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 700, the loss is [ 0.18571341]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337293474978922, auc for val: 0.6266608176359809\n",
      "--------------------------------------------------------------\n",
      "Epoch 56: iteration 800, the loss is [ 0.18736207]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338859931623695, auc for val: 0.6267735451564234\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 0, the loss is [ 0.18959652]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6351621373928964, auc for val: 0.6271672106375967\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 100, the loss is [ 0.20309439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337843415753099, auc for val: 0.626680059550122\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 200, the loss is [ 0.19116482]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335582081260192, auc for val: 0.6266022123061565\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 300, the loss is [ 0.16587579]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338137041058921, auc for val: 0.6267294079116796\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 400, the loss is [ 0.19105527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336598577806876, auc for val: 0.6265693718705483\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 500, the loss is [ 0.18083824]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337658506779484, auc for val: 0.6266818350135808\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 600, the loss is [ 0.20266786]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333431293460489, auc for val: 0.6264727914196856\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 700, the loss is [ 0.18808766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337284393512963, auc for val: 0.6266540428082308\n",
      "--------------------------------------------------------------\n",
      "Epoch 57: iteration 800, the loss is [ 0.19538507]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338583865570762, auc for val: 0.6267633183866625\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 0, the loss is [ 0.17839915]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6344158544589812, auc for val: 0.6270045847002272\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 100, the loss is [ 0.15602382]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337433697791162, auc for val: 0.6266532033159813\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 200, the loss is [ 0.18988153]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337535968439084, auc for val: 0.6266527760520155\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 300, the loss is [ 0.18651804]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332108848362451, auc for val: 0.6263877746613153\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 400, the loss is [ 0.18785582]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334327443771416, auc for val: 0.6264270278153302\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 500, the loss is [ 0.17977531]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337324002123066, auc for val: 0.6265647183269448\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 600, the loss is [ 0.16809812]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332096529754656, auc for val: 0.626271852058431\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 700, the loss is [ 0.1955677]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340103340373346, auc for val: 0.6268061487800388\n",
      "--------------------------------------------------------------\n",
      "Epoch 58: iteration 800, the loss is [ 0.20821117]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6331635444195327, auc for val: 0.6262676859215215\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 0, the loss is [ 0.18582538]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338911740579249, auc for val: 0.6267790933231107\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 100, the loss is [ 0.21167454]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339330885518705, auc for val: 0.6268051326185249\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 200, the loss is [ 0.17139213]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337340865715103, auc for val: 0.6266912548684035\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 300, the loss is [ 0.19684668]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334321661283814, auc for val: 0.6264519695059527\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 400, the loss is [ 0.19810292]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633397622702244, auc for val: 0.6264758286274656\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 500, the loss is [ 0.20311013]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337037663478204, auc for val: 0.6267066852371375\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 600, the loss is [ 0.17560312]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340213934216898, auc for val: 0.6269114048194614\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 700, the loss is [ 0.18766293]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340150009168153, auc for val: 0.6269163941599647\n",
      "--------------------------------------------------------------\n",
      "Epoch 59: iteration 800, the loss is [ 0.19057983]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338740150419143, auc for val: 0.6268236365312705\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 0, the loss is [ 0.18838966]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343533172536376, auc for val: 0.6270605876040785\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 100, the loss is [ 0.16963968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633197720072966, auc for val: 0.626306927798775\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 200, the loss is [ 0.21511465]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342451126186379, auc for val: 0.627044935459034\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: iteration 300, the loss is [ 0.17744374]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339268964746172, auc for val: 0.6267981723506957\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 400, the loss is [ 0.22275087]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334252991055095, auc for val: 0.6265382104194389\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 500, the loss is [ 0.17731036]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337364995098268, auc for val: 0.6267166188110977\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 600, the loss is [ 0.18062213]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333099123132712, auc for val: 0.6264582055550951\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 700, the loss is [ 0.18261528]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335557143364523, auc for val: 0.6266265112213701\n",
      "--------------------------------------------------------------\n",
      "Epoch 60: iteration 800, the loss is [ 0.15284078]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339808005287739, auc for val: 0.6268935085988665\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 0, the loss is [ 0.20392364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6349212365323121, auc for val: 0.6275413084315173\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 100, the loss is [ 0.20498891]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332938883838859, auc for val: 0.6263246987220191\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 200, the loss is [ 0.16247743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337461087504861, auc for val: 0.6266691699573761\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 300, the loss is [ 0.18695484]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336152922005268, auc for val: 0.6266621708473682\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 400, the loss is [ 0.17998438]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341238986619118, auc for val: 0.6268561136045617\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 500, the loss is [ 0.17779346]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336184978057378, auc for val: 0.6266632133213257\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 600, the loss is [ 0.19666138]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334321352874169, auc for val: 0.6264667232689931\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 700, the loss is [ 0.1661665]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341704768662162, auc for val: 0.6268638093678394\n",
      "--------------------------------------------------------------\n",
      "Epoch 61: iteration 800, the loss is [ 0.20229918]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340391351696082, auc for val: 0.6268999012696972\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 0, the loss is [ 0.18327017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338401425420219, auc for val: 0.6266330016241343\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 100, the loss is [ 0.16957229]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337226249405906, auc for val: 0.6267699140392012\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 200, the loss is [ 0.18715827]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336400792150868, auc for val: 0.6266528299298764\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 300, the loss is [ 0.19629121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336473897604005, auc for val: 0.6265542234208534\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 400, the loss is [ 0.16115056]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63337144823076, auc for val: 0.6264260555078891\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 500, the loss is [ 0.19128875]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337793928758882, auc for val: 0.6267693664897789\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 600, the loss is [ 0.22698663]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336490074810665, auc for val: 0.6266668143671836\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 700, the loss is [ 0.16618715]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633505461419635, auc for val: 0.6264907853722139\n",
      "--------------------------------------------------------------\n",
      "Epoch 62: iteration 800, the loss is [ 0.1975679]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336656642299411, auc for val: 0.6266371690140173\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 0, the loss is [ 0.15670054]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338469144139482, auc for val: 0.6268683338551717\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 100, the loss is [ 0.18670696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335121821991364, auc for val: 0.6265654889056513\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 200, the loss is [ 0.19509722]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333255275805532, auc for val: 0.6263825848450508\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 300, the loss is [ 0.17500226]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335100438149699, auc for val: 0.6264890687985099\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 400, the loss is [ 0.18974355]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336333125219691, auc for val: 0.6266864008490388\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 500, the loss is [ 0.14985543]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333969739598507, auc for val: 0.6264657446966844\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 600, the loss is [ 0.20322683]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337336084979128, auc for val: 0.626711640747356\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 700, the loss is [ 0.16812405]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338212644707477, auc for val: 0.6267031267923786\n",
      "--------------------------------------------------------------\n",
      "Epoch 63: iteration 800, the loss is [ 0.15633529]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338144299893445, auc for val: 0.6266983015914047\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: iteration 0, the loss is [ 0.17974937]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6351355885012823, auc for val: 0.6276827515987842\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 100, the loss is [ 0.20778738]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338117672314859, auc for val: 0.6268167927899775\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 200, the loss is [ 0.1740842]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338179064385142, auc for val: 0.626667074985673\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 300, the loss is [ 0.15191083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339368176032256, auc for val: 0.6267844034248317\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 400, the loss is [ 0.18162562]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338983777033542, auc for val: 0.6267850599829491\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 500, the loss is [ 0.20059231]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337414712433526, auc for val: 0.6267178717846044\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 600, the loss is [ 0.19479057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336794179087802, auc for val: 0.6266418714235876\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 700, the loss is [ 0.21305351]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341504885975161, auc for val: 0.6269326740447361\n",
      "--------------------------------------------------------------\n",
      "Epoch 64: iteration 800, the loss is [ 0.18825483]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338919026467251, auc for val: 0.6268007008512322\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 0, the loss is [ 0.18356322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6323953025643121, auc for val: 0.6257335921816217\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 100, the loss is [ 0.17489663]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338294949888916, auc for val: 0.6266761991387481\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 200, the loss is [ 0.19273071]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335624031155546, auc for val: 0.626619771476878\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 300, the loss is [ 0.21342319]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340169733472207, auc for val: 0.6267928234067961\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 400, the loss is [ 0.17092517]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633417622256109, auc for val: 0.6264990762979071\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 500, the loss is [ 0.17122766]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340490241432262, auc for val: 0.6268631766162185\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 600, the loss is [ 0.17396739]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338493966091676, auc for val: 0.6268362652512437\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 700, the loss is [ 0.18747848]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337262581453394, auc for val: 0.626648315466332\n",
      "--------------------------------------------------------------\n",
      "Epoch 65: iteration 800, the loss is [ 0.17210945]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338462889375457, auc for val: 0.6267359421685166\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 0, the loss is [ 0.15194333]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343135585353803, auc for val: 0.62713105483409\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 100, the loss is [ 0.15584336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337787233409651, auc for val: 0.626745977233331\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 200, the loss is [ 0.18018965]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339473801311403, auc for val: 0.6268738532034683\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 300, the loss is [ 0.20541924]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339946432522023, auc for val: 0.6267567264930443\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 400, the loss is [ 0.18973605]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339742464759901, auc for val: 0.6268000555698762\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 500, the loss is [ 0.19301753]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335954800113182, auc for val: 0.6266383443031665\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 600, the loss is [ 0.19603409]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338324561079606, auc for val: 0.6267371613117385\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 700, the loss is [ 0.2021905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338056654355523, auc for val: 0.6266960650336953\n",
      "--------------------------------------------------------------\n",
      "Epoch 66: iteration 800, the loss is [ 0.17742994]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633607617360813, auc for val: 0.62663333240914\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 0, the loss is [ 0.19881907]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6291936231994374, auc for val: 0.6235733142464371\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 100, the loss is [ 0.18588406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337263085421033, auc for val: 0.6267665259988394\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 200, the loss is [ 0.21577364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335148604161251, auc for val: 0.6265531358398497\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 300, the loss is [ 0.22081263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337798105815827, auc for val: 0.6266652356205653\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 400, the loss is [ 0.17285651]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337879343544337, auc for val: 0.6266758821364509\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 500, the loss is [ 0.21329872]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340468236906521, auc for val: 0.6267372703204337\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: iteration 600, the loss is [ 0.18464762]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336375945464067, auc for val: 0.626658173861882\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 700, the loss is [ 0.19043218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338192901079511, auc for val: 0.6268300041426311\n",
      "--------------------------------------------------------------\n",
      "Epoch 67: iteration 800, the loss is [ 0.23193796]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336043445856818, auc for val: 0.6266814328090852\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 0, the loss is [ 0.19082986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.632669137710185, auc for val: 0.6258428276649013\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 100, the loss is [ 0.18394354]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335226757793312, auc for val: 0.6265408955416637\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 200, the loss is [ 0.1938708]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334239524606893, auc for val: 0.6264748475492099\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 300, the loss is [ 0.2114445]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633893911019608, auc for val: 0.6268386709603764\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 400, the loss is [ 0.18861669]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334360353940462, auc for val: 0.6265597540459116\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 500, the loss is [ 0.17737289]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339525143401229, auc for val: 0.6268849257303462\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 600, the loss is [ 0.2028982]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336317955175353, auc for val: 0.6266167793761442\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 700, the loss is [ 0.18757683]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338615422292971, auc for val: 0.6267929624868553\n",
      "--------------------------------------------------------------\n",
      "Epoch 68: iteration 800, the loss is [ 0.20458929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634038118809102, auc for val: 0.6268633996455028\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 0, the loss is [ 0.19171339]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341985213513686, auc for val: 0.6270617653991747\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 100, the loss is [ 0.18261692]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633676101848085, auc for val: 0.6266348472541095\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 200, the loss is [ 0.22731461]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337411412682211, auc for val: 0.6267022860471556\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 300, the loss is [ 0.20903315]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63392639405289, auc for val: 0.6267971323826853\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 400, the loss is [ 0.17869604]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334817021280418, auc for val: 0.6265686915059342\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 500, the loss is [ 0.19469114]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339905396261257, auc for val: 0.6267871436778907\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 600, the loss is [ 0.19160178]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336820959711776, auc for val: 0.6266993603540177\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 700, the loss is [ 0.21848743]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335957334637556, auc for val: 0.6265906836969222\n",
      "--------------------------------------------------------------\n",
      "Epoch 69: iteration 800, the loss is [ 0.18048808]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343719679211086, auc for val: 0.6271178309517014\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 0, the loss is [ 0.1707585]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631485710848973, auc for val: 0.6252813639717232\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 100, the loss is [ 0.19033697]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338684293490382, auc for val: 0.6268393200006528\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 200, the loss is [ 0.1863351]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336172444567673, auc for val: 0.6266818801206271\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 300, the loss is [ 0.19720039]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337928822808988, auc for val: 0.6267843733534675\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 400, the loss is [ 0.1893422]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337874565900189, auc for val: 0.6267514351859258\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 500, the loss is [ 0.17391691]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337316539228025, auc for val: 0.6266999705521155\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 600, the loss is [ 0.17368437]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338396295307905, auc for val: 0.626791952590209\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 700, the loss is [ 0.16812778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340160426302949, auc for val: 0.6268119262408778\n",
      "--------------------------------------------------------------\n",
      "Epoch 70: iteration 800, the loss is [ 0.19842596]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342075922278232, auc for val: 0.6269322693342934\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 0, the loss is [ 0.18469545]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6323670317574952, auc for val: 0.6256212606008074\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 100, the loss is [ 0.18343282]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337535449785272, auc for val: 0.6266434514231795\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 200, the loss is [ 0.21744061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337207769561822, auc for val: 0.6266744111455541\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: iteration 300, the loss is [ 0.18947574]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340065494877026, auc for val: 0.6268674855921078\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 400, the loss is [ 0.17954265]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336529702744682, auc for val: 0.6266786875441323\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 500, the loss is [ 0.15311749]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335183442856773, auc for val: 0.626638929441794\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 600, the loss is [ 0.190548]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334061154072339, auc for val: 0.6264967770915226\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 700, the loss is [ 0.18915412]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336149003115795, auc for val: 0.6265974171765467\n",
      "--------------------------------------------------------------\n",
      "Epoch 71: iteration 800, the loss is [ 0.18689096]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342059915894959, auc for val: 0.6270024897285241\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 0, the loss is [ 0.21296249]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6347736900344972, auc for val: 0.6274181423887913\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 100, the loss is [ 0.20616648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338899632215624, auc for val: 0.6267879029798356\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 200, the loss is [ 0.19688427]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340383816916089, auc for val: 0.6268106883030533\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 300, the loss is [ 0.20408794]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335682478261551, auc for val: 0.6266460688848348\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 400, the loss is [ 0.16936989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336675349392707, auc for val: 0.6266695984743154\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 500, the loss is [ 0.16912727]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338073895150331, auc for val: 0.6267581573887888\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 600, the loss is [ 0.19291587]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336902155700634, auc for val: 0.6266831594065773\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 700, the loss is [ 0.20528437]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339303193579013, auc for val: 0.6267798764315522\n",
      "--------------------------------------------------------------\n",
      "Epoch 72: iteration 800, the loss is [ 0.16306967]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333955793144315, auc for val: 0.626493637139915\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 0, the loss is [ 0.14713657]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6346013137003319, auc for val: 0.6271381967830777\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 100, the loss is [ 0.18785377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338129756716833, auc for val: 0.6268025063860552\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 200, the loss is [ 0.18283646]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337714306509465, auc for val: 0.62671145280133\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 300, the loss is [ 0.18398117]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337949306156329, auc for val: 0.626727665025532\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 400, the loss is [ 0.20965524]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633702413983122, auc for val: 0.6266880434973061\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 500, the loss is [ 0.22092882]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341771574519794, auc for val: 0.6269540146895005\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 600, the loss is [ 0.19848415]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338139615004078, auc for val: 0.6267436216431387\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 700, the loss is [ 0.17691955]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337846792800064, auc for val: 0.6267725828727704\n",
      "--------------------------------------------------------------\n",
      "Epoch 73: iteration 800, the loss is [ 0.20278989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332571315968009, auc for val: 0.6263707567751485\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 0, the loss is [ 0.17864394]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339091019337695, auc for val: 0.6267047731995663\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 100, the loss is [ 0.15287514]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334279554478291, auc for val: 0.626556517615344\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 200, the loss is [ 0.18452947]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633843785795205, auc for val: 0.6267704678534912\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 300, the loss is [ 0.18207905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633865262468948, auc for val: 0.6267996157761754\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 400, the loss is [ 0.16699092]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634100640168837, auc for val: 0.626982651398994\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 500, the loss is [ 0.19030537]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335272098648845, auc for val: 0.626558305608538\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 600, the loss is [ 0.18237855]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6343998572738909, auc for val: 0.6270968348746512\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 700, the loss is [ 0.17075129]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338629429810726, auc for val: 0.6267253532894123\n",
      "--------------------------------------------------------------\n",
      "Epoch 74: iteration 800, the loss is [ 0.17180224]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337508658339907, auc for val: 0.6267427508265515\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: iteration 0, the loss is [ 0.17600633]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633358553383892, auc for val: 0.6263899786417134\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 100, the loss is [ 0.21717016]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337160632355376, auc for val: 0.6267389442930384\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 200, the loss is [ 0.16921635]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338387046110386, auc for val: 0.626761884984971\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 300, the loss is [ 0.16049057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336378098920885, auc for val: 0.6266576463600357\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 400, the loss is [ 0.18004376]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633981857624088, auc for val: 0.626787297793632\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 500, the loss is [ 0.18629952]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340799438719799, auc for val: 0.6269526865375835\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 600, the loss is [ 0.1567879]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337233026688529, auc for val: 0.6267466112379254\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 700, the loss is [ 0.19070968]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340083343988603, auc for val: 0.6268733181837811\n",
      "--------------------------------------------------------------\n",
      "Epoch 75: iteration 800, the loss is [ 0.20968959]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338572312962861, auc for val: 0.6268009602167479\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 0, the loss is [ 0.21530136]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6345195555402094, auc for val: 0.6270605374851382\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 100, the loss is [ 0.19466247]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341312204923903, auc for val: 0.6269427091095504\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 200, the loss is [ 0.16786933]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633486391191374, auc for val: 0.6265489521613112\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 300, the loss is [ 0.1770674]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336574269870755, auc for val: 0.6266857317611865\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 400, the loss is [ 0.18639639]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339243944144156, auc for val: 0.6267448520631221\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 500, the loss is [ 0.20029788]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337082327996796, auc for val: 0.6267571036380697\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 600, the loss is [ 0.21593322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338506273105123, auc for val: 0.6267767064085806\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 700, the loss is [ 0.20361711]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342230723050126, auc for val: 0.626926510668057\n",
      "--------------------------------------------------------------\n",
      "Epoch 76: iteration 800, the loss is [ 0.16316044]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633775618529282, auc for val: 0.6268186108545355\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 0, the loss is [ 0.21318358]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338927178839493, auc for val: 0.6267921067059503\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 100, the loss is [ 0.19794506]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633816425376558, auc for val: 0.6267461275901518\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 200, the loss is [ 0.18884107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340088244532835, auc for val: 0.6269531739442775\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 300, the loss is [ 0.19782065]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338271398677214, auc for val: 0.6267368731278322\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 400, the loss is [ 0.17677768]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338978374067583, auc for val: 0.6267793038226598\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 500, the loss is [ 0.20701411]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340455471529868, auc for val: 0.6268920501377049\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 600, the loss is [ 0.17476241]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337663599789886, auc for val: 0.6267221130999242\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 700, the loss is [ 0.18050155]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340649115684929, auc for val: 0.6268525514008825\n",
      "--------------------------------------------------------------\n",
      "Epoch 77: iteration 800, the loss is [ 0.20817225]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6336037089835491, auc for val: 0.626616719233416\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 0, the loss is [ 0.21275252]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337956841709279, auc for val: 0.6266776262755721\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 100, the loss is [ 0.18422367]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340234801723622, auc for val: 0.6268414287550644\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 200, the loss is [ 0.18262652]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339361517784936, auc for val: 0.626832729360008\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 300, the loss is [ 0.17405476]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338348532006691, auc for val: 0.6267328636126109\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 400, the loss is [ 0.17036489]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337739650980255, auc for val: 0.6268096245285462\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 500, the loss is [ 0.20581475]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337693404992656, auc for val: 0.6267319978079178\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: iteration 600, the loss is [ 0.18160711]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342393741895566, auc for val: 0.6270087395603751\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 700, the loss is [ 0.19447562]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633576150069672, auc for val: 0.6266166628496082\n",
      "--------------------------------------------------------------\n",
      "Epoch 78: iteration 800, the loss is [ 0.20730288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633591509565647, auc for val: 0.6265883130710477\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 0, the loss is [ 0.19565938]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6323294887963508, auc for val: 0.6256737451550521\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 100, the loss is [ 0.19805993]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337355148405374, auc for val: 0.6267594855407057\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 200, the loss is [ 0.17859913]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6335373151890277, auc for val: 0.6265899857906789\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 300, the loss is [ 0.18196324]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334144611731924, auc for val: 0.6264617188928077\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 400, the loss is [ 0.22049122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339056107984262, auc for val: 0.6267978641192131\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 500, the loss is [ 0.17504415]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340708929378033, auc for val: 0.6269379565810398\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 600, the loss is [ 0.17822602]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634019237182228, auc for val: 0.6268328759579083\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 700, the loss is [ 0.17317916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338025270775571, auc for val: 0.6267798789374992\n",
      "--------------------------------------------------------------\n",
      "Epoch 79: iteration 800, the loss is [ 0.22748958]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338473363709034, auc for val: 0.6267288127492641\n",
      "--------------------------------------------------------------\n",
      "Learning rate is 0.00012123533828619627. Weight decay is 0.09556399115764713. dropout is 0.75\n",
      " Val aus is 0.6267288127492641. Train auc is 0.6338473363709034\n",
      "This is round you consume 6:18:04.303331 time to run this model.\n",
      "You have finished 4!!\n",
      "Epoch 0: iteration 0, the loss is [ 0.94123596]\n",
      "  acc for train: 0.1888265601373929, acc for val: 0.18849521178293416\n",
      "  auc for train: 0.4955630562962641, auc for val: 0.49485942559444374\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.20898148]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5000837360785191, auc for val: 0.5058270685660382\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.14906761]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4743290422763837, auc for val: 0.47847105712392424\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.15541779]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.48325925069570275, auc for val: 0.49050743763068766\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.17495032]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47126770050779043, auc for val: 0.47696282660157785\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 500, the loss is [ 0.19947299]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4707180788100561, auc for val: 0.4774641237599421\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.15300527]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.45694483845150724, auc for val: 0.4658679303876788\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.14081395]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4549939721412208, auc for val: 0.4619333555119668\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.16408017]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4923533380291627, auc for val: 0.49867177039863925\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.14416641]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5304485197059374, auc for val: 0.5313579749919318\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.15131702]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5760885710884066, auc for val: 0.5804479884482658\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.15689486]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.601035444647816, auc for val: 0.5979487680985007\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.17768821]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6008015012460148, auc for val: 0.5994897425774952\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.18159758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6012528527322094, auc for val: 0.601473400114215\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.15751633]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6051514544151697, auc for val: 0.6040168949845014\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 600, the loss is [ 0.14217472]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6122278197250148, auc for val: 0.6108131172573504\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.17645566]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6158935511789833, auc for val: 0.614950528496206\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.15665215]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6147678879756366, auc for val: 0.6140392546475594\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.15639199]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6137770503384499, auc for val: 0.6149084686815363\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.15905911]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6159574916095629, auc for val: 0.6152538658643145\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: iteration 200, the loss is [ 0.14255184]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6148138926462153, auc for val: 0.6136001237697253\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.18940867]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6177760457763516, auc for val: 0.6157283042825912\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.14434986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6167810623096632, auc for val: 0.6150329854297023\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.18872085]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6167958009669746, auc for val: 0.6150658108296285\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.15901218]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6161170095031114, auc for val: 0.6115291527741976\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.16428421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6175607845013509, auc for val: 0.6176819606216688\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.16370115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6173192871502331, auc for val: 0.6149300160669293\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.1481671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6165536705644804, auc for val: 0.6149570138870764\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.16384101]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6154972638000658, auc for val: 0.6132132468990109\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.12939648]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6155957134148099, auc for val: 0.6138362779513831\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.15146978]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6137988671130544, auc for val: 0.611894756660717\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.19218232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6150043883948468, auc for val: 0.6152825163565167\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 500, the loss is [ 0.18654115]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6156483446414924, auc for val: 0.6135332438028631\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 600, the loss is [ 0.18640472]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187756285661223, auc for val: 0.6147691881465418\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.15808859]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6128113573627973, auc for val: 0.6102595322615819\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.16845617]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6142821805825522, auc for val: 0.6126354344075184\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.21487992]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6117917549222927, auc for val: 0.6096172129350489\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.16505779]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.614999891102023, auc for val: 0.6116745854091095\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.16782761]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6137649161580767, auc for val: 0.6099185693520435\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.11261208]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6109786708457786, auc for val: 0.6099187222148112\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.12539035]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6110300998932116, auc for val: 0.6084370008529443\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.18529405]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6143826004634234, auc for val: 0.6150166917622224\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.13082619]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6141540416312162, auc for val: 0.6146162464414049\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 700, the loss is [ 0.19161306]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6155414190176189, auc for val: 0.6161051962074316\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 800, the loss is [ 0.17521843]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6125411354793953, auc for val: 0.6146939007274503\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 0, the loss is [ 0.12728608]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6043030166222154, auc for val: 0.6085228984516896\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 100, the loss is [ 0.17758787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6179299026137647, auc for val: 0.61833559555194\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 200, the loss is [ 0.11292952]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187192931772839, auc for val: 0.615751977964025\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 300, the loss is [ 0.13242871]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6172190362376532, auc for val: 0.6144856051587386\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 400, the loss is [ 0.14553402]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6217549591859295, auc for val: 0.6230132488716923\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 500, the loss is [ 0.15296263]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6213650319250089, auc for val: 0.6221770594604291\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 600, the loss is [ 0.12000821]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6212441790935612, auc for val: 0.6166029061026466\n",
      "--------------------------------------------------------------\n",
      "Epoch 5: iteration 700, the loss is [ 0.15369356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620544309956102, auc for val: 0.6180428558337503\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: iteration 800, the loss is [ 0.14209147]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6178768532176137, auc for val: 0.6142321298713254\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 0, the loss is [ 0.24128741]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6198650514719194, auc for val: 0.6198657806760692\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 100, the loss is [ 0.10800971]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6187635367437655, auc for val: 0.6182793169939172\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 200, the loss is [ 0.14631449]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6191715297759708, auc for val: 0.6171550125896773\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 300, the loss is [ 0.1319599]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6189032371920012, auc for val: 0.6186549672220125\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 400, the loss is [ 0.17630045]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200285396565477, auc for val: 0.6190238551520928\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 500, the loss is [ 0.15704945]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215267307153318, auc for val: 0.6204632635986418\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 600, the loss is [ 0.1188271]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6214423175269157, auc for val: 0.617631797827332\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 700, the loss is [ 0.18051261]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207818540984789, auc for val: 0.6180523383372485\n",
      "--------------------------------------------------------------\n",
      "Epoch 6: iteration 800, the loss is [ 0.15864487]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6235350084472049, auc for val: 0.6219624037981977\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 0, the loss is [ 0.15087166]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621977451623611, auc for val: 0.6202808206322917\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 100, the loss is [ 0.18596546]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6217985526186958, auc for val: 0.6193073642144592\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 200, the loss is [ 0.18571019]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6206452327224745, auc for val: 0.62010402982943\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 300, the loss is [ 0.12372497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215260521368173, auc for val: 0.6203949502300881\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 400, the loss is [ 0.16662772]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6206883848743732, auc for val: 0.6205830365891118\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 500, the loss is [ 0.15742768]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207307103492915, auc for val: 0.6202808507036559\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 600, the loss is [ 0.16978547]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6198680891909779, auc for val: 0.6209046874179929\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 700, the loss is [ 0.16737109]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6229169512676408, auc for val: 0.6209186568196181\n",
      "--------------------------------------------------------------\n",
      "Epoch 7: iteration 800, the loss is [ 0.13468221]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6212561655619467, auc for val: 0.6198373619839659\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 0, the loss is [ 0.18297037]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6226671101602512, auc for val: 0.6220664432003453\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 100, the loss is [ 0.16109967]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6229467353686999, auc for val: 0.6224133865524307\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 200, the loss is [ 0.18181916]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220711926192232, auc for val: 0.6198914678859282\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 300, the loss is [ 0.13325903]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6216578084472937, auc for val: 0.6202627941024521\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 400, the loss is [ 0.14072654]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6224533111643639, auc for val: 0.6213302160154393\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 500, the loss is [ 0.20239742]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6186883311678095, auc for val: 0.614694112479973\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 600, the loss is [ 0.1350055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6222229437685297, auc for val: 0.6198596298291253\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 700, the loss is [ 0.15174989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6209669777221158, auc for val: 0.6216350556987822\n",
      "--------------------------------------------------------------\n",
      "Epoch 8: iteration 800, the loss is [ 0.12721086]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6191070341307345, auc for val: 0.6170451518726181\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 0, the loss is [ 0.14481075]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6202376549225029, auc for val: 0.6197701361964159\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 100, the loss is [ 0.17340611]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6217324720261495, auc for val: 0.6193621141448038\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 200, the loss is [ 0.14728417]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6230731261243121, auc for val: 0.6242773725895345\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 300, the loss is [ 0.2190984]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6239539986407667, auc for val: 0.6250126149372645\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 400, the loss is [ 0.18095811]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6221855696210854, auc for val: 0.6208999311305619\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: iteration 500, the loss is [ 0.18618974]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.621734400243443, auc for val: 0.6232685359587959\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 600, the loss is [ 0.12240127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6222032906537696, auc for val: 0.6228586106404275\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 700, the loss is [ 0.17421815]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6225918138392016, auc for val: 0.6216529581842445\n",
      "--------------------------------------------------------------\n",
      "Epoch 9: iteration 800, the loss is [ 0.17898206]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620269806357445, auc for val: 0.6165844322612651\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 0, the loss is [ 0.14939897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6214568887618485, auc for val: 0.6196569713882196\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 100, the loss is [ 0.16519941]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6244708944422857, auc for val: 0.623954958699788\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 200, the loss is [ 0.14430007]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6240256679407197, auc for val: 0.6225328738649413\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 300, the loss is [ 0.17814462]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6239727718218434, auc for val: 0.622187553113547\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 400, the loss is [ 0.19532098]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6251697944468809, auc for val: 0.6231808704144326\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 500, the loss is [ 0.14392406]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6267488016636967, auc for val: 0.6233884593060868\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 600, the loss is [ 0.14891946]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268367268572818, auc for val: 0.6252880961983742\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 700, the loss is [ 0.15719683]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274505744384324, auc for val: 0.6259408916363958\n",
      "--------------------------------------------------------------\n",
      "Epoch 10: iteration 800, the loss is [ 0.18525536]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6269201756278685, auc for val: 0.6246966200307923\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 0, the loss is [ 0.17425127]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273673249360323, auc for val: 0.6242375430677065\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 100, the loss is [ 0.16585757]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6275327353861888, auc for val: 0.626064463642538\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 200, the loss is [ 0.13340156]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273317255740154, auc for val: 0.6253901483845403\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 300, the loss is [ 0.15958296]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.624656253431178, auc for val: 0.6226522145795516\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 400, the loss is [ 0.15012264]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.625644724584734, auc for val: 0.6211905959246244\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 500, the loss is [ 0.18605447]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6256343767068402, auc for val: 0.6231208304299432\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 600, the loss is [ 0.17810415]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276332742250661, auc for val: 0.6262756648568116\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 700, the loss is [ 0.14993122]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274626932369711, auc for val: 0.6276126903321888\n",
      "--------------------------------------------------------------\n",
      "Epoch 11: iteration 800, the loss is [ 0.15318024]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279490554015098, auc for val: 0.6277288484940922\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 0, the loss is [ 0.12958071]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6280470485854386, auc for val: 0.6272333789155071\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 100, the loss is [ 0.18513905]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6265157410555179, auc for val: 0.6245308528888416\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 200, the loss is [ 0.15131083]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6265919550305283, auc for val: 0.6260078317459863\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 300, the loss is [ 0.1695797]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276673781481359, auc for val: 0.6271982931513751\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 400, the loss is [ 0.17600356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6265147717680628, auc for val: 0.6260386586531694\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 500, the loss is [ 0.17015326]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6268841771884089, auc for val: 0.6255409149276698\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 600, the loss is [ 0.16956116]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6283517961169787, auc for val: 0.6270736135166532\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 700, the loss is [ 0.11073107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271382027731254, auc for val: 0.6251718666169808\n",
      "--------------------------------------------------------------\n",
      "Epoch 12: iteration 800, the loss is [ 0.13559106]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6254616315178314, auc for val: 0.6219839574484584\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 0, the loss is [ 0.1472989]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6264800105227827, auc for val: 0.6251089034453003\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 100, the loss is [ 0.10847322]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628664631710779, auc for val: 0.6265146419877797\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: iteration 200, the loss is [ 0.10966957]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6286261578781174, auc for val: 0.6265248725164612\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 300, the loss is [ 0.16303907]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6284042020268407, auc for val: 0.6260349736580864\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 400, the loss is [ 0.20343997]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6279501724009529, auc for val: 0.6252861177532072\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 500, the loss is [ 0.15546194]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6273641090504999, auc for val: 0.6254914550514699\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 600, the loss is [ 0.19077139]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6297998973527678, auc for val: 0.6282912105692746\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 700, the loss is [ 0.16506962]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6265444999070708, auc for val: 0.6253302299384809\n",
      "--------------------------------------------------------------\n",
      "Epoch 13: iteration 800, the loss is [ 0.16572951]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6272966203630912, auc for val: 0.6265734452874183\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 0, the loss is [ 0.15693057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6278777871886865, auc for val: 0.6285795373147739\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 100, the loss is [ 0.16959563]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6287351057880908, auc for val: 0.6266677390616315\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 200, the loss is [ 0.11326933]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.627535843444289, auc for val: 0.6256995238319771\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 300, the loss is [ 0.12757701]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6271941385434514, auc for val: 0.625126876097279\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 400, the loss is [ 0.15815417]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6277492522517337, auc for val: 0.6251169249816897\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 500, the loss is [ 0.17664532]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6274517452356482, auc for val: 0.6265472268167925\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 600, the loss is [ 0.1307783]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6276494379049873, auc for val: 0.6269608446480851\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 700, the loss is [ 0.16300464]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6287668947837284, auc for val: 0.6274492712625894\n",
      "--------------------------------------------------------------\n",
      "Epoch 14: iteration 800, the loss is [ 0.15949887]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6284790141679364, auc for val: 0.6281843707713397\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 0, the loss is [ 0.1444402]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.628950557519574, auc for val: 0.6281750110592453\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 100, the loss is [ 0.14497346]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6301513442881918, auc for val: 0.6293794543959945\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 200, the loss is [ 0.17184272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6304667079908279, auc for val: 0.6298787843859535\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 300, the loss is [ 0.1191778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6316850672298899, auc for val: 0.6302681283615024\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 400, the loss is [ 0.13079156]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6310039485485863, auc for val: 0.6295117032436698\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 500, the loss is [ 0.16470693]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6309330610941366, auc for val: 0.6289800102010086\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 600, the loss is [ 0.21564452]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6317847724351783, auc for val: 0.6300590221189317\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 700, the loss is [ 0.17883059]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6319856867872234, auc for val: 0.6298152887005326\n",
      "--------------------------------------------------------------\n",
      "Epoch 15: iteration 800, the loss is [ 0.16270418]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6317280246740454, auc for val: 0.6295006081632688\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 0, the loss is [ 0.21596231]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.631665899531814, auc for val: 0.6294202562252635\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 100, the loss is [ 0.16746548]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6313110916269217, auc for val: 0.6277201641347179\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 200, the loss is [ 0.18729964]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6314311598302228, auc for val: 0.6299549764519166\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 300, the loss is [ 0.20309468]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6315471761182375, auc for val: 0.6287903225418434\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 400, the loss is [ 0.13905399]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6309012332187868, auc for val: 0.629064109782772\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 500, the loss is [ 0.14481421]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6320367817628555, auc for val: 0.6300254186224581\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 600, the loss is [ 0.11382496]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6321733855154517, auc for val: 0.6302846463112399\n",
      "--------------------------------------------------------------\n",
      "Epoch 16: iteration 700, the loss is [ 0.15467609]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6323369661456777, auc for val: 0.6301354873331195\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: iteration 800, the loss is [ 0.14793645]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633322956495336, auc for val: 0.6305383170625201\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 0, the loss is [ 0.18664895]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338044419999986, auc for val: 0.63123749883273\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 100, the loss is [ 0.1403908]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329438447509937, auc for val: 0.6315879104154817\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 200, the loss is [ 0.19266276]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334244043310612, auc for val: 0.632207004625096\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 300, the loss is [ 0.11799107]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340634921111701, auc for val: 0.6321816018402231\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 400, the loss is [ 0.14689986]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634279736586843, auc for val: 0.6340508553779487\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 500, the loss is [ 0.16809049]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6332865211035649, auc for val: 0.6326531421307791\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 600, the loss is [ 0.16198103]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333269321971112, auc for val: 0.631058395040775\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 700, the loss is [ 0.16871238]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.63314042165762, auc for val: 0.6310423168847381\n",
      "--------------------------------------------------------------\n",
      "Epoch 17: iteration 800, the loss is [ 0.15023297]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330099589671478, auc for val: 0.6304986566921154\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 0, the loss is [ 0.17260578]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.633123613795749, auc for val: 0.6309405929776308\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 100, the loss is [ 0.13973489]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342943792429567, auc for val: 0.6328535640139754\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 200, the loss is [ 0.1309929]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337192179029149, auc for val: 0.6323065095161233\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 300, the loss is [ 0.1478316]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6341926831336027, auc for val: 0.6313932948115148\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 400, the loss is [ 0.17707388]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6334279905400545, auc for val: 0.6295251839856273\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 500, the loss is [ 0.15538068]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6340947684820546, auc for val: 0.6306444902785494\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 600, the loss is [ 0.14774758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6346408886095327, auc for val: 0.6333679021205965\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 700, the loss is [ 0.17012756]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338085961001351, auc for val: 0.6315092274381873\n",
      "--------------------------------------------------------------\n",
      "Epoch 18: iteration 800, the loss is [ 0.15465061]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6339065923758899, auc for val: 0.6322415278041236\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 0, the loss is [ 0.16157055]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342748902268622, auc for val: 0.6325399221917486\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 100, the loss is [ 0.17665628]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6338621925948991, auc for val: 0.6316289515626905\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 200, the loss is [ 0.15807292]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6329599100335519, auc for val: 0.6302589753900366\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 300, the loss is [ 0.13697538]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6337629940625988, auc for val: 0.6318289587116562\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 400, the loss is [ 0.15656453]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6330425247840714, auc for val: 0.6314628411059992\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 500, the loss is [ 0.13537598]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6342029023142386, auc for val: 0.63192528230295\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 600, the loss is [ 0.20677201]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6333279491759828, auc for val: 0.6299025194630891\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 700, the loss is [ 0.12030233]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.634210618352534, auc for val: 0.6301727670538615\n",
      "--------------------------------------------------------------\n",
      "Epoch 19: iteration 800, the loss is [ 0.1651644]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6348927049299712, auc for val: 0.6321114679011643\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 0, the loss is [ 0.17375821]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6348779964179633, auc for val: 0.6321944748900301\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 100, the loss is [ 0.14178386]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6351307037253634, auc for val: 0.6326944288607952\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 200, the loss is [ 0.17062566]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6352773913912074, auc for val: 0.6326435330769569\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 300, the loss is [ 0.17701283]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358055375746335, auc for val: 0.6331751133520025\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 400, the loss is [ 0.15735272]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6358108861244544, auc for val: 0.6335132833835946\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: iteration 500, the loss is [ 0.11417504]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6356969322389823, auc for val: 0.632181942649017\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 600, the loss is [ 0.1541997]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6359049206889468, auc for val: 0.6325396177191864\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 700, the loss is [ 0.14302066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6364378798406327, auc for val: 0.6333311436368332\n",
      "--------------------------------------------------------------\n",
      "Epoch 20: iteration 800, the loss is [ 0.17100513]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371756047547334, auc for val: 0.6339462621615112\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 0, the loss is [ 0.15543288]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371866738010449, auc for val: 0.6341470549248656\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 100, the loss is [ 0.1470177]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6369639378820648, auc for val: 0.6341268319324689\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 200, the loss is [ 0.10068167]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6372767192143187, auc for val: 0.6343390042012101\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 300, the loss is [ 0.16207622]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371400845434625, auc for val: 0.6334492188482018\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 400, the loss is [ 0.18099129]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6366735850421922, auc for val: 0.6324973223454975\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 500, the loss is [ 0.16085464]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636741808965827, auc for val: 0.6321921456122812\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 600, the loss is [ 0.14823759]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6367359954053735, auc for val: 0.6324137302180042\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 700, the loss is [ 0.15749943]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.636885907072793, auc for val: 0.6325898356443578\n",
      "--------------------------------------------------------------\n",
      "Epoch 21: iteration 800, the loss is [ 0.14547333]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6371385305144124, auc for val: 0.6333662268950182\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 0, the loss is [ 0.13946778]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6374257045706647, auc for val: 0.633840603917593\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 100, the loss is [ 0.12874752]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6375466192386327, auc for val: 0.634468209576238\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 200, the loss is [ 0.14298308]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381227567454428, auc for val: 0.634810425459283\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 300, the loss is [ 0.14731705]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382142676069515, auc for val: 0.6345984085592564\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 400, the loss is [ 0.16165785]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378143205881729, auc for val: 0.633727827531184\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 500, the loss is [ 0.12206133]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.637802772772603, auc for val: 0.6337646586874106\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 600, the loss is [ 0.09969817]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6380387052233748, auc for val: 0.6341468895323626\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 700, the loss is [ 0.17869726]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381522632778215, auc for val: 0.6335347593494978\n",
      "--------------------------------------------------------------\n",
      "Epoch 22: iteration 800, the loss is [ 0.13378146]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384654021797539, auc for val: 0.6333886876980976\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 0, the loss is [ 0.1364162]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386810505513716, auc for val: 0.6332135808916287\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 100, the loss is [ 0.1407121]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638259591689329, auc for val: 0.6328329739003413\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 200, the loss is [ 0.2007332]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382550889085142, auc for val: 0.6330506592525117\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 300, the loss is [ 0.1798961]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6381850031645496, auc for val: 0.6327736217983069\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 400, the loss is [ 0.20543617]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382532706829311, auc for val: 0.6333320933907512\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 500, the loss is [ 0.14071919]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6379295379483455, auc for val: 0.6341009868479481\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 600, the loss is [ 0.12980755]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6378115558000558, auc for val: 0.633418350592893\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 700, the loss is [ 0.12298289]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382376963823437, auc for val: 0.6345962346502225\n",
      "--------------------------------------------------------------\n",
      "Epoch 23: iteration 800, the loss is [ 0.16298008]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6385323482516971, auc for val: 0.6340084021295979\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 0, the loss is [ 0.13055559]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383203314616194, auc for val: 0.6335836365930171\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 100, the loss is [ 0.19285467]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383248706486856, auc for val: 0.6334657869168796\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: iteration 200, the loss is [ 0.18983367]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6384825311277564, auc for val: 0.6336212070036127\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 300, the loss is [ 0.15869172]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386124196661379, auc for val: 0.6345620861102734\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 400, the loss is [ 0.15251988]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387707632068707, auc for val: 0.6342216306550051\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 500, the loss is [ 0.09051211]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387815969652224, auc for val: 0.635341423101648\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 600, the loss is [ 0.1577366]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386762147808949, auc for val: 0.6343271222534469\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 700, the loss is [ 0.1657787]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6382518107226876, auc for val: 0.6335242268542014\n",
      "--------------------------------------------------------------\n",
      "Epoch 24: iteration 800, the loss is [ 0.13619232]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638157151686636, auc for val: 0.6322690105250176\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 0, the loss is [ 0.14367159]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6383446123442612, auc for val: 0.6318509909977963\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 100, the loss is [ 0.20057356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6386249305082152, auc for val: 0.6326370714925833\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 200, the loss is [ 0.16055696]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.638768095424795, auc for val: 0.6330033306842466\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 300, the loss is [ 0.11865283]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6387861512249408, auc for val: 0.6330428770340621\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 400, the loss is [ 0.16809909]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6389586176085386, auc for val: 0.6328652016319047\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 500, the loss is [ 0.13969897]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6390249766973132, auc for val: 0.6328378141369974\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 600, the loss is [ 0.21363565]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6392180713575959, auc for val: 0.6332140269501971\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 700, the loss is [ 0.18162854]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639429256214589, auc for val: 0.6332978446129216\n",
      "--------------------------------------------------------------\n",
      "Epoch 25: iteration 800, the loss is [ 0.16279492]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399281544968826, auc for val: 0.6332678333914914\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 0, the loss is [ 0.15987085]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6397069368190664, auc for val: 0.6333336896789985\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 100, the loss is [ 0.18337356]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401152125987607, auc for val: 0.6338885439369294\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 200, the loss is [ 0.10882671]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.639779136985546, auc for val: 0.6331822953961423\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 300, the loss is [ 0.16061546]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6399030288500781, auc for val: 0.6334652493912454\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 400, the loss is [ 0.15926392]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6401221026557363, auc for val: 0.633680922467964\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 500, the loss is [ 0.15192243]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6402968018014902, auc for val: 0.634101243707517\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 600, the loss is [ 0.14483364]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404923516035149, auc for val: 0.6345426750447092\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 700, the loss is [ 0.14935212]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404823442902564, auc for val: 0.6343071498557518\n",
      "--------------------------------------------------------------\n",
      "Epoch 26: iteration 800, the loss is [ 0.15815417]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.640278013470466, auc for val: 0.6344301918541004\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 0, the loss is [ 0.15294831]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6404588147986316, auc for val: 0.6346031936650782\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 100, the loss is [ 0.16721661]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6405925238291225, auc for val: 0.6344030737484969\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 200, the loss is [ 0.16133454]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6406840418791265, auc for val: 0.6347555564964551\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 300, the loss is [ 0.14307873]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6407950814093982, auc for val: 0.6350738656449941\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 400, the loss is [ 0.18237886]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412731413254293, auc for val: 0.6357415927682939\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 500, the loss is [ 0.16685233]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6412286292338586, auc for val: 0.6352484800328748\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 600, the loss is [ 0.14206228]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6411302317163827, auc for val: 0.6346461957158249\n",
      "--------------------------------------------------------------\n",
      "Epoch 27: iteration 700, the loss is [ 0.2285393]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6409059889186993, auc for val: 0.634331020254026\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: iteration 800, the loss is [ 0.18065917]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6413700085436197, auc for val: 0.63457358339517\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 0, the loss is [ 0.14267676]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414661095300281, auc for val: 0.6348792337523718\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 100, the loss is [ 0.19742237]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.641741431071257, auc for val: 0.6344443441898577\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 200, the loss is [ 0.11964439]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414857922490225, auc for val: 0.6339996250501841\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 300, the loss is [ 0.15068087]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419395587605163, auc for val: 0.6342475170876518\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 400, the loss is [ 0.14084987]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6416379423984759, auc for val: 0.633904025677577\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 500, the loss is [ 0.18473783]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6414509009151627, auc for val: 0.6336793762986569\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 600, the loss is [ 0.1608246]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6418648423887313, auc for val: 0.6344938779914943\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 700, the loss is [ 0.12971814]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6423778284216646, auc for val: 0.6351623481280836\n",
      "--------------------------------------------------------------\n",
      "Epoch 28: iteration 800, the loss is [ 0.16569003]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.642133430705859, auc for val: 0.6350934220554851\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 0, the loss is [ 0.17247318]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6418418364978419, auc for val: 0.6349555423448712\n",
      "--------------------------------------------------------------\n",
      "Epoch 29: iteration 100, the loss is [ 0.15723148]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6419035501953265, auc for val: 0.6348006597837725\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-699:\n",
      "Process Process-700:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOWINGUP: Learning rate is 0.0008203039459907334. Weight decay is 0.014601620731181977. dropout is 0.75\n",
      " Val aus is 0.6348006597837725. Train auc is 0.6419035501953265\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n",
      "Epoch 0: iteration 0, the loss is [ 0.70214808]\n",
      "  acc for train: 0.9497727230301107, acc for val: 0.9501857417536261\n",
      "  auc for train: 0.4481523133731325, auc for val: 0.45401067372044646\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.20098335]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.554762399938085, auc for val: 0.5592452685013967\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.12990937]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5086171768037494, auc for val: 0.5201410880244561\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.14846796]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5185851035224394, auc for val: 0.530338843930863\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.11860301]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.4717002796631605, auc for val: 0.4781886669668992\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 500, the loss is [ 0.15593512]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.47824815807035315, auc for val: 0.48455244548151893\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 600, the loss is [ 0.15783444]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.46985771970894974, auc for val: 0.4747428494906973\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 700, the loss is [ 0.19712405]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5352822259249537, auc for val: 0.5372865118584821\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 800, the loss is [ 0.1884525]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5563760029101935, auc for val: 0.5552530793979039\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.1404614]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5565619631046543, auc for val: 0.5585592905659996\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.13830028]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5744334935118985, auc for val: 0.5762808742194627\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.1274166]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6027833455659755, auc for val: 0.6023434273279977\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.11216298]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.5981265138242008, auc for val: 0.5965572533112682\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.15578066]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6118313296769022, auc for val: 0.6055878631432972\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 500, the loss is [ 0.12624413]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6175882152590395, auc for val: 0.6119553153762384\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 600, the loss is [ 0.17052594]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6207106706016883, auc for val: 0.616625750315619\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 700, the loss is [ 0.11061503]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6202351600507968, auc for val: 0.61795176465982\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 800, the loss is [ 0.17769758]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215474673605184, auc for val: 0.6187447177142908\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.16711769]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6221983405630261, auc for val: 0.6189317503225956\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.11649434]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.623318196698754, auc for val: 0.6188439043500473\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.14223047]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6232898513789303, auc for val: 0.621944171780703\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 300, the loss is [ 0.17834798]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6209730414885895, auc for val: 0.6169443789724021\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 400, the loss is [ 0.18226206]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215989182826203, auc for val: 0.6179444372707534\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 500, the loss is [ 0.20393518]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.622915941013491, auc for val: 0.6204394596079632\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 600, the loss is [ 0.1703914]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6228785675617075, auc for val: 0.6209982381789166\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 700, the loss is [ 0.21127497]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6211598978488202, auc for val: 0.617852168301727\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 800, the loss is [ 0.18254012]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6215012000393196, auc for val: 0.6182789811970175\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 0, the loss is [ 0.17447057]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.617746671187648, auc for val: 0.6152959845687391\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 100, the loss is [ 0.14456114]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.620067133374763, auc for val: 0.6183910433885279\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 200, the loss is [ 0.20038582]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220988113599337, auc for val: 0.6201687797413309\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 300, the loss is [ 0.12100007]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220923833763556, auc for val: 0.619934952331475\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 400, the loss is [ 0.15960336]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6200709799155067, auc for val: 0.6168446736056139\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: iteration 500, the loss is [ 0.14824243]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6203678689528678, auc for val: 0.6200699138667922\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 600, the loss is [ 0.15624656]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.623816690956683, auc for val: 0.6214784340104562\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 700, the loss is [ 0.11900377]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6221969303038857, auc for val: 0.6223634254868283\n",
      "--------------------------------------------------------------\n",
      "Epoch 3: iteration 800, the loss is [ 0.15985848]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6220193498081741, auc for val: 0.6226212874344881\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 0, the loss is [ 0.12043726]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6205569320266202, auc for val: 0.6185013752236257\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 100, the loss is [ 0.18219917]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6204520906026624, auc for val: 0.6178909703852795\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 200, the loss is [ 0.0998236]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6190727965634855, auc for val: 0.6152273341503122\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 300, the loss is [ 0.13956936]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6223744152621733, auc for val: 0.6207583651718913\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 400, the loss is [ 0.19911423]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6204050005465614, auc for val: 0.6173388927166394\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 500, the loss is [ 0.16151585]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.622977426920694, auc for val: 0.619406034625131\n",
      "--------------------------------------------------------------\n",
      "Epoch 4: iteration 600, the loss is [ 0.1413773]\n",
      "  acc for train: 0.9634420093710915, acc for val: 0.9639343650245478\n",
      "  auc for train: 0.6193659348294138, auc for val: 0.6140246863245981\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 0, the loss is [ 1.09527755]\n",
      "  acc for train: 0.483187571169893, acc for val: 0.4821538576415464\n",
      "  auc for train: 0.541518823385761, auc for val: 0.5336574720664091\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.52482617]\n",
      "  acc for train: 0.9629706546696783, acc for val: 0.9635236797401482\n",
      "  auc for train: 0.5423363283097007, auc for val: 0.5408918516566776\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-714:\n",
      "Process Process-713:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOWINGUP: Learning rate is 0.0001601895128921694. Weight decay is 0.010418313081810416. dropout is 0.75\n",
      " Val aus is 0.5408918516566776. Train auc is 0.5423363283097007\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n",
      "Epoch 0: iteration 0, the loss is [ 0.69948697]\n",
      "  acc for train: 0.9596688383206705, acc for val: 0.9602101961955609\n",
      "  auc for train: 0.4712898290930484, auc for val: 0.47588385728475385\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-715:\n",
      "Process Process-716:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOWINGUP: Learning rate is 0.00010962299938523821. Weight decay is 0.0500428090665439. dropout is 0.75\n",
      " Val aus is 0.47588385728475385. Train auc is 0.4712898290930484\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-718:\n",
      "Process Process-717:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOWINGUP: Learning rate is 0.00018357314377707924. Weight decay is 0.038231894107606613. dropout is 0.75\n",
      " Val aus is 0. Train auc is 0\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n"
     ]
    }
   ],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "input_size = 238\n",
    "hidden_size= [220,200,200]\n",
    "lr_decay = {'step_size': 5, 'gamma':0.5}\n",
    "\n",
    "train_hist={}\n",
    "\n",
    "for i in range(10):\n",
    "    tic = datetime.now()\n",
    "#     dropout = np.random.uniform(0.5,1)\n",
    "#     weight_decay = 10** (np.random.uniform(-1,1))#L2 \n",
    "#     learning_rate = 10** (np.random.uniform(-4,-2))\n",
    "    \n",
    "    \n",
    "    dropout = 0.75\n",
    "    #During this training, I will set 1e-3 as upper bound for learning_rate, 0.1 for upper bound of weight_decay\n",
    "    weight_decay = 10** (np.random.uniform(-3,-1))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-4,-2))\n",
    "    \n",
    "    nn_model = NeuralNetwork(input_size = input_size, hidden_size=hidden_size,\n",
    "                             learning_rate = learning_rate,num_epochs=80,batch_size =512,\n",
    "                             verbose=True,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay)\n",
    "    try:\n",
    "        nn_model.train(data)\n",
    "        describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                    .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "        train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "        print(describe)\n",
    "        if nn_model.auc_history['val'][-1]> best_auc:\n",
    "            best_auc =nn_model.auc_history['val'][-1]\n",
    "            best_net = nn_model\n",
    "        toc = datetime.now()\n",
    "        print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "        print('You have finished {}!!'.format(i+1))\n",
    "    except:\n",
    "        describe= 'BLOWINGUP: Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                    .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "        train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "        print(describe)\n",
    "        print(\"WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\")\n",
    "        0.0005358686327667781 0.04687949688795907\n",
    "        0.00029890640322661804 0.03493291532559407\n",
    "        0.0008203039459907334 0.014601620731181977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAALJCAYAAADvZCFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12eff37550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_vis.nnplot(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_vis.nnplot(best_net)\n",
    "train_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a specific one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We train for ensemble this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "input_size = 237\n",
    "hidden_size= [230,220,210]\n",
    "lr_decay = {'step_size': 25, 'gamma':0.1}\n",
    "for i in range(5):\n",
    "    #learnning_rate 5e-4 too large\n",
    "    train_hist={}\n",
    "    tic = datetime.now()\n",
    "    weight_decay = 10** (np.random.uniform(-3,-1))#L2 \n",
    "    learning_rate = 10** (np.random.uniform(-4,np.log10(5e-4)))\n",
    "    dropout = np.random.uniform(0,1)\n",
    "    nn_model = NeuralNetwork(data,input_size = input_size, hidden_size=hidden_size,learning_rate = learning_rate,num_epochs=70,verbose=None,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n",
    "    nn_model.train()\n",
    "    describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "\n",
    "    print(describe)\n",
    "    train_hist['describe']= describe\n",
    "    train_hist['net'] = nn_model\n",
    "    toc = datetime.now()\n",
    "    print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "    print('You have finished {}!!'.format(i+1))\n",
    "\n",
    "    filename= 'search_lr_wd_ensemble{}.pkl'.format(i)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm search_lr_wd_ensemble0.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_util\n",
    "import data_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "\n",
    "rso = np.random.RandomState(66)\n",
    "\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "lv1_pre = data_preprocess.preprocess_cell()\n",
    "\n",
    "X_train = train_data.drop(['id','target'],axis=1)\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop(['id'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train, col = lv1_pre.process(X_train, y=y_train, rso =rso, oversample= None)\n",
    "X_test = lv1_pre.process(X_test,test=True,rso =rso)\n",
    "X_dev, y_dev = X_train.iloc[:100000,:], y_train.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={}\n",
    "#enter df here\n",
    "data['X_train'] = X_train.values\n",
    "data['X_val'] = X_dev.values\n",
    "data['y_train'] = y_train.values\n",
    "data['y_val'] =y_dev.values\n",
    "#X_train = None\n",
    "#X_val = None\n",
    "#print(type(X_train),type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: iteration 0, the loss is [ 0.9746893]\n",
      "  acc for train: 0.963552482140817, acc for val: 0.96329\n",
      "  auc for train: 0.4721207474209999, auc for val: 0.4736403189470083\n",
      "--------------------------------------------------------------\n",
      "BLOWINGUP: Learning rate is 0.04687949688795907. Weight decay is 0.0005358686327667781. dropout is 0.75\n",
      " Val aus is 0.4736403189470083. Train auc is 0.4721207474209999\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n",
      "Epoch 0: iteration 0, the loss is [ 1.30615878]\n",
      "  acc for train: 0.963552482140817, acc for val: 0.96329\n",
      "  auc for train: 0.4721815523648501, auc for val: 0.4648010585171117\n",
      "--------------------------------------------------------------\n",
      "BLOWINGUP: Learning rate is 0.03493291532559407. Weight decay is 0.00029890640322661804. dropout is 0.75\n",
      " Val aus is 0.4648010585171117. Train auc is 0.4721815523648501\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n",
      "Epoch 0: iteration 0, the loss is [ 0.99644208]\n",
      "  acc for train: 0.963552482140817, acc for val: 0.96329\n",
      "  auc for train: 0.5105895328189008, auc for val: 0.5121401359233897\n",
      "--------------------------------------------------------------\n",
      "BLOWINGUP: Learning rate is 0.014601620731181977. Weight decay is 0.0008203039459907334. dropout is 0.75\n",
      " Val aus is 0.5121401359233897. Train auc is 0.5105895328189008\n",
      "WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\n"
     ]
    }
   ],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "best_net = None\n",
    "best_auc =0\n",
    "\n",
    "#10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "input_size = 238\n",
    "hidden_size= [220,200,200]\n",
    "lr_decay = {'step_size': 6, 'gamma':0.5}\n",
    "\n",
    "train_hist={}\n",
    "X_test_tensor = torch.from_numpy(X_test.values)\n",
    "sub = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for i, (weight_decay, learning_rate)  in enumerate(learn_list):\n",
    "    tic = datetime.now()\n",
    "#     dropout = np.random.uniform(0.5,1)\n",
    "#     weight_decay = 10** (np.random.uniform(-1,1))#L2 \n",
    "#     learning_rate = 10** (np.random.uniform(-4,-2))\n",
    "    \n",
    "    \n",
    "    dropout = 0.75\n",
    "    #During this training, I will set 1e-3 as upper bound for learning_rate, 0.1 for upper bound of weight_decay\n",
    "    \n",
    "    nn_model = NeuralNetwork(input_size = input_size, hidden_size=hidden_size,\n",
    "                             learning_rate = learning_rate,num_epochs=100,batch_size =512,\n",
    "                             verbose=True,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay)\n",
    "    try:\n",
    "        nn_model.train(data)\n",
    "        describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                    .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "        train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "        print(describe)\n",
    "        out = nn_model.test(X_test_tensor).data.numpy()[:,1]\n",
    "        sub['NN'+str(i)] = out\n",
    "        toc = datetime.now()\n",
    "        print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "        print('You have finished {}!!'.format(i+1))\n",
    "    except:\n",
    "        describe= 'BLOWINGUP: Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                    .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "        train_hist[(nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])]= describe\n",
    "        print(describe)\n",
    "        print(\"WARNING: YOUR TRAINING IS BLOWING UP THIS TIME!\")\n",
    "\n",
    "sub.to_csv('final_NN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import data_util \n",
    "\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "train_df = data_util.load_train_data()\n",
    "test_df = data_util.load_test_data()\n",
    "\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "\n",
    "\n",
    "def target_encode(trn_series=None,    # Revised to encode validation series\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "\n",
    "\n",
    "# Process data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "\n",
    "\n",
    "#########################\n",
    "# train_df['na_sum'] = (train_df == -1).sum(axis=1)\n",
    "# train_df['na_ca_t_sum'] = (train_df[f_cats] == -1).sum(axis=1)\n",
    "# test_df['na_sum'] = (test_df == -1).sum(axis=1)\n",
    "# test_df['na_ca_t_sum'] = (test_df[f_cats] == -1).sum(axis=1)\n",
    "\n",
    "# train_features += ['na_ca_t_sum', 'na_sum']\n",
    "\n",
    "train_df['ps_car_13_+_ps_reg_03'] = train_df['ps_car_13'] + train_df['ps_reg_03']\n",
    "train_df['ps_car_13_-_ps_reg_03'] = train_df['ps_car_13'] - train_df['ps_reg_03']\n",
    "train_df['ps_car_13_x_ps_reg_03'] = train_df['ps_car_13'] * train_df['ps_reg_03']\n",
    "train_df['ps_car_13_/_ps_reg_03'] = train_df['ps_car_13'] / train_df['ps_reg_03']\n",
    "\n",
    "test_df['ps_car_13_+_ps_reg_03'] = test_df['ps_car_13'] + test_df['ps_reg_03']\n",
    "test_df['ps_car_13_-_ps_reg_03'] = test_df['ps_car_13'] - test_df['ps_reg_03']\n",
    "test_df['ps_car_13_x_ps_reg_03'] = test_df['ps_car_13'] * test_df['ps_reg_03']\n",
    "test_df['ps_car_13_/_ps_reg_03'] = test_df['ps_car_13'] / test_df['ps_reg_03']\n",
    "\n",
    "\n",
    "train_features+= ['ps_car_13_x_ps_reg_03', 'ps_car_13_/_ps_reg_03','ps_car_13_+_ps_reg_03','ps_car_13_-_ps_reg_03']\n",
    "\n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_reg_01_plus_ps_car_02_cat</th>\n",
       "      <th>ps_reg_01_plus_ps_car_04_cat</th>\n",
       "      <th>ps_car_13_x_ps_reg_03</th>\n",
       "      <th>ps_car_13_/_ps_reg_03</th>\n",
       "      <th>ps_car_13_+_ps_reg_03</th>\n",
       "      <th>ps_car_13_-_ps_reg_03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.00000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.813265</td>\n",
       "      <td>0.551102</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>7.299922</td>\n",
       "      <td>0.439184</td>\n",
       "      <td>0.276256</td>\n",
       "      <td>0.379945</td>\n",
       "      <td>8.295933</td>\n",
       "      <td>0.910027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>16.703544</td>\n",
       "      <td>61.82433</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.685398</td>\n",
       "      <td>1.364367</td>\n",
       "      <td>0.262163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.224588</td>\n",
       "      <td>0.793506</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>3.546042</td>\n",
       "      <td>0.404264</td>\n",
       "      <td>0.357154</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>2.508270</td>\n",
       "      <td>0.347106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.127545</td>\n",
       "      <td>7.100134</td>\n",
       "      <td>28.83025</td>\n",
       "      <td>0.721817</td>\n",
       "      <td>0.801999</td>\n",
       "      <td>0.845887</td>\n",
       "      <td>0.802906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250619</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-3.092035</td>\n",
       "      <td>-3.092035</td>\n",
       "      <td>-0.691277</td>\n",
       "      <td>-3.453098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.670867</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>0.353514</td>\n",
       "      <td>0.544906</td>\n",
       "      <td>1.204588</td>\n",
       "      <td>-0.212443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.765811</td>\n",
       "      <td>0.720677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>0.542125</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>1.491923</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.906190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.396485</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>0.825184</td>\n",
       "      <td>1.156926</td>\n",
       "      <td>1.857717</td>\n",
       "      <td>0.341294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.720626</td>\n",
       "      <td>4.037945</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>8.840192</td>\n",
       "      <td>15.059844</td>\n",
       "      <td>5.998826</td>\n",
       "      <td>4.092035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_car_13      ps_reg_03  ps_ind_05_cat      ps_ind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.813265       0.551102       0.405188       4.423318   \n",
       "std         0.224588       0.793506       1.350642       2.699902   \n",
       "min         0.250619      -1.000000      -1.000000       0.000000   \n",
       "25%         0.670867       0.525000       0.000000       2.000000   \n",
       "50%         0.765811       0.720677       0.000000       4.000000   \n",
       "75%         0.906190       1.000000       0.000000       6.000000   \n",
       "max         3.720626       4.037945       6.000000      11.000000   \n",
       "\n",
       "           ps_ind_15      ps_reg_02      ps_car_14      ps_car_12  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        7.299922       0.439184       0.276256       0.379945   \n",
       "std         3.546042       0.404264       0.357154       0.058327   \n",
       "min         0.000000       0.000000      -1.000000      -1.000000   \n",
       "25%         5.000000       0.200000       0.333167       0.316228   \n",
       "50%         7.000000       0.300000       0.368782       0.374166   \n",
       "75%        10.000000       0.600000       0.396485       0.400000   \n",
       "max        13.000000       1.800000       0.636396       1.264911   \n",
       "\n",
       "       ps_car_01_cat  ps_car_07_cat          ...            ps_ind_04_cat  \\\n",
       "count  595212.000000  595212.000000          ...            595212.000000   \n",
       "mean        8.295933       0.910027          ...                 0.416794   \n",
       "std         2.508270       0.347106          ...                 0.493311   \n",
       "min        -1.000000      -1.000000          ...                -1.000000   \n",
       "25%         7.000000       1.000000          ...                 0.000000   \n",
       "50%         7.000000       1.000000          ...                 0.000000   \n",
       "75%        11.000000       1.000000          ...                 1.000000   \n",
       "max        11.000000       1.000000          ...                 1.000000   \n",
       "\n",
       "       ps_ind_18_bin  ps_ind_12_bin      ps_ind_14  \\\n",
       "count  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.153446       0.009439       0.012451   \n",
       "std         0.360417       0.096693       0.127545   \n",
       "min         0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       4.000000   \n",
       "\n",
       "       ps_reg_01_plus_ps_car_02_cat  ps_reg_01_plus_ps_car_04_cat  \\\n",
       "count                 595212.000000                  595212.00000   \n",
       "mean                      16.703544                      61.82433   \n",
       "std                        7.100134                      28.83025   \n",
       "min                        0.000000                       0.00000   \n",
       "25%                       12.000000                      40.00000   \n",
       "50%                       19.000000                      70.00000   \n",
       "75%                       24.000000                      90.00000   \n",
       "max                       24.000000                      99.00000   \n",
       "\n",
       "       ps_car_13_x_ps_reg_03  ps_car_13_/_ps_reg_03  ps_car_13_+_ps_reg_03  \\\n",
       "count          595212.000000          595212.000000          595212.000000   \n",
       "mean                0.465909               0.685398               1.364367   \n",
       "std                 0.721817               0.801999               0.845887   \n",
       "min                -3.092035              -3.092035              -0.691277   \n",
       "25%                 0.353514               0.544906               1.204588   \n",
       "50%                 0.542125               0.852464               1.491923   \n",
       "75%                 0.825184               1.156926               1.857717   \n",
       "max                 8.840192              15.059844               5.998826   \n",
       "\n",
       "       ps_car_13_-_ps_reg_03  \n",
       "count          595212.000000  \n",
       "mean                0.262163  \n",
       "std                 0.802906  \n",
       "min                -3.453098  \n",
       "25%                -0.212443  \n",
       "50%                 0.045800  \n",
       "75%                 0.341294  \n",
       "max                 4.092035  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "sddsd\n",
      "{'dropout': None, 'lr_decay': {'gamma': 0.1, 'step_size': 30}, 'verbose': True, 'input_size': 54, 'learning_rate': 0.01, 'weight_decay': 0.08, 'batchnorm': True, 'hidden_size': [230, 220, 210], 'num_epochs': 70}\n",
      "Epoch 0: iteration 0, the loss is [ 0.78651083]\n",
      "  acc for train: 0.9635087542448164, acc for val: 0.9635593861041808\n",
      "  auc for train: 0.5867404153739948, auc for val: 0.5914332609299277\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 100, the loss is [ 0.17065661]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.488435814111397, auc for val: 0.4747470689892394\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 200, the loss is [ 0.1929232]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5972034540029725, auc for val: 0.5975308034834141\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 300, the loss is [ 0.19917277]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.6047201658631218, auc for val: 0.6068857118003418\n",
      "--------------------------------------------------------------\n",
      "Epoch 0: iteration 400, the loss is [ 0.18159238]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5884345213809592, auc for val: 0.5827378080839644\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 0, the loss is [ 0.19357218]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.45298985003277314, auc for val: 0.451689124644101\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 100, the loss is [ 0.18441767]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5780901359835157, auc for val: 0.5812611315011385\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 200, the loss is [ 0.17548452]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.6062842588945956, auc for val: 0.6080724088071128\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 300, the loss is [ 0.18069255]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.6004544780202453, auc for val: 0.602537249179273\n",
      "--------------------------------------------------------------\n",
      "Epoch 1: iteration 400, the loss is [ 0.16321924]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5559515500175052, auc for val: 0.5535197292619063\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 0, the loss is [ 0.18739708]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5973482212305387, auc for val: 0.5932567451444306\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 100, the loss is [ 0.18425043]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.48476288871769607, auc for val: 0.4880602931589862\n",
      "--------------------------------------------------------------\n",
      "Epoch 2: iteration 200, the loss is [ 0.16878688]\n",
      "  acc for train: 0.9635423557602448, acc for val: 0.9635929874079114\n",
      "  auc for train: 0.5414385561060905, auc for val: 0.5367682055742481\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0dda984c87ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                              \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                              weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdescribe\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}'\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competition_husky/safe_driver_prediction/MY_NN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clear gradients for next train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competition_husky/safe_driver_prediction/MY_NN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# return out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from MY_NN import NeuralNetwork\n",
    "from datetime import datetime\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = 1, shuffle = True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y_test_pred_all = np.zeros((len(test_df),5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    \n",
    "    for f in f_cats:\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_valid[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train= scaler.transform(X_train)\n",
    "    X_valid = scaler.transform(X_valid)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Run model for this fold\n",
    "    best_net = None\n",
    "    best_auc =0\n",
    "\n",
    "    #10.22. for 4 layers, best one has lr 3.305e-4, wd is 9.904e-3 0.6374\n",
    "    input_size = 54\n",
    "    hidden_size= [230,220,210]\n",
    "    lr_decay = {'step_size': 30, 'gamma':0.1}\n",
    "    #learnning_rate 5e-4 too large\n",
    "    train_hist={}\n",
    "    tic = datetime.now()\n",
    "    weight_decay = 0.08\n",
    "    learning_rate = 0.01\n",
    "    dropout = None\n",
    "    data ={}\n",
    "    data['X_train'] = X_train\n",
    "    data['X_val'] = X_valid\n",
    "    data['y_train'] = y_train.values\n",
    "    data['y_val'] =y_valid.values\n",
    "    nn_model = NeuralNetwork(input_size = input_size, hidden_size=hidden_size,\n",
    "                             learning_rate = learning_rate,num_epochs=70,verbose=True,dropout=dropout,\n",
    "                             weight_decay=weight_decay,lr_decay=lr_decay ,batchnorm=True)\n",
    "    nn_model.train(data)\n",
    "    describe= 'Learning rate is {}. Weight decay is {}. dropout is {}\\n Val aus is {}. Train auc is {}' \\\n",
    "                .format(learning_rate, weight_decay, dropout,nn_model.auc_history['val'][-1],nn_model.auc_history['train'][-1])\n",
    "\n",
    "    print(describe)\n",
    "    train_hist['describe']= describe\n",
    "    train_hist['net'] = nn_model\n",
    "    toc = datetime.now()\n",
    "    print('This is round you consume {} time to run this model.'.format(toc-tic))\n",
    "    print('You have finished {}!!'.format(i+1))\n",
    "\n",
    "    filename= 'search_lr_wd_ensemble{}.pkl'.format(i)\n",
    "        \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred_all[:,i] = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476169, 54)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
