{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Aug 18 2017, 17:48:00) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/FDSM_lhn/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/FDSM_lhn/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting scipy\n",
      "  Downloading scipy-0.19.1-cp35-cp35m-manylinux1_x86_64.whl (47.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 47.9MB 33kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /home/FDSM_lhn/.local/lib/python3.5/site-packages (from scipy)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-0.19.1\n"
     ]
    }
   ],
   "source": [
    "#! pip3 install pandas\n",
    "! sudo pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('datasets/train.csv')\n",
    "\n",
    "# # train.head\n",
    "# train.iloc[:10,:10]\n",
    "# N, _ = train.shape\n",
    "\n",
    "# for i in range(3):\n",
    "#     file = \"datasets/train_batch_{}\".format(i)\n",
    "#     with open(file,'wb') as f:\n",
    "#         pickle.dump(train.iloc[int(2e5)*i:min(N+1,int(2e5) * (i+1)),:] ,file = f)\n",
    "    \n",
    "# test = pd.read_csv('datasets/test.csv')\n",
    "# test.shape\n",
    "\n",
    "# N, _ = test.shape\n",
    "\n",
    "# for i in range(5):\n",
    "#     file = \"datasets/test_batch_{}\".format(i)\n",
    "#     with open(file,'wb') as f:\n",
    "#         pickle.dump(test.iloc[int(2e5)*i:min(N+1,int(2e5) * (i+1)),:] ,file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import data_util\n",
    "import data_preprocess\n",
    "import datetime\n",
    "\n",
    "tic= datetime.datetime.now()\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "naive_pre = data_preprocess.naive_preprocess()\n",
    "train_data = naive_pre.dtype_change(train_data)\n",
    "test_data = naive_pre.dtype_change(test_data)\n",
    "#train_prop is specified\n",
    "X_train, X_val, y_train, y_val = data_util.split_train(train_data,prop=0.75)\n",
    "\n",
    "X_train = naive_pre.scale(X_train)\n",
    "X_val = naive_pre.scale(X_val,test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446409, 235) (148803, 235)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape ,X_val.shape)\n",
    "# dev_train.dtypes\n",
    "# dev_train.head\n",
    "# train_data.isnull().any()\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=<mtrand.RandomState object at 0x7fb955bcc480>,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "tic= datetime.datetime.now()\n",
    "hidden_layer_size = [(300,200,100)]\n",
    "learning_rate = [0.001]\n",
    "reg = []\n",
    "momentum =[0.9]\n",
    "rso= np.random.RandomState(66)\n",
    "\n",
    "#for now I don't mess up with inits\n",
    "mlp = MLPClassifier(hidden_layer_sizes= hidden_layer_size[0],random_state=rso,alpha= 0.001)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val score it have: 0.5953008753764144 \n",
      "The time it cost: -1 day, 23:57:44.336906\n",
      "The test score it have: 0.7112570696063083 \n",
      "The time it cost: 0:29:13.188801\n"
     ]
    }
   ],
   "source": [
    "#check the performance\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "test_predictions = mlp.predict_proba(X_val)\n",
    "auc_score = roc_auc_score(y_val,test_predictions[:,1])\n",
    "\n",
    "print('The val score it have: {} '.format(auc_score))\n",
    "print(\"The time it cost: {}\".format(toc-tic))\n",
    "\n",
    "test_predictions = mlp.predict_proba(X_train)\n",
    "auc_score = roc_auc_score(y_train,test_predictions[:,1])\n",
    "toc = datetime.datetime.now()\n",
    "print('The test score it have: {} '.format(auc_score))\n",
    "print(\"The time it cost: {}\".format(toc-tic))\n",
    "\n",
    "#classification_report(y_train,test_predictions[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62780916443936541"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val,test_predictions[:,1])\n",
    "# sum(test_predictions)\n",
    "# sum(dev_y)\n",
    "# test_predictions\n",
    "# sum(test_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_size[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Package for NN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#! sudo pip3 install scikit-neuralnetwork\n",
    "!sudo pip3 install scikit-neuralnetwork --upgrade\n",
    "!sudo pip3 install Theano --upgrade"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "#train_prop is specified\n",
    "X_train, X_val, y_train, y_val = data_util.split_train(train_data,prop=0.75)\n",
    "train_mean = X_train.mean()\n",
    "X_train.fillna(train_mean)\n",
    "X_val.fillna(train_mean)\n",
    "\n",
    "weight = np.zeros_like(y_train)\n",
    "weight[y_train==1]=100\n",
    "weight[y_train==0]=1\n",
    "\n",
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn= Classifier(\n",
    "    layers= [\n",
    "        Layer('Rectifier', units= 100),\n",
    "        Layer('Rectifier', units= 80),\n",
    "        Layer('Rectifier', units= 50),\n",
    "        Layer('Softmax')],\n",
    "    learning_rate=0.000000,\n",
    "    batch_size = 2000,\n",
    "    n_iter= 20,\n",
    "    regularize= 'L2'\n",
    ")\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(-1, 1.0))),\n",
    "        ('neural network', nn)])\n",
    "pipeline.fit(X_train, y_train,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: iteration 0, the loss is Variable containing:\n",
      " 0.6053\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 10, the loss is Variable containing:\n",
      " 0.1907\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 20, the loss is Variable containing:\n",
      " 0.1484\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 30, the loss is Variable containing:\n",
      " 0.1588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 40, the loss is Variable containing:\n",
      " 0.1638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 50, the loss is Variable containing:\n",
      " 0.1498\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 60, the loss is Variable containing:\n",
      " 0.1580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 70, the loss is Variable containing:\n",
      " 0.1453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 80, the loss is Variable containing:\n",
      " 0.1545\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 90, the loss is Variable containing:\n",
      " 0.1562\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 100, the loss is Variable containing:\n",
      " 0.1574\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 110, the loss is Variable containing:\n",
      " 0.1569\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 0, the loss is Variable containing:\n",
      " 0.1359\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 10, the loss is Variable containing:\n",
      " 0.1597\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 20, the loss is Variable containing:\n",
      " 0.1508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 30, the loss is Variable containing:\n",
      " 0.1439\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 40, the loss is Variable containing:\n",
      " 0.1625\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 50, the loss is Variable containing:\n",
      " 0.1484\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 60, the loss is Variable containing:\n",
      " 0.1575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 70, the loss is Variable containing:\n",
      " 0.1545\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 80, the loss is Variable containing:\n",
      " 0.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 90, the loss is Variable containing:\n",
      " 0.1621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 100, the loss is Variable containing:\n",
      " 0.1559\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 110, the loss is Variable containing:\n",
      " 0.1571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 0, the loss is Variable containing:\n",
      " 0.1548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 10, the loss is Variable containing:\n",
      " 0.1526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 20, the loss is Variable containing:\n",
      " 0.1391\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 30, the loss is Variable containing:\n",
      " 0.1443\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 40, the loss is Variable containing:\n",
      " 0.1628\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 50, the loss is Variable containing:\n",
      " 0.1643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 60, the loss is Variable containing:\n",
      " 0.1543\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 70, the loss is Variable containing:\n",
      " 0.1630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 80, the loss is Variable containing:\n",
      " 0.1522\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 90, the loss is Variable containing:\n",
      " 0.1439\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 100, the loss is Variable containing:\n",
      " 0.1468\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 110, the loss is Variable containing:\n",
      " 0.1579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 0, the loss is Variable containing:\n",
      " 0.1546\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 10, the loss is Variable containing:\n",
      " 0.1486\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 20, the loss is Variable containing:\n",
      " 0.1649\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 30, the loss is Variable containing:\n",
      " 0.1423\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 40, the loss is Variable containing:\n",
      " 0.1538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 50, the loss is Variable containing:\n",
      " 0.1558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 60, the loss is Variable containing:\n",
      " 0.1451\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 70, the loss is Variable containing:\n",
      " 0.1606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 80, the loss is Variable containing:\n",
      " 0.1493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 90, the loss is Variable containing:\n",
      " 0.1497\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 100, the loss is Variable containing:\n",
      " 0.1606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 110, the loss is Variable containing:\n",
      " 0.1620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 0, the loss is Variable containing:\n",
      " 0.1494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 10, the loss is Variable containing:\n",
      " 0.1524\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 20, the loss is Variable containing:\n",
      " 0.1614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 30, the loss is Variable containing:\n",
      " 0.1477\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 40, the loss is Variable containing:\n",
      " 0.1715\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 50, the loss is Variable containing:\n",
      " 0.1769\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 60, the loss is Variable containing:\n",
      " 0.1451\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 70, the loss is Variable containing:\n",
      " 0.1538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 80, the loss is Variable containing:\n",
      " 0.1722\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 90, the loss is Variable containing:\n",
      " 0.1431\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 100, the loss is Variable containing:\n",
      " 0.1411\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 110, the loss is Variable containing:\n",
      " 0.1491\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 235\n",
    "hidden_size = [300,250,200]\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "batch_size = 5000\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# X_dev_tensor = torch.from_numpy(X_dev.values)\n",
    "# y_dev_tensor = torch.from_numpy(y_dev.values)\n",
    "\n",
    "# X_dev_tensor= X_dev_tensor.float()\n",
    "# y_dev_tensor =y_dev_tensor.type(torch.LongTensor)\n",
    "# #print(X_train_tensor)\n",
    "# X_dev_Variable = Variable(X_dev_tensor)\n",
    "# y_dev_Variable = Variable(y_dev_tensor)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.values)\n",
    "y_train_tensor = torch.from_numpy(y_train.values)\n",
    "\n",
    "X_train_tensor= X_train_tensor.float()\n",
    "y_train_tensor =y_train_tensor.type(torch.LongTensor)\n",
    "#print(X_train_tensor)\n",
    "X_train_Variable = Variable(X_train_tensor)\n",
    "y_train_Variable = Variable(y_train_tensor)\n",
    "\n",
    "\n",
    "train_set = Data.TensorDataset(data_tensor=X_train_tensor, target_tensor=y_train_tensor )\n",
    "\n",
    "\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_set,      \n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2)              # subprocesses for loading data\n",
    "\n",
    "\n",
    "# train_loader = Data.DataLoader(dataset=train_dataset, \n",
    "#                                            batch_size=batch_size, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = Data.DataLoader(dataset=test_dataset, \n",
    "#                                           batch_size=batch_size, \n",
    "#                                           shuffle=False)\n",
    "    \n",
    "class My_Net(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(My_Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0],hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1],hidden_size[2])\n",
    "        self.fc4 = nn.Linear(hidden_size[2], num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "        \n",
    "net = My_Net(input_size, hidden_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,  (batch_x, batch_y) in enumerate(train_loader):\n",
    "#         print(batch_x)\n",
    "        x,  y = Variable(batch_x), Variable(batch_y)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 ==0:\n",
    "            print('epoch {}: iteration {}, the loss is {}'.format(epoch,i ,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: iteration 0, the loss is Variable containing:\n",
      " 0.7395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 10, the loss is Variable containing:\n",
      " 0.2306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 20, the loss is Variable containing:\n",
      " 0.1929\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 30, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 40, the loss is Variable containing:\n",
      " 0.1502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 50, the loss is Variable containing:\n",
      " 0.1642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 60, the loss is Variable containing:\n",
      " 0.1539\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 70, the loss is Variable containing:\n",
      " 0.1650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 0: iteration 80, the loss is Variable containing:\n",
      " 0.1600\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 0, the loss is Variable containing:\n",
      " 0.1538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 10, the loss is Variable containing:\n",
      " 0.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 20, the loss is Variable containing:\n",
      " 0.1613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 30, the loss is Variable containing:\n",
      " 0.1547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 40, the loss is Variable containing:\n",
      " 0.1740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 50, the loss is Variable containing:\n",
      " 0.1568\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 60, the loss is Variable containing:\n",
      " 0.1484\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 70, the loss is Variable containing:\n",
      " 0.1547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 1: iteration 80, the loss is Variable containing:\n",
      " 0.1507\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 0, the loss is Variable containing:\n",
      " 0.1461\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 10, the loss is Variable containing:\n",
      " 0.1452\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 20, the loss is Variable containing:\n",
      " 0.1532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 30, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 40, the loss is Variable containing:\n",
      " 0.1495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 50, the loss is Variable containing:\n",
      " 0.1527\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 60, the loss is Variable containing:\n",
      " 0.1593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 70, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 2: iteration 80, the loss is Variable containing:\n",
      " 0.1441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 0, the loss is Variable containing:\n",
      " 0.1665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 10, the loss is Variable containing:\n",
      " 0.1506\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 20, the loss is Variable containing:\n",
      " 0.1509\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 30, the loss is Variable containing:\n",
      " 0.1462\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 40, the loss is Variable containing:\n",
      " 0.1593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 50, the loss is Variable containing:\n",
      " 0.1637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 60, the loss is Variable containing:\n",
      " 0.1407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 70, the loss is Variable containing:\n",
      " 0.1329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 3: iteration 80, the loss is Variable containing:\n",
      " 0.1531\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 0, the loss is Variable containing:\n",
      " 0.1551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 10, the loss is Variable containing:\n",
      " 0.1419\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 20, the loss is Variable containing:\n",
      " 0.1571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 30, the loss is Variable containing:\n",
      " 0.1558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 40, the loss is Variable containing:\n",
      " 0.1564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 50, the loss is Variable containing:\n",
      " 0.1630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 60, the loss is Variable containing:\n",
      " 0.1532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 70, the loss is Variable containing:\n",
      " 0.1442\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 4: iteration 80, the loss is Variable containing:\n",
      " 0.1502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 0, the loss is Variable containing:\n",
      " 0.1598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 10, the loss is Variable containing:\n",
      " 0.1626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 20, the loss is Variable containing:\n",
      " 0.1501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 30, the loss is Variable containing:\n",
      " 0.1433\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 40, the loss is Variable containing:\n",
      " 0.1560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 50, the loss is Variable containing:\n",
      " 0.1481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 60, the loss is Variable containing:\n",
      " 0.1598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 70, the loss is Variable containing:\n",
      " 0.1604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 5: iteration 80, the loss is Variable containing:\n",
      " 0.1606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 0, the loss is Variable containing:\n",
      " 0.1449\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 10, the loss is Variable containing:\n",
      " 0.1378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 20, the loss is Variable containing:\n",
      " 0.1494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 30, the loss is Variable containing:\n",
      " 0.1395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 40, the loss is Variable containing:\n",
      " 0.1677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 50, the loss is Variable containing:\n",
      " 0.1412\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 60, the loss is Variable containing:\n",
      " 0.1594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 70, the loss is Variable containing:\n",
      " 0.1583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 6: iteration 80, the loss is Variable containing:\n",
      " 0.1316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 0, the loss is Variable containing:\n",
      " 0.1387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 10, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 20, the loss is Variable containing:\n",
      " 0.1567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 30, the loss is Variable containing:\n",
      " 0.1621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 40, the loss is Variable containing:\n",
      " 0.1537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 50, the loss is Variable containing:\n",
      " 0.1644\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 60, the loss is Variable containing:\n",
      " 0.1528\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 70, the loss is Variable containing:\n",
      " 0.1734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 7: iteration 80, the loss is Variable containing:\n",
      " 0.1447\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 0, the loss is Variable containing:\n",
      " 0.1554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 10, the loss is Variable containing:\n",
      " 0.1403\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 20, the loss is Variable containing:\n",
      " 0.1585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 30, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 40, the loss is Variable containing:\n",
      " 0.1540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 50, the loss is Variable containing:\n",
      " 0.1367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 60, the loss is Variable containing:\n",
      " 0.1579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 70, the loss is Variable containing:\n",
      " 0.1542\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 8: iteration 80, the loss is Variable containing:\n",
      " 0.1441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 0, the loss is Variable containing:\n",
      " 0.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 10, the loss is Variable containing:\n",
      " 0.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 20, the loss is Variable containing:\n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 30, the loss is Variable containing:\n",
      " 0.1637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 40, the loss is Variable containing:\n",
      " 0.1591\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 50, the loss is Variable containing:\n",
      " 0.1611\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: iteration 60, the loss is Variable containing:\n",
      " 0.1703\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 70, the loss is Variable containing:\n",
      " 0.1652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "epoch 9: iteration 80, the loss is Variable containing:\n",
      " 0.1558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(446409,)\n",
      "(148803,)\n",
      "test set auc is 0.6344029175708916; Val set auc is 0.6293206671721198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score            \n",
    "#try to test it's accuracy\n",
    "out=  net(X_train_Variable)\n",
    "out = F.softmax(out)\n",
    "score_1 = roc_auc_score(y_train_Variable.data.numpy(), out.data.numpy()[:,1])\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val.values)\n",
    "y_val_tensor = torch.from_numpy(y_val.values)\n",
    "\n",
    "X_val_tensor= X_val_tensor.float()\n",
    "y_val_tensor =y_val_tensor.type(torch.LongTensor)\n",
    "#print(X_train_tensor)\n",
    "X_val_Variable = Variable(X_val_tensor)\n",
    "y_val_Variable = Variable(y_val_tensor)\n",
    "out2=  net(X_val_Variable)\n",
    "out2 = F.softmax(out2)\n",
    "score_2 = roc_auc_score(y_val_Variable.data.numpy(), out2.data.numpy()[:,1])\n",
    "\n",
    "print(out.data.numpy()[:,1].shape)\n",
    "print(out2.data.numpy()[:,1].shape)\n",
    "print('test set auc is {}; Val set auc is {}'.format(score_1, score_2))\n",
    "\n",
    "\n",
    "#So here I've tested that with Variable type, I can run this function\n",
    "# for t in range(100):\n",
    "#     out = net(X_train_tensor)                 # input x and predict based on x\n",
    "#     loss = criterion(out, y_train_tensor)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "#     optimizer.zero_grad()   # clear gradients for next train\n",
    "#     loss.backward()         # backpropagation, compute gradients\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446409,)\n",
      "(446409,)\n"
     ]
    }
   ],
   "source": [
    "print(out.data.numpy()[:,1].shape)\n",
    "print(out2.data.numpy()[:,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set auc is 0.6344029175708916; Val set auc is 0.6293206671721198\n"
     ]
    }
   ],
   "source": [
    "print('test set auc is {}; Val set auc is {}'.format(score_1, score_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_util\n",
    "import data_preprocess\n",
    "import datetime\n",
    "\n",
    "tic= datetime.datetime.now()\n",
    "train_data = data_util.load_train_data()\n",
    "test_data= data_util.load_test_data()\n",
    "\n",
    "naive_pre = data_preprocess.naive_preprocess()\n",
    "y_test_index = test_data['id']\n",
    "test_data.drop(['id'], axis=1, inplace=True)\n",
    "train_data = naive_pre.dtype_change(train_data)\n",
    "test_data = naive_pre.dtype_change(test_data)\n",
    "#train_prop is specified\n",
    "#X_train, X_val, y_train, y_val = data_util.split_train(train_data,prop=0.75)\n",
    "y_train = train_data['target']\n",
    "train_data.drop(['target','id'], axis=1, inplace=True)\n",
    "X_train = train_data\n",
    "\n",
    "X_train = naive_pre.scale(X_train)\n",
    "X_test = naive_pre.scale(test_data,test=True)\n",
    "\n",
    "#result = y_test_index,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9771  0.0229\n",
      " 0.9714  0.0286\n",
      " 0.9794  0.0206\n",
      "       ⋮        \n",
      " 0.9646  0.0354\n",
      " 0.9802  0.0198\n",
      " 0.9744  0.0256\n",
      "[torch.FloatTensor of size 892816x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.values)\n",
    "\n",
    "X_test_tensor= X_test_tensor.float()\n",
    "\n",
    "#print(X_train_tensor)\n",
    "X_test_Variable = Variable(X_test_tensor)\n",
    "\n",
    "out=  net(X_test_Variable)\n",
    "out = F.softmax(out)\n",
    "print(out)\n",
    "prob = out.data.numpy()[:,1]\n",
    "\n",
    "result = np.hstack((y_test_index, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"inter.csv\", result, delimiter=\",\",header= 'id, target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
